import json
import cv2
import torch
import re
import easyocr
import numpy as np
from torchvision import transforms
from tqdm import tqdm

# GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# EasyOCR ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš©)
reader = easyocr.Reader(['en'], gpu=torch.cuda.is_available())

def load_json(json_path):
    """JSON íŒŒì¼ì„ ë¡œë“œí•˜ê³  ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

def process_image(file_path, letter_bbox, target_size=(200, 200)):
    """
    ì´ë¯¸ì§€ì—ì„œ letter_bbox ì˜ì—­ì„ ì¶”ì¶œí•œ í›„, 100x100 í¬ê¸°ë¡œ ë³€í™˜í•˜ê³  GPU í…ì„œë¡œ ë³€í™˜
    """
    # ì´ë¯¸ì§€ ë¡œë“œ
    image = cv2.imread(file_path)
    if image is None:
        raise ValueError(f"Image at {file_path} could not be loaded.")

    # BBox ì¢Œí‘œ ì¶”ì¶œ
    x_min, y_min, w, h = map(int, letter_bbox)


    # ROI (Region of Interest) ìë¥´ê¸°
    roi = image[y_min:y_min+h, x_min:x_min+w]

    # í¬ê¸° ì¡°ì • (100x100)
    resized_roi = cv2.resize(roi, target_size, interpolation=cv2.INTER_AREA)

    # EasyOCRì„ ìœ„í•œ ë³€í™˜ (BGR â†’ GRAY)
    gray_roi = cv2.cvtColor(resized_roi, cv2.COLOR_BGR2GRAY)
    # gray_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    return gray_roi  # EasyOCRì€ grayscale ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬ ê°€ëŠ¥


def extract_text(image):
    """
    EasyOCRì„ ì‚¬ìš©í•´ ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ë©°, 
    R, RST â†’ "R", L, LST â†’ "L" ë³€í™˜
    ë‚˜ë¨¸ì§€ëŠ” "None"ìœ¼ë¡œ ë°˜í™˜
    """
    results = reader.readtext(image)
    
    extracted_text = []
    for _, text, _ in results:  # OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ê°€ì ¸ì˜¤ê¸°
        text = text.strip().upper()  # ëŒ€ì†Œë¬¸ì í†µì¼

        # ë¶ˆí•„ìš”í•œ ë¬¸ì ì‚­ì œ
        text = re.sub(r'[^A-Z]', '', text)
        
        # íŠ¹ì • ë³€í™˜ ê·œì¹™ ì ìš©
        if text in ["R", "RST"]:
            extracted_text.append("R")
        elif text in ["L", "LST"]:
            extracted_text.append("L")

    return " ".join(extracted_text)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜



def process_json(json_path):
    """
    JSON íŒŒì¼ì„ ë¡œë“œí•˜ê³ , ê° ì´ë¯¸ì§€ì˜ letter_bboxì—ì„œ ROIë¥¼ ì¶”ì¶œí•˜ì—¬ EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¸ì‹
    """
    data = load_json(json_path)
    ann = data["annotations"]
    results = []
    count = 0
    with tqdm(total=len(ann), desc="Processing Images", unit="img") as pbar:
        for item in ann:
            file_path = item["file_path"]
            letter_bbox = item["letter_bbox"]

            try:
                roi = process_image(file_path, letter_bbox)  # ROI ì¶”ì¶œ
                text = extract_text(roi)  # EasyOCRë¡œ í…ìŠ¤íŠ¸ ì¸ì‹
                if text is None:
                    continue
                results.append({
                    "file_path": file_path,
                    "letter_bbox": letter_bbox,
                    "bbox": item['bbox'],
                    "image_id": item["image_id"],
                    "score": item["score"],
                    "detected_text": text,
                })
                count += 1
                tqdm.write(f"âœ… Processed: {file_path} -> Text: {text}")
            except Exception as e:
                tqdm.write(f"âŒ Error processing {file_path}: {str(e)}")
            pbar.update(1)  

    print(f"After Processing remain images : {count}")
    
    return results

# ì˜ˆì œ JSON íŒŒì¼ ê²½ë¡œ
json_path = "data/json/joint/bbox_from_yolo_new.json"

# ì‹¤í–‰
ocr_results = process_json(json_path)

# ê²°ê³¼ ì €ì¥ (JSON íŒŒì¼ë¡œ ì €ì¥ ê°€ëŠ¥)
output_path = "./data/json/joint/ocr_results_v1.json"
with open(output_path, 'w', encoding='utf-8') as f:
    json.dump(ocr_results, f, ensure_ascii=False, indent=4)

print(f"\nğŸ¯ OCR ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")
