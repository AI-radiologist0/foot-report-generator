import os
import json
import logging
import torch
import numpy as np
import pandas as pd
from collections import Counter, defaultdict
from datetime import datetime

import _init_path
from config import cfg, update_config
from dataset.joint_patches import FinalSamplesDataset
from utils.utils import stratified_split_dataset, check_label_distribution_from_subset

def setup_logger(output_dir):
    os.makedirs(output_dir, exist_ok=True)
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    # File handler
    file_handler = logging.FileHandler(os.path.join(output_dir, 'seed_analysis.log'))
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    return logger

def analyze_seed_dataset(seed: int, cfg):
    """íŠ¹ì • ì‹œë“œì˜ ë°ì´í„°ì…‹ì„ ë¶„ì„"""
    cfg.defrost()
    cfg.DATASET.SEED = seed
    cfg.freeze()

    dataset = FinalSamplesDataset(cfg)
    train_dataset, val_dataset, test_dataset = stratified_split_dataset(dataset, seed)

    # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
    total_size = len(dataset)
    train_size = len(train_dataset)
    val_size = len(val_dataset)
    test_size = len(test_dataset)

    # Patient ID ìˆ˜ì§‘
    train_patient_ids = [dataset.data[i]['patient_id'] for i in train_dataset.indices]
    val_patient_ids = [dataset.data[i]['patient_id'] for i in val_dataset.indices]
    test_patient_ids = [dataset.data[i]['patient_id'] for i in test_dataset.indices]

    # í´ë˜ìŠ¤ë³„ ë¶„í¬ ìˆ˜ì§‘
    train_labels = [dataset.data[i]['class_label'] for i in train_dataset.indices]
    val_labels = [dataset.data[i]['class_label'] for i in val_dataset.indices]
    test_labels = [dataset.data[i]['class_label'] for i in test_dataset.indices]

    # ì¤‘ë³µ í™•ì¸
    train_val_overlap = set(train_patient_ids) & set(val_patient_ids)
    train_test_overlap = set(train_patient_ids) & set(test_patient_ids)
    val_test_overlap = set(val_patient_ids) & set(test_patient_ids)

    return {
        'seed': seed,
        'total_size': total_size,
        'train_size': train_size,
        'val_size': val_size,
        'test_size': test_size,
        'train_patient_ids': train_patient_ids,
        'val_patient_ids': val_patient_ids,
        'test_patient_ids': test_patient_ids,
        'train_labels': train_labels,
        'val_labels': val_labels,
        'test_labels': test_labels,
        'train_val_overlap': len(train_val_overlap),
        'train_test_overlap': len(train_test_overlap),
        'val_test_overlap': len(val_test_overlap),
        'train_val_overlap_patients': list(train_val_overlap),
        'train_test_overlap_patients': list(train_test_overlap),
        'val_test_overlap_patients': list(val_test_overlap)
    }

def comprehensive_seed_analysis(cfg, num_seeds=20):
    """0~19 ì‹œë“œê¹Œì§€ ì¢…í•© ë¶„ì„"""
    logger = logging.getLogger()
    
    logger.info("ğŸ” [Seed 0-19 ì¢…í•© ë¶„ì„ ì‹œì‘]")
    logger.info("=" * 80)

    all_results = []
    
    # 1. ê° ì‹œë“œë³„ ê¸°ë³¸ ë¶„ì„
    logger.info("ğŸ“Š 1ë‹¨ê³„: ê° ì‹œë“œë³„ ê¸°ë³¸ ë¶„ì„")
    logger.info("-" * 50)
    
    for seed in range(num_seeds):
        logger.info(f"ğŸ” Seed {seed} ë¶„ì„ ì¤‘...")
        result = analyze_seed_dataset(seed, cfg)
        all_results.append(result)
        
        logger.info(f"  ğŸ“ˆ í¬ê¸°: Total={result['total_size']}, Train={result['train_size']}, Val={result['val_size']}, Test={result['test_size']}")
        logger.info(f"  ğŸ”— ì¤‘ë³µ: Train-Val={result['train_val_overlap']}, Train-Test={result['train_test_overlap']}, Val-Test={result['val_test_overlap']}")

    # 2. ë°ì´í„° í¬ê¸° ì¼ê´€ì„± ê²€ì‚¬
    logger.info("\nğŸ“Š 2ë‹¨ê³„: ë°ì´í„° í¬ê¸° ì¼ê´€ì„± ê²€ì‚¬")
    logger.info("-" * 50)
    
    sizes_df = pd.DataFrame([{
        'seed': r['seed'],
        'total': r['total_size'],
        'train': r['train_size'],
        'val': r['val_size'],
        'test': r['test_size']
    } for r in all_results])
    
    logger.info(f"ğŸ“ í¬ê¸° í†µê³„:")
    logger.info(f"  Total: mean={sizes_df['total'].mean():.1f}, std={sizes_df['total'].std():.1f}")
    logger.info(f"  Train: mean={sizes_df['train'].mean():.1f}, std={sizes_df['train'].std():.1f}")
    logger.info(f"  Val:   mean={sizes_df['val'].mean():.1f}, std={sizes_df['val'].std():.1f}")
    logger.info(f"  Test:  mean={sizes_df['test'].mean():.1f}, std={sizes_df['test'].std():.1f}")
    
    # í¬ê¸° ì´ìƒì¹˜ í™•ì¸
    for col in ['total', 'train', 'val', 'test']:
        mean_val = sizes_df[col].mean()
        std_val = sizes_df[col].std()
        outliers = sizes_df[abs(sizes_df[col] - mean_val) > 2 * std_val]
        if not outliers.empty:
            logger.warning(f"âš ï¸  {col} í¬ê¸° ì´ìƒì¹˜: {outliers[['seed', col]].to_dict('records')}")

    # 3. ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬
    logger.info("\nğŸ“Š 3ë‹¨ê³„: ì¤‘ë³µ ë°ì´í„° ê²€ì‚¬")
    logger.info("-" * 50)
    
    overlap_df = pd.DataFrame([{
        'seed': r['seed'],
        'train_val_overlap': r['train_val_overlap'],
        'train_test_overlap': r['train_test_overlap'],
        'val_test_overlap': r['val_test_overlap']
    } for r in all_results])
    
    logger.info(f"ğŸ”— ì¤‘ë³µ í†µê³„:")
    logger.info(f"  Train-Val ì¤‘ë³µ: mean={overlap_df['train_val_overlap'].mean():.1f}, max={overlap_df['train_val_overlap'].max()}")
    logger.info(f"  Train-Test ì¤‘ë³µ: mean={overlap_df['train_test_overlap'].mean():.1f}, max={overlap_df['train_test_overlap'].max()}")
    logger.info(f"  Val-Test ì¤‘ë³µ: mean={overlap_df['val_test_overlap'].mean():.1f}, max={overlap_df['val_test_overlap'].max()}")
    
    # ì¤‘ë³µì´ ìˆëŠ” ì‹œë“œë“¤ í™•ì¸
    problematic_seeds = overlap_df[
        (overlap_df['train_val_overlap'] > 0) | 
        (overlap_df['train_test_overlap'] > 0) | 
        (overlap_df['val_test_overlap'] > 0)
    ]
    
    if not problematic_seeds.empty:
        logger.warning(f"âš ï¸  ì¤‘ë³µì´ ìˆëŠ” ì‹œë“œë“¤: {problematic_seeds.to_dict('records')}")
    else:
        logger.info("âœ… ëª¨ë“  ì‹œë“œì—ì„œ ì¤‘ë³µ ì—†ìŒ")

    # 4. í´ë˜ìŠ¤ ë¶„í¬ ê²€ì‚¬
    logger.info("\nğŸ“Š 4ë‹¨ê³„: í´ë˜ìŠ¤ ë¶„í¬ ê²€ì‚¬")
    logger.info("-" * 50)
    
    for seed in range(num_seeds):
        result = all_results[seed]
        logger.info(f"ğŸ” Seed {seed} í´ë˜ìŠ¤ ë¶„í¬:")
        
        train_dist = Counter(result['train_labels'])
        val_dist = Counter(result['val_labels'])
        test_dist = Counter(result['test_labels'])
        
        logger.info(f"  Train: {dict(train_dist)}")
        logger.info(f"  Val:   {dict(val_dist)}")
        logger.info(f"  Test:  {dict(test_dist)}")
        
        # ê·¹ë‹¨ì ì¸ ë¶„í¬ í™•ì¸
        for split_name, dist in [('Train', train_dist), ('Val', val_dist), ('Test', test_dist)]:
            if len(dist) > 1:  # ì´ì§„ ë¶„ë¥˜ì¸ ê²½ìš°
                min_count = min(dist.values())
                max_count = max(dist.values())
                ratio = max_count / min_count if min_count > 0 else float('inf')
                if ratio > 3:  # 3:1 ì´ìƒì˜ ë¶ˆê· í˜•
                    logger.warning(f"âš ï¸  Seed {seed} {split_name} ë¶ˆê· í˜•: {ratio:.1f}:1")

    # 5. ì‹œë“œ ê°„ ì¼ê´€ì„± ê²€ì‚¬
    logger.info("\nğŸ“Š 5ë‹¨ê³„: ì‹œë“œ ê°„ ì¼ê´€ì„± ê²€ì‚¬")
    logger.info("-" * 50)
    
    # Test ì„¸íŠ¸ í¬ê¸° ë³€ë™ì„±
    test_sizes = [r['test_size'] for r in all_results]
    test_size_std = np.std(test_sizes)
    test_size_cv = test_size_std / np.mean(test_sizes)  # ë³€ë™ê³„ìˆ˜
    
    logger.info(f"ğŸ“ Test ì„¸íŠ¸ í¬ê¸° ë³€ë™ì„±:")
    logger.info(f"  í‘œì¤€í¸ì°¨: {test_size_std:.1f}")
    logger.info(f"  ë³€ë™ê³„ìˆ˜: {test_size_cv:.3f}")
    
    if test_size_cv > 0.1:  # 10% ì´ìƒ ë³€ë™
        logger.warning(f"âš ï¸  Test ì„¸íŠ¸ í¬ê¸°ê°€ ë¶ˆì•ˆì • (ë³€ë™ê³„ìˆ˜: {test_size_cv:.3f})")
    
    # 6. íŠ¹ì´í•œ ì‹œë“œ ì‹ë³„
    logger.info("\nğŸ“Š 6ë‹¨ê³„: íŠ¹ì´í•œ ì‹œë“œ ì‹ë³„")
    logger.info("-" * 50)
    
    # Test ì„¸íŠ¸ê°€ ê°€ì¥ ì‘ì€ ì‹œë“œ
    min_test_seed = min(all_results, key=lambda x: x['test_size'])
    logger.info(f"ğŸ” Test ì„¸íŠ¸ê°€ ê°€ì¥ ì‘ì€ ì‹œë“œ: {min_test_seed['seed']} (í¬ê¸°: {min_test_seed['test_size']})")
    
    # Test ì„¸íŠ¸ê°€ ê°€ì¥ í° ì‹œë“œ
    max_test_seed = max(all_results, key=lambda x: x['test_size'])
    logger.info(f"ğŸ” Test ì„¸íŠ¸ê°€ ê°€ì¥ í° ì‹œë“œ: {max_test_seed['seed']} (í¬ê¸°: {max_test_seed['test_size']})")
    
    # ì¤‘ë³µì´ ê°€ì¥ ë§ì€ ì‹œë“œ
    max_overlap_seed = max(all_results, key=lambda x: x['train_test_overlap'])
    if max_overlap_seed['train_test_overlap'] > 0:
        logger.warning(f"âš ï¸  Train-Test ì¤‘ë³µì´ ê°€ì¥ ë§ì€ ì‹œë“œ: {max_overlap_seed['seed']} (ì¤‘ë³µ: {max_overlap_seed['train_test_overlap']})")

    # 7. ê²°ê³¼ ìš”ì•½
    logger.info("\nğŸ“Š 7ë‹¨ê³„: ì¢…í•© ê²°ê³¼ ìš”ì•½")
    logger.info("=" * 80)
    
    # ë¬¸ì œê°€ ìˆëŠ” ì‹œë“œë“¤ ì‹ë³„
    problematic_seeds = []
    
    for result in all_results:
        issues = []
        
        # Test ì„¸íŠ¸ê°€ ë„ˆë¬´ ì‘ì€ ê²½ìš°
        if result['test_size'] < 20:
            issues.append(f"Testì„¸íŠ¸ì‘ìŒ({result['test_size']})")
        
        # ì¤‘ë³µì´ ìˆëŠ” ê²½ìš°
        if result['train_test_overlap'] > 0:
            issues.append(f"Train-Testì¤‘ë³µ({result['train_test_overlap']})")
        
        if result['train_val_overlap'] > 0:
            issues.append(f"Train-Valì¤‘ë³µ({result['train_val_overlap']})")
        
        if issues:
            problematic_seeds.append({
                'seed': result['seed'],
                'issues': issues,
                'test_size': result['test_size']
            })
    
    if problematic_seeds:
        logger.warning(f"âš ï¸  ë¬¸ì œê°€ ìˆëŠ” ì‹œë“œë“¤:")
        for ps in problematic_seeds:
            logger.warning(f"  Seed {ps['seed']}: {', '.join(ps['issues'])} (Testí¬ê¸°: {ps['test_size']})")
    else:
        logger.info("âœ… ëª¨ë“  ì‹œë“œê°€ ì •ìƒ")

    # 8. ê¶Œì¥ì‚¬í•­
    logger.info("\nğŸ“‹ 8ë‹¨ê³„: ê¶Œì¥ì‚¬í•­")
    logger.info("=" * 80)
    
    if problematic_seeds:
        logger.info("ğŸ”§ ê¶Œì¥ ì¡°ì¹˜:")
        logger.info("  1. ë¬¸ì œê°€ ìˆëŠ” ì‹œë“œë“¤ì„ ì œì™¸í•˜ê³  ì‹¤í—˜ ì¬ì‹¤í–‰")
        logger.info("  2. Test ì„¸íŠ¸ í¬ê¸°ê°€ 20ê°œ ë¯¸ë§Œì¸ ì‹œë“œë“¤ì€ ì œì™¸")
        logger.info("  3. ì¤‘ë³µì´ ìˆëŠ” ì‹œë“œë“¤ì€ ë°ì´í„° ëˆ„ì¶œ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë¯€ë¡œ ì œì™¸")
        logger.info("  4. Patient ID ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µì„ ì™„ì „íˆ ì œê±°í•˜ëŠ” ë¡œì§ ì¶”ê°€ ê³ ë ¤")
    else:
        logger.info("âœ… ëª¨ë“  ì‹œë“œê°€ ì •ìƒì´ë¯€ë¡œ í˜„ì¬ ì„¤ì •ìœ¼ë¡œ ì‹¤í—˜ ì§„í–‰ ê°€ëŠ¥")

    return all_results, problematic_seeds

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--cfg', default='config/large/tmp/origin_oa_normal.yaml', type=str)
    parser.add_argument('--num_seeds', default=20, type=int)
    args = parser.parse_args()

    update_config(cfg, args)
    
    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
    output_dir = os.path.join('output', f"seed_analysis_{timestamp}")
    logger = setup_logger(output_dir)
    
    logger.info(f"ğŸ” Seed 0-{args.num_seeds-1} ì¢…í•© ë¶„ì„ ì‹œì‘")
    logger.info(f"ğŸ“ ì„¤ì • íŒŒì¼: {args.cfg}")
    logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    all_results, problematic_seeds = comprehensive_seed_analysis(cfg, args.num_seeds)
    
    # ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
    results_df = pd.DataFrame([{
        'seed': r['seed'],
        'total_size': r['total_size'],
        'train_size': r['train_size'],
        'val_size': r['val_size'],
        'test_size': r['test_size'],
        'train_val_overlap': r['train_val_overlap'],
        'train_test_overlap': r['train_test_overlap'],
        'val_test_overlap': r['val_test_overlap']
    } for r in all_results])
    
    csv_path = os.path.join(output_dir, 'seed_analysis_results.csv')
    results_df.to_csv(csv_path, index=False)
    logger.info(f"ğŸ“„ ê²°ê³¼ê°€ CSVë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {csv_path}")
    
    # ë¬¸ì œê°€ ìˆëŠ” ì‹œë“œë“¤ë§Œ ë³„ë„ ì €ì¥
    if problematic_seeds:
        problematic_df = pd.DataFrame(problematic_seeds)
        problematic_csv_path = os.path.join(output_dir, 'problematic_seeds.csv')
        problematic_df.to_csv(problematic_csv_path, index=False)
        logger.info(f"ğŸ“„ ë¬¸ì œ ì‹œë“œë“¤ì´ ë³„ë„ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {problematic_csv_path}")

if __name__ == '__main__':
    main()