import os
import json
import logging
import pandas as pd
from collections import Counter, defaultdict
from datetime import datetime

def setup_logger(output_dir):
    os.makedirs(output_dir, exist_ok=True)
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

    # File handler
    file_handler = logging.FileHandler(os.path.join(output_dir, 'patient_analysis.log'))
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

    # Console handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    return logger

def analyze_patient_distribution(json_path):
    """JSON íŒŒì¼ì—ì„œ í™˜ìë³„ ë¶„í¬ ë¶„ì„"""
    logger = logging.getLogger()
    
    logger.info(f"ğŸ” JSON íŒŒì¼ ë¶„ì„ ì‹œì‘: {json_path}")
    logger.info("=" * 80)
    
    # JSON íŒŒì¼ ë¡œë“œ
    with open(json_path, 'r') as f:
        data = json.load(f)
    
    logger.info(f"ğŸ“Š ì´ ë°ì´í„° ê°œìˆ˜: {len(data)}")
    
    # í™˜ìë³„ ë°ì´í„° ìˆ˜ì§‘
    patient_data = defaultdict(list)
    patient_classes = defaultdict(list)
    
    for idx, item in enumerate(data):
        patient_id = item.get('patient_id', 'unknown')
        class_label = item.get('class', 'unknown').lower()
        
        patient_data[patient_id].append({
            'index': idx,
            'class': class_label,
            'file_path': item.get('merged_image_path', ''),
            'left_right_files': item.get('file_paths', []),
            'diagnosis': item.get('diagnosis', '')
        })
        patient_classes[patient_id].append(class_label)
    
    # í™˜ìë³„ í†µê³„
    patient_stats = {}
    for patient_id, items in patient_data.items():
        class_counts = Counter([item['class'] for item in items])
        patient_stats[patient_id] = {
            'total_images': len(items),
            'classes': dict(class_counts),
            'unique_classes': len(set(class_counts.keys())),
            'items': items
        }
    
    # 1. ê¸°ë³¸ í†µê³„
    logger.info("ğŸ“Š 1ë‹¨ê³„: ê¸°ë³¸ í†µê³„")
    logger.info("-" * 50)
    
    total_patients = len(patient_data)
    total_images = sum(stats['total_images'] for stats in patient_stats.values())
    
    logger.info(f"ğŸ‘¥ ì´ í™˜ì ìˆ˜: {total_patients}")
    logger.info(f"ğŸ–¼ï¸  ì´ ì´ë¯¸ì§€ ìˆ˜: {total_images}")
    logger.info(f"ğŸ“ˆ í™˜ìë‹¹ í‰ê·  ì´ë¯¸ì§€ ìˆ˜: {total_images / total_patients:.2f}")
    
    # 2. í™˜ìë³„ ì´ë¯¸ì§€ ìˆ˜ ë¶„í¬
    logger.info("\nğŸ“Š 2ë‹¨ê³„: í™˜ìë³„ ì´ë¯¸ì§€ ìˆ˜ ë¶„í¬")
    logger.info("-" * 50)
    
    image_counts = [stats['total_images'] for stats in patient_stats.values()]
    image_count_dist = Counter(image_counts)
    
    logger.info("í™˜ìë³„ ì´ë¯¸ì§€ ìˆ˜ ë¶„í¬:")
    for count, num_patients in sorted(image_count_dist.items()):
        logger.info(f"  {count}ê°œ ì´ë¯¸ì§€: {num_patients}ëª… í™˜ì")
    
    # 3. ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê°€ì§„ í™˜ìë“¤
    logger.info("\nğŸ“Š 3ë‹¨ê³„: ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê°€ì§„ í™˜ìë“¤")
    logger.info("-" * 50)
    
    multi_image_patients = {pid: stats for pid, stats in patient_stats.items() if stats['total_images'] > 1}
    
    logger.info(f"ğŸ” ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê°€ì§„ í™˜ì ìˆ˜: {len(multi_image_patients)}")
    
    if multi_image_patients:
        logger.info("ğŸ“‹ ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê°€ì§„ í™˜ì ìƒì„¸:")
        for patient_id, stats in sorted(multi_image_patients.items(), key=lambda x: x[1]['total_images'], reverse=True):
            logger.info(f"  í™˜ì {patient_id}: {stats['total_images']}ê°œ ì´ë¯¸ì§€")
            logger.info(f"    í´ë˜ìŠ¤ ë¶„í¬: {stats['classes']}")
            
            # ê° ì´ë¯¸ì§€ ìƒì„¸ ì •ë³´
            for item in stats['items']:
                logger.info(f"    - ì¸ë±ìŠ¤ {item['index']}: {item['class']} ({item['file_path']})")
            logger.info("")
    
    # 4. ê°™ì€ í™˜ìì˜ ë‹¤ë¥¸ í´ë˜ìŠ¤
    logger.info("\nğŸ“Š 4ë‹¨ê³„: ê°™ì€ í™˜ìì˜ ë‹¤ë¥¸ í´ë˜ìŠ¤")
    logger.info("-" * 50)
    
    mixed_class_patients = {pid: stats for pid, stats in patient_stats.items() if stats['unique_classes'] > 1}
    
    logger.info(f"ğŸ” ì—¬ëŸ¬ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í™˜ì ìˆ˜: {len(mixed_class_patients)}")
    
    if mixed_class_patients:
        logger.info("ğŸ“‹ ì—¬ëŸ¬ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í™˜ì ìƒì„¸:")
        for patient_id, stats in sorted(mixed_class_patients.items(), key=lambda x: x[1]['unique_classes'], reverse=True):
            logger.info(f"  í™˜ì {patient_id}: {stats['unique_classes']}ê°œ í´ë˜ìŠ¤")
            logger.info(f"    í´ë˜ìŠ¤ ë¶„í¬: {stats['classes']}")
            logger.info("")
    
    # 5. í´ë˜ìŠ¤ë³„ í™˜ì ë¶„í¬
    logger.info("\nğŸ“Š 5ë‹¨ê³„: í´ë˜ìŠ¤ë³„ í™˜ì ë¶„í¬")
    logger.info("-" * 50)
    
    class_patient_dist = defaultdict(set)
    for patient_id, classes in patient_classes.items():
        for class_name in classes:
            class_patient_dist[class_name].add(patient_id)
    
    logger.info("í´ë˜ìŠ¤ë³„ í™˜ì ìˆ˜:")
    for class_name, patients in sorted(class_patient_dist.items()):
        logger.info(f"  {class_name}: {len(patients)}ëª… í™˜ì")
    
    # 6. ì¤‘ë³µ í™˜ì ID í™•ì¸
    logger.info("\nğŸ“Š 6ë‹¨ê³„: ì¤‘ë³µ í™˜ì ID í™•ì¸")
    logger.info("-" * 50)
    
    all_patient_ids = [item.get('patient_id', 'unknown') for item in data]
    duplicate_patient_ids = [pid for pid, count in Counter(all_patient_ids).items() if count > 1]
    
    if duplicate_patient_ids:
        logger.info(f"ğŸ” ì¤‘ë³µëœ í™˜ì ID ìˆ˜: {len(duplicate_patient_ids)}")
        logger.info("ğŸ“‹ ì¤‘ë³µëœ í™˜ì IDë“¤:")
        for pid in sorted(duplicate_patient_ids):
            count = all_patient_ids.count(pid)
            logger.info(f"  {pid}: {count}ë²ˆ ë“±ì¥")
    else:
        logger.info("âœ… ì¤‘ë³µëœ í™˜ì ID ì—†ìŒ")
    
    # 7. ê²°ê³¼ ìš”ì•½
    logger.info("\nğŸ“Š 7ë‹¨ê³„: ê²°ê³¼ ìš”ì•½")
    logger.info("=" * 80)
    
    logger.info("ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­:")
    
    # ê°€ì¥ ë§ì€ ì´ë¯¸ì§€ë¥¼ ê°€ì§„ í™˜ì
    if patient_stats:
        max_images_patient = max(patient_stats.items(), key=lambda x: x[1]['total_images'])
        logger.info(f"  ğŸ“ˆ ê°€ì¥ ë§ì€ ì´ë¯¸ì§€: í™˜ì {max_images_patient[0]} ({max_images_patient[1]['total_images']}ê°œ)")
    
    # ê°€ì¥ ë§ì€ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í™˜ì
    if patient_stats:
        max_classes_patient = max(patient_stats.items(), key=lambda x: x[1]['unique_classes'])
        logger.info(f"  ğŸ¯ ê°€ì¥ ë§ì€ í´ë˜ìŠ¤: í™˜ì {max_classes_patient[0]} ({max_classes_patient[1]['unique_classes']}ê°œ)")
    
    # ë°ì´í„° ëˆ„ì¶œ ìœ„í—˜ë„
    multi_image_ratio = len(multi_image_patients) / total_patients
    logger.info(f"  âš ï¸  ë°ì´í„° ëˆ„ì¶œ ìœ„í—˜ë„: {multi_image_ratio:.1%} ({len(multi_image_patients)}/{total_patients} í™˜ì)")
    
    if multi_image_ratio > 0.5:
        logger.warning("  ğŸš¨ ë†’ì€ ë°ì´í„° ëˆ„ì¶œ ìœ„í—˜! Patient ID ê¸°ë°˜ ë¶„í•  ê°•ë ¥ ê¶Œì¥")
    elif multi_image_ratio > 0.2:
        logger.warning("  âš ï¸  ì¤‘ê°„ ë°ì´í„° ëˆ„ì¶œ ìœ„í—˜! Patient ID ê¸°ë°˜ ë¶„í•  ê¶Œì¥")
    else:
        logger.info("  âœ… ë‚®ì€ ë°ì´í„° ëˆ„ì¶œ ìœ„í—˜")
    
    return patient_stats, multi_image_patients, mixed_class_patients

def save_analysis_results(patient_stats, output_dir):
    """ë¶„ì„ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
    logger = logging.getLogger()
    
    # í™˜ìë³„ í†µê³„ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    results = []
    for patient_id, stats in patient_stats.items():
        results.append({
            'patient_id': patient_id,
            'total_images': stats['total_images'],
            'unique_classes': stats['unique_classes'],
            'classes': str(stats['classes']),
            'has_multiple_images': stats['total_images'] > 1,
            'has_multiple_classes': stats['unique_classes'] > 1
        })
    
    df = pd.DataFrame(results)
    
    # CSV ì €ì¥
    csv_path = os.path.join(output_dir, 'patient_analysis_results.csv')
    df.to_csv(csv_path, index=False)
    logger.info(f"ğŸ“„ ë¶„ì„ ê²°ê³¼ê°€ CSVë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {csv_path}")
    
    # ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê°€ì§„ í™˜ìë“¤ë§Œ ë³„ë„ ì €ì¥
    multi_image_df = df[df['has_multiple_images'] == True]
    if not multi_image_df.empty:
        multi_image_csv_path = os.path.join(output_dir, 'multi_image_patients.csv')
        multi_image_df.to_csv(multi_image_csv_path, index=False)
        logger.info(f"ğŸ“„ ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ê°€ì§„ í™˜ìë“¤ì´ ë³„ë„ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {multi_image_csv_path}")
    
    # ì—¬ëŸ¬ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í™˜ìë“¤ë§Œ ë³„ë„ ì €ì¥
    multi_class_df = df[df['has_multiple_classes'] == True]
    if not multi_class_df.empty:
        multi_class_csv_path = os.path.join(output_dir, 'multi_class_patients.csv')
        multi_class_df.to_csv(multi_class_csv_path, index=False)
        logger.info(f"ğŸ“„ ì—¬ëŸ¬ í´ë˜ìŠ¤ë¥¼ ê°€ì§„ í™˜ìë“¤ì´ ë³„ë„ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {multi_class_csv_path}")

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--json', required=True, type=str, help='ë¶„ì„í•  JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output_dir', default=None, type=str, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    args = parser.parse_args()
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if args.output_dir is None:
        timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        json_name = os.path.splitext(os.path.basename(args.json))[0]
        output_dir = os.path.join('output', f"patient_analysis_{json_name}_{timestamp}")
    else:
        output_dir = args.output_dir
    
    logger = setup_logger(output_dir)
    
    logger.info(f"ğŸ” í™˜ì ë¶„ì„ ì‹œì‘")
    logger.info(f"ğŸ“ JSON íŒŒì¼: {args.json}")
    logger.info(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    # ë¶„ì„ ì‹¤í–‰
    patient_stats, multi_image_patients, mixed_class_patients = analyze_patient_distribution(args.json)
    
    # ê²°ê³¼ ì €ì¥
    save_analysis_results(patient_stats, output_dir)
    
    logger.info("âœ… í™˜ì ë¶„ì„ ì™„ë£Œ!")

if __name__ == '__main__':
    main()