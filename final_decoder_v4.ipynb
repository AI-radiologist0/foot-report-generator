{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882011e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-13 10:10:44.343032: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-13 10:10:44.349692: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747156244.357259   86173 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747156244.359557   86173 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747156244.365533   86173 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747156244.365540   86173 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747156244.365541   86173 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747156244.365541   86173 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-13 10:10:44.367808: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]         /home/avaghasiya/.conda/envs/rsna/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:676: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n",
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0d9a5d61a04c16ae721011a96b757e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53c59d69d51439c93fa57401a01a6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.3008\n",
      "  Validation Loss     : 0.8050\n",
      "  Semantic Similarity : 0.3757\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8cfcd8aec74f74836cfc569db486b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf339501137478d854fe88c83e6ae86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss               : 0.8727\n",
      "Test Semantic Similarity: 0.4036\n",
      "\n",
      "--- Example 39 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Joint space narrowing with sclerotic changes in intertarsal joint with loose body._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Joint space narrowing with sclerotic changes in intertarsal joint with loose body.\n",
      "Generated Report : \n",
      "degenerative change.\n",
      "\n",
      "--- Example 29 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Gouty arthritis in Rt 1st and left 5th MTP._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Gouty arthritis in Rt 1st and left 5th MTP.\n",
      "Generated Report : \n",
      "no bony lesion.\n",
      "\n",
      "--- Example 105 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "postop. state._x000D_\n",
      "degenerative change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "postop. state._x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "postop. state. degenerative change.\n",
      "Generated Report : \n",
      "degenerative change.\n",
      "\n",
      "--- Example 26 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both 1st MTP joint, severe OA (Rt. > Lt.)_x000D_\n",
      "both ankle soft tissue swelling._x000D_\n",
      "_x000D_\n",
      "--> underlying gout arthritis cannot be excluded._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both 1st MTP joint, severe OA (Rt. > Lt.)_x000D_\n",
      "both ankle soft tissue swelling._x000D_\n",
      "_x000D_\n",
      "--> underlying gout arthritis cannot be excluded._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both 1st MTP joint, severe OA (Rt. > Lt.) both ankle soft tissue swelling. --> underlying gout arthritis cannot be excluded.\n",
      "Generated Report : \n",
      "No bony abnormality\n",
      "\n",
      "--- Example 47 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Marginal erosion, bilateral 5th metatarsal head_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Marginal erosion, bilateral 5th metatarsal head\n",
      "Generated Report : \n",
      "degenerative change\n",
      "\n",
      "--- Example 88 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change.\n",
      "Generated Report : \n",
      "degenerative change\n",
      "\n",
      "--- Example 121 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_degenerative change\n",
      "soft tissue swelling, Lt ankle and foot_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- degenerative change soft tissue swelling, Lt ankle and foot\n",
      "Generated Report : \n",
      "no bony lesion.\n",
      "\n",
      "--- Example 62 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_mild degenerative change\n",
      "soft tissue swelling, Lt 1st MTP joint_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- mild degenerative change soft tissue swelling, Lt 1st MTP joint\n",
      "Generated Report : \n",
      "no bony lesion.\n",
      "\n",
      "--- Example 11 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "No visible crystal deposition in both MTP area._x000D_\n",
      "Suspicious osteolytic lesion in the left 1st IP, r/o enchondroma._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No visible crystal deposition in both MTP area. Suspicious osteolytic lesion in the left 1st IP, r/o enchondroma.\n",
      "Generated Report : \n",
      "No bony abnormality\n",
      "\n",
      "--- Example 33 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Lt. large os trigonum._x000D_\n",
      "Lt. foot soft tissue swelling._x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Lt. large os trigonum. Lt. foot soft tissue swelling.\n",
      "Generated Report : \n",
      "No bony abnormality.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "# 1) Remove any existing handlers (e.g. from prior imports or notebook runs)\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "\n",
    "# 2) Configure file-only logging\n",
    "logging.basicConfig(\n",
    "    filename='training.log',      # will be created in your current working directory\n",
    "    filemode='w',                 # overwrite on each run\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    abnormal = ['ra', 'oa', 'gout']\n",
    "    normal = ['normal']\n",
    "    class_counts, data_by_class = count_labels(data, abnormal + normal, cfg)\n",
    "    combined = {\n",
    "        'abnormal': sum((data_by_class[c] for c in abnormal), []),\n",
    "        'normal': data_by_class['normal']\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': sum(class_counts[c] for c in abnormal),\n",
    "        'normal': class_counts['normal']\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced = []\n",
    "    final_counts = {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if len(target_classes) == 2 and 'abnormal' in target_classes and 'normal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset\n",
    "# =============================================================================\n",
    "\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2\n",
    "        self.abnormal_classify = self.is_binary and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {'ra': 'abnormal', 'oa': 'abnormal', 'gout': 'abnormal', 'normal': 'normal'}\n",
    "            if self.abnormal_classify else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        for i, (merged, fp, item) in enumerate(filtered):\n",
    "            cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                cls = self.abnormal_mapping.get(cls, cls)\n",
    "            self.data[i] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"Findings: {clean}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=511, return_tensors='pt')\n",
    "\n",
    "        if tok['input_ids'][0][-1] != self.tokenizer.eos_token_id:\n",
    "            input_ids = torch.cat([tok['input_ids'], torch.tensor([[self.tokenizer.eos_token_id]])], dim=1)\n",
    "            attention_mask = torch.cat([tok['attention_mask'], torch.tensor([[1]])], dim=1)\n",
    "        else:\n",
    "            input_ids = tok['input_ids']\n",
    "            attention_mask = tok['attention_mask']\n",
    "\n",
    "        input_ids = input_ids.squeeze(0)\n",
    "        attention_mask = attention_mask.squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img': img,\n",
    "            'patches': patches_tensor,\n",
    "            'raw_report': raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'): left = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left', 'right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side == 'left': left = lst\n",
    "                            else: right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p, 1) for p in left]\n",
    "        if right and not left:\n",
    "            left = [cv2.flip(p, 1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] stacked full_imgs shape: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] stacked patches shape: {patches.shape}\")\n",
    "\n",
    "    ids = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] padded input_ids shape: {ids.shape}, padded attention_mask shape: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs': imgs,\n",
    "        'patches': patches,\n",
    "        'input_ids': ids,\n",
    "        'attention_mask': masks,\n",
    "        'raw_reports': [b['raw_report'] for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model\n",
    "# =============================================================================\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2, 3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        # Global image\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        logging.info(f\"[Model] global_encoder output shape: {g_feats.shape}\")\n",
    "        g = self.global_proj(g_feats).unsqueeze(1)\n",
    "        logging.info(f\"[Model] global_proj + unsqueeze shape: {g.shape}\")\n",
    "\n",
    "        # Patch images\n",
    "        B, N, C, H, W = patches.shape\n",
    "        logging.info(f\"[Model] patches input shape: {patches.shape}\")\n",
    "        p = patches.view(B * N, C, H, W)\n",
    "        pf_feats = (self.patch_encoder.forward_features(p)\n",
    "                    if hasattr(self.patch_encoder, 'forward_features')\n",
    "                    else self.patch_encoder(p))\n",
    "        logging.info(f\"[Model] patch_encoder output shape: {pf_feats.shape}\")\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "        logging.info(f\"[Model] patch_proj + reshape shape: {pf.shape}\")\n",
    "\n",
    "        # Combine\n",
    "        cat = torch.cat([g, pf], dim=1)\n",
    "        logging.info(f\"[Model] concatenated features shape: {cat.shape}\")\n",
    "        comb, _ = self.attn(cat, cat, cat)\n",
    "        comb = self.norm(comb)\n",
    "        logging.info(f\"[Model] after attention & norm shape: {comb.shape}\")\n",
    "\n",
    "        # Decoder\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        logging.info(f\"[Model] decoder logits shape: {out.logits.shape}\")\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Train / Eval helpers\n",
    "# =============================================================================\n",
    "\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts = b['patches'].to(device)\n",
    "        ids = b['input_ids'].to(device)\n",
    "        msk = b['attention_mask'].to(device)\n",
    "\n",
    "        logging.info(f\"[Train] batch full_imgs {imgs.shape}, patches {pts.shape}, input_ids {ids.shape}, mask {msk.shape}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts = b['patches'].to(device)\n",
    "        ids = b['input_ids'].to(device)\n",
    "        msk = b['attention_mask'].to(device)\n",
    "\n",
    "        logging.info(f\"[Eval] batch full_imgs {imgs.shape}, patches {pts.shape}, input_ids {ids.shape}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # Use consistent prompt\n",
    "            prompt_text = \"Findings:\"\n",
    "            prompt_ids = tokenizer(prompt_text, return_tensors='pt')['input_ids'].to(device)\n",
    "            prompt = prompt_ids.repeat(imgs.size(0), 1)\n",
    "\n",
    "            # Encode images\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B, N, C, H, W = pts.shape\n",
    "            p = pts.view(B * N, C, H, W)\n",
    "            pf_feats = model.patch_encoder(p)\n",
    "            pf_pooled = model._pool(pf_feats)\n",
    "            pf = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat = torch.cat([g, pf], dim=1)\n",
    "            comb, _ = model.attn(cat, cat, cat)\n",
    "            comb = model.norm(comb)\n",
    "\n",
    "            gen_ids = model.decoder.generate(\n",
    "                input_ids=prompt,\n",
    "                encoder_hidden_states=comb,\n",
    "                early_stopping=True,\n",
    "                attention_mask=torch.ones_like(prompt),\n",
    "                max_length=100,\n",
    "                do_sample=True,\n",
    "                top_k=40,\n",
    "                top_p=0.9,\n",
    "                temperature=0.7,\n",
    "                repetition_penalty=1.3,\n",
    "                no_repeat_ngram_size=2,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "            gen_txt = [tokenizer.decode(g_, skip_special_tokens=True).replace(\"Findings:\", \"\").strip() for g_ in gen_ids]\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True).replace(\"Findings:\", \"\").strip() for i_ in ids]\n",
    "\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt.extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1 = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2 = stm.encode(gt, convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Similarity\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Similarity\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW = True\n",
    "cfg.DATASET.USE_PATCH = True\n",
    "cfg.DATASET.REPORT = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['ra', 'oa', 'gout', 'normal', 'uncertain', 'ref.prev']\n",
    "cfg.DATASET.BALANCE = False\n",
    "cfg.DATASET.AUGMENT = False\n",
    "\n",
    "# Initialize and configure tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "# Prepare dataset\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "logging.info(\"Dataset class distribution:\")\n",
    "for cls, cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "# Split\n",
    "n = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = int(0.1 * n)\n",
    "n_test = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Model, optimizer, scheduler, scaler\n",
    "model = MultiModalModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "# Training\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logging.info(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    logging.info(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    logging.info(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    logging.info(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# Plot metrics\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# Test evaluation\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "logging.info(\"\\n========== TEST RESULTS ==========\")\n",
    "logging.info(f\"Test Loss               : {test_loss:.4f}\")\n",
    "logging.info(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "logging.info(\"\\n===== RANDOM TEST EXAMPLES =====\")\n",
    "for idx in random.sample(range(len(test_ds)), min(10, len(test_ds))):\n",
    "    ex = test_ds[idx]\n",
    "    raw = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    prompt_text = \"Findings:\"\n",
    "    prompt_ids = tokenizer(prompt_text, return_tensors='pt')['input_ids'].to(device)\n",
    "    prompt = prompt_ids.repeat(fi.size(0), 1)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B, N, C, H, W = pa.shape\n",
    "    p = pa.view(B * N, C, H, W)\n",
    "    pf_feats = model.patch_encoder(p)\n",
    "    pf_pooled = model._pool(pf_feats)\n",
    "    pf = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "    cat = torch.cat([g, pf], dim=1)\n",
    "    comb, _ = model.attn(cat, cat, cat)\n",
    "    comb = model.norm(comb)\n",
    "\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt,\n",
    "        encoder_hidden_states=comb,\n",
    "        early_stopping=True,\n",
    "        attention_mask=torch.ones_like(prompt),\n",
    "        max_length=100,\n",
    "        do_sample=True,\n",
    "        top_k=40,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        no_repeat_ngram_size=2,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True).replace(\"Findings:\", \"\").strip()\n",
    "\n",
    "    logging.info(f\"\\n--- Example {idx} ---\")\n",
    "    logging.info(f\"Raw Report       : \\n{raw}\")\n",
    "    logging.info(f\"Cleaned Report   : \\n{clean}\")\n",
    "    logging.info(f\"Generated Report : \\n{gen}\")\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529f4d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29efe8b2142047bab6f9a95a409b7a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0599dd33134747b6b080cc66e57538eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.4058\n",
      "  Validation Loss     : 0.9173\n",
      "  Semantic Similarity : 0.1761\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b176febee44cdc997f36e954c7c451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d61e5afe83415f8c6ae0103b69f5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss               : 0.9260\n",
      "Test Semantic Similarity: 0.1794\n",
      "\n",
      "--- Example 113 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_Degenerative changes_x000D__x000D_[CONCLUSION    ]_x000D_Degenerative changes_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "Degenerative changes\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 108 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both hands, ankles, and feet, degenerative change._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both hands, ankles, and feet, degenerative change._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both hands, ankles, and feet, degenerative change.\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 21 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Enthesopathy in both calcaneus._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Enthesopathy in both calcaneus.\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 6 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant interval change since last study._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant interval change since last study._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant interval change since last study.\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 10 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_degenerative change\n",
      "\n",
      "hallux valgus, both \n",
      "\n",
      "old fracture, Lt fibular tip \n",
      "\n",
      "soft tissue swelling, rt ankle_x000D__x000D_[CONCLUSION    ]_x000D_degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "degenerative change hallux valgus, both old fracture, Lt fibular tip soft tissue swelling, rt ankle degenerative change\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 19 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 117 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_Rt. 1st MTP joint, OA with erosion and soft tissue swelling\n",
      "  --> gout arthritis._x000D__x000D_[CONCLUSION    ]_x000D_Rt. 1st MTP joint, OA with erosion and soft tissue swelling\n",
      "  --> gout arthritis._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "Rt. 1st MTP joint, OA with erosion and soft tissue swelling --> gout arthritis.\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 179 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_No significant interval change_x000D__x000D_[CONCLUSION    ]_x000D_No significant interval change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "No significant interval change\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 185 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_OA, both feet._x000D__x000D_[CONCLUSION    ]_x000D_OA, both feet._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "OA, both feet.\n",
      "Generated Report : \n",
      "FINDINGS:\n",
      "\n",
      "--- Example 64 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      "FINDINGS:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    abnormal = ['ra', 'oa', 'gout']\n",
    "    normal = ['normal']\n",
    "    class_counts, data_by_class = count_labels(data, abnormal + normal, cfg)\n",
    "    combined = {\n",
    "        'abnormal': sum((data_by_class[c] for c in abnormal), []),\n",
    "        'normal': data_by_class['normal']\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': sum(class_counts[c] for c in abnormal),\n",
    "        'normal': class_counts['normal']\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced = []\n",
    "    final_counts = {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if len(target_classes) == 2 and 'abnormal' in target_classes and 'normal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset\n",
    "# =============================================================================\n",
    "\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2\n",
    "        self.abnormal_classify = self.is_binary and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {'ra': 'abnormal', 'oa': 'abnormal', 'gout': 'abnormal', 'normal': 'normal'}\n",
    "            if self.abnormal_classify else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        for i, (merged, fp, item) in enumerate(filtered):\n",
    "            cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                cls = self.abnormal_mapping.get(cls, cls)\n",
    "            self.data[i] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} {clean}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=511, return_tensors='pt')\n",
    "\n",
    "        if tok['input_ids'][0][-1] != self.tokenizer.eos_token_id:\n",
    "            input_ids = torch.cat([tok['input_ids'], torch.tensor([[self.tokenizer.eos_token_id]])], dim=1)\n",
    "            attention_mask = torch.cat([tok['attention_mask'], torch.tensor([[1]])], dim=1)\n",
    "        else:\n",
    "            input_ids = tok['input_ids']\n",
    "            attention_mask = tok['attention_mask']\n",
    "\n",
    "        input_ids = input_ids.squeeze(0)\n",
    "        attention_mask = attention_mask.squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img': img,\n",
    "            'patches': patches_tensor,\n",
    "            'raw_report': raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'): left = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left', 'right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side == 'left': left = lst\n",
    "                            else: right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p, 1) for p in left]\n",
    "        if right and not left:\n",
    "            left = [cv2.flip(p, 1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE | re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] stacked full_imgs shape: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] stacked patches shape: {patches.shape}\")\n",
    "\n",
    "    ids = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] padded input_ids shape: {ids.shape}, padded attention_mask shape: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs': imgs,\n",
    "        'patches': patches,\n",
    "        'input_ids': ids,\n",
    "        'attention_mask': masks,\n",
    "        'raw_reports': [b['raw_report'] for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model\n",
    "# =============================================================================\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2, 3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        # Global image\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        logging.info(f\"[Model] global_encoder output shape: {g_feats.shape}\")\n",
    "        g = self.global_proj(g_feats).unsqueeze(1)\n",
    "        logging.info(f\"[Model] global_proj + unsqueeze shape: {g.shape}\")\n",
    "\n",
    "        # Patch images\n",
    "        B, N, C, H, W = patches.shape\n",
    "        logging.info(f\"[Model] patches input shape: {patches.shape}\")\n",
    "        p = patches.view(B * N, C, H, W)\n",
    "        pf_feats = (self.patch_encoder.forward_features(p)\n",
    "                    if hasattr(self.patch_encoder, 'forward_features')\n",
    "                    else self.patch_encoder(p))\n",
    "        logging.info(f\"[Model] patch_encoder output shape: {pf_feats.shape}\")\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "        logging.info(f\"[Model] patch_proj + reshape shape: {pf.shape}\")\n",
    "\n",
    "        # Combine\n",
    "        cat = torch.cat([g, pf], dim=1)\n",
    "        logging.info(f\"[Model] concatenated features shape: {cat.shape}\")\n",
    "        comb, _ = self.attn(cat, cat, cat)\n",
    "        comb = self.norm(comb)\n",
    "        logging.info(f\"[Model] after attention & norm shape: {comb.shape}\")\n",
    "\n",
    "        # Decoder\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        logging.info(f\"[Model] decoder logits shape: {out.logits.shape}\")\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Train / Eval helpers\n",
    "# =============================================================================\n",
    "\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts = b['patches'].to(device)\n",
    "        ids = b['input_ids'].to(device)\n",
    "        msk = b['attention_mask'].to(device)\n",
    "\n",
    "        logging.info(f\"[Train] batch full_imgs {imgs.shape}, patches {pts.shape}, input_ids {ids.shape}, mask {msk.shape}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts = b['patches'].to(device)\n",
    "        ids = b['input_ids'].to(device)\n",
    "        msk = b['attention_mask'].to(device)\n",
    "\n",
    "        logging.info(f\"[Eval] batch full_imgs {imgs.shape}, patches {pts.shape}, input_ids {ids.shape}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # build the visual context reuse\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B, N, C, H, W = pts.shape\n",
    "            p = pts.view(B * N, C, H, W)\n",
    "            pf_feats = model.patch_encoder(p)\n",
    "            pf_pooled = model._pool(pf_feats)\n",
    "            pf = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat = torch.cat([g, pf], dim=1)\n",
    "            comb, _ = model.attn(cat, cat, cat)\n",
    "            comb = model.norm(comb)\n",
    "\n",
    "            # Prepare FINDINGS: prompt\n",
    "            prompt_ids = tokenizer(\n",
    "                \"FINDINGS:\",\n",
    "                return_tensors=\"pt\",\n",
    "                add_special_tokens=False\n",
    "            ).input_ids.to(device)              # (1, L)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)  # (B, L)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_ids = model.decoder.generate(\n",
    "                input_ids=prompt_ids,\n",
    "                attention_mask=prompt_mask,\n",
    "                encoder_hidden_states=comb,\n",
    "                encoder_attention_mask=torch.ones(B, comb.size(1), device=device),\n",
    "                max_length=150,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                temperature=0.7,\n",
    "                repetition_penalty=1.3,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            gen_txt = [tokenizer.decode(g_, skip_special_tokens=True) for g_ in gen_ids]\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt.extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1 = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2 = stm.encode(gt, convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Similarity\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Similarity\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW = True\n",
    "cfg.DATASET.USE_PATCH = True\n",
    "cfg.DATASET.REPORT = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['ra', 'oa', 'gout', 'normal', 'uncertain', 'ref.prev']\n",
    "cfg.DATASET.BALANCE = False\n",
    "cfg.DATASET.AUGMENT = False\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "logging.info(\"Dataset class distribution:\")\n",
    "for cls, cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = int(0.1 * n)\n",
    "n_test = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "num_epochs = 1\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logging.info(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    logging.info(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    logging.info(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    logging.info(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# Test evaluation\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "logging.info(\"\\n========== TEST RESULTS ==========\")\n",
    "logging.info(f\"Test Loss               : {test_loss:.4f}\")\n",
    "logging.info(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random test examples\n",
    "logging.info(\"\\n===== RANDOM TEST EXAMPLES =====\")\n",
    "for idx in random.sample(range(len(test_ds)), min(10, len(test_ds))):\n",
    "    ex = test_ds[idx]\n",
    "    raw = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    # Visual context\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B, N, C, H, W = pa.shape\n",
    "    p = pa.view(B * N, C, H, W)\n",
    "    pf_feats = model.patch_encoder(p)\n",
    "    pf_pooled = model._pool(pf_feats)\n",
    "    pf = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "    cat = torch.cat([g, pf], dim=1)\n",
    "    comb, _ = model.attn(cat, cat, cat)\n",
    "    comb = model.norm(comb)\n",
    "\n",
    "    # FINDINGS: prompt\n",
    "    prompt_ids = tokenizer(\n",
    "        \"FINDINGS:\",\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=False\n",
    "    ).input_ids.to(device)             # (1, L)\n",
    "    prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    logging.info(f\"\\n--- Example {idx} ---\")\n",
    "    logging.info(f\"Raw Report       : \\n{raw}\")\n",
    "    logging.info(f\"Cleaned Report   : \\n{clean}\")\n",
    "    logging.info(f\"Generated Report : \\n{gen}\")\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "227514db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9fd1cfa80441b4bf0662cf5d99ed4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e30f35e0a346b09357a5ce00344221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1713\n",
      "  Validation Loss     : 0.8442\n",
      "  Semantic Similarity : 0.4435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d86125673b5409b86df02a1ad52c85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550a708f102441ee83c7bd85f3cac475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.7300\n",
      "  Validation Loss     : 0.7557\n",
      "  Semantic Similarity : 0.4816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58488be2088847e599dd825ef36f70fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0f565c2eee45af932a03f117289c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.6344\n",
      "  Validation Loss     : 0.7205\n",
      "  Semantic Similarity : 0.4666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6512fe8a4b92409b9ec4cece26d41606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e372ccd3e2004f638d5bd5124097a812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.5757\n",
      "  Validation Loss     : 0.7080\n",
      "  Semantic Similarity : 0.4581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d60583517de47129fd35b06397f759c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5258c4333e4b9f8e0f278eb7ac2c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.5232\n",
      "  Validation Loss     : 0.7011\n",
      "  Semantic Similarity : 0.4660\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fda21adf1e74f089f12b1d5c194da04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db32a6456394f9db9b539acf05e6152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss               : 0.6444\n",
      "Test Semantic Similarity: 0.4657\n",
      "\n",
      "--- Example 104 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality. No bony abnormality.\n",
      "Generated Report : \n",
      "FINDINGS: Rt. 1st PP head, suspicious erosion --> gout arthritis cannot be excluded \n",
      "\n",
      "--- Example 164 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality. No bony abnormality.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality \n",
      "\n",
      "--- Example 20 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_no significant bony abnormality_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- no significant bony abnormality\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony abnormality \n",
      "\n",
      "--- Example 13 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant interval change since last study._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant interval change since last study._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant interval change since last study.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 32 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "small enthesophyte in plantar are in both calcaneus._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "small enthesophyte in plantar are in both calcaneus.\n",
      "Generated Report : \n",
      "FINDINGS: Rt. accessory navicular bone type II with OA Lt. 1st MTP joint, suspicious erosion --> gout arthritis \n",
      "\n",
      "--- Example 189 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "cervcial spondylosis._x000D_\n",
      "C5/6 disc sapce narrowing._x000D_\n",
      "_x000D_\n",
      "_x000D_\n",
      "Rt. elbow, lateral epicondyle, spur change._x000D_\n",
      "Lt. elobw, osteophyte with joint effusion_x000D_\n",
      "_x000D_\n",
      "Lt. hallux valgus._x000D_\n",
      "both accessory navicular bone, type II_x000D_\n",
      "both calcaneal spur._x000D_\n",
      "_x000D_\n",
      "minimal OA, both knee joints._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "cervcial spondylosis. C5/6 disc sapce narrowing. Rt. elbow, lateral epicondyle, spur change. Lt. elobw, osteophyte with joint effusion Lt. hallux valgus. both accessory navicular bone, type II both calcaneal spur. minimal OA, both knee joints.\n",
      "Generated Report : \n",
      "FINDINGS: both feet, RA involvement. \n",
      "\n",
      "--- Example 51 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "diffuse osteopenia_x000D_\n",
      "Lt. wrist, degenerative change._x000D_\n",
      "both ankle, degenerative change._x000D_\n",
      "both accessory navicular bone, type II_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "diffuse osteopenia_x000D_\n",
      "Lt. wrist, degenerative change._x000D_\n",
      "both ankle, degenerative change._x000D_\n",
      "both accessory navicular bone, type II_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "diffuse osteopenia Lt. wrist, degenerative change. both ankle, degenerative change. both accessory navicular bone, type II\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 235 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Accessory navicular bone, both._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Accessory navicular bone, both.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 217 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Rt. 3rd MTP joint space narrowing _x000D_\n",
      "_x000D_\n",
      "both hands, no significant interval change since last study._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Rt. 3rd MTP joint space narrowing _x000D_\n",
      "_x000D_\n",
      "both hands, no significant interval change since last study._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Rt. 3rd MTP joint space narrowing both hands, no significant interval change since last study.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 89 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions (unchanged)\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    abnormal = ['ra', 'oa', 'gout']\n",
    "    normal = ['normal']\n",
    "    class_counts, data_by_class = count_labels(data, abnormal + normal, cfg)\n",
    "    combined = {\n",
    "        'abnormal': sum((data_by_class[c] for c in abnormal), []),\n",
    "        'normal': data_by_class['normal']\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': sum(class_counts[c] for c in abnormal),\n",
    "        'normal': class_counts['normal']\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced = []\n",
    "    final_counts = {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if len(target_classes) == 2 and 'abnormal' in target_classes and 'normal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms (unchanged)\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2\n",
    "        self.abnormal_classify = self.is_binary and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {'ra': 'abnormal', 'oa': 'abnormal', 'gout': 'abnormal', 'normal': 'normal'}\n",
    "            if self.abnormal_classify else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        for i, (merged, fp, item) in enumerate(filtered):\n",
    "            cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                cls = self.abnormal_mapping.get(cls, cls)\n",
    "            self.data[i] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token  = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        # <<<— CHANGED: prepend FINDINGS: so the model learns to generate after it\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function (unchanged)\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition (unchanged)\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim>2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p     = patches.view(B*N, C, H, W)\n",
    "        pf_feats = (self.patch_encoder.forward_features(p)\n",
    "                    if hasattr(self.patch_encoder, 'forward_features')\n",
    "                    else self.patch_encoder(p))\n",
    "        pf_pooled= self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1), torch.cat([g,pf],1), torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops (mostly unchanged, except decode)\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context for generation\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p      = pts.view(B*N, C, H, W)\n",
    "            pf_feats = model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_  = model.attn(torch.cat([g,pf],1), torch.cat([g,pf],1), torch.cat([g,pf],1))\n",
    "            comb    = model.norm(cat)\n",
    "\n",
    "            # <<<— CHANGED: decode with FINDINGS: prefix\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_ids = model.decoder.generate(\n",
    "                input_ids=prompt_ids,\n",
    "                attention_mask=prompt_mask,\n",
    "                encoder_hidden_states=comb,\n",
    "                encoder_attention_mask=torch.ones(B, comb.size(1), device=device),\n",
    "                max_length=150,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                temperature=0.7,\n",
    "                repetition_penalty=1.3,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            gen_txt = [tokenizer.decode(g_, skip_special_tokens=True) for g_ in gen_ids]\n",
    "            gt_txt  = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt.extend(gt_txt)\n",
    "\n",
    "    return total_loss/len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt, convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON          = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW       = True\n",
    "cfg.DATASET.USE_PATCH     = True\n",
    "cfg.DATASET.REPORT        = True\n",
    "cfg.DATASET.TARGET_CLASSES= ['ra','oa','gout','normal','uncertain','ref.prev']\n",
    "cfg.DATASET.BALANCE      = False\n",
    "cfg.DATASET.AUGMENT      = False\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n        = len(dataset)\n",
    "n_train  = int(0.8 * n)\n",
    "n_val    = int(0.1 * n)\n",
    "n_test   = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model     = MultiModalModel().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    logging.info(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    #print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Sem Sim: {sem:.4f}\")\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# final test\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(10,len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    # visual context\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N,C,H,W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1), torch.cat([g,pf],1), torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    # <<<— CHANGED: generate after FINDINGS: prompt\n",
    "    prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce47ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 178 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "RA, both hands and feet with erosion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "RA, both hands and feet with erosion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "RA, both hands and feet with erosion.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 120 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "gout, both 1st MTP joints._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "gout, both 1st MTP joints._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "gout, both 1st MTP joints. gout, both 1st MTP joints.\n",
      "Generated Report : \n",
      "FINDINGS: both feet, no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 76 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "포함된 bone에 이상소견은 보이지 않음._x000D_\n",
      "보이는 한도내에 soft tissue에 이상소견 보이지 않음._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "bone . soft tissue . No bony abnormality\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 2 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality. No bony abnormality.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 151 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Mild OA in tibiotalar joints, both._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Mild OA in tibiotalar joints, both.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 52 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No significant interval change._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No significant interval change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No significant interval change. No significant interval change.\n",
      "Generated Report : \n",
      "FINDINGS: both 1st MTP joint, OA with suspicious gout arthritis. \n",
      "\n",
      "--- Example 53 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 128 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No significant abnormality._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No significant abnormality.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 172 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_mild degenerative change \n",
      "suspicious radiolucent lesion at Rt 1st metatarsal shaft \n",
      "- r/o benign lesion such as lipoma or simple bone cyst, more likely_x000D__x000D_[CONCLUSION    ]_x000D_mild degenerative change \n",
      "suspicious radiolucent lesion at Rt 1st metatarsal shaft \n",
      "- r/o benign lesion such as lipoma or simple bone cyst, more likely_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "mild degenerative change suspicious radiolucent lesion at Rt 1st metatarsal shaft - r/o benign lesion such as lipoma or simple bone cyst, more likely\n",
      "Generated Report : \n",
      "FINDINGS: both feet, RA involvement. \n",
      "\n",
      "--- Example 186 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "both knees, soft tissue swelling._x000D_\n",
      "_x000D_\n",
      "both hands, fingers, periarticular osteopenia._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both knees, soft tissue swelling. both hands, fingers, periarticular osteopenia.\n",
      "Generated Report : \n",
      "FINDINGS: both 1st MTP joint, R/O gout \n",
      "\n",
      "--- Example 225 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_soft tissue swelling, Lt 1st MTP joint \n",
      "suspicious erosion with tiny calcification, Rt 1st MTP joint_x000D__x000D_[CONCLUSION    ]_x000D_soft tissue swelling, Lt 1st MTP joint \n",
      "suspicious erosion with tiny calcification, Rt 1st MTP joint_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "soft tissue swelling, Lt 1st MTP joint suspicious erosion with tiny calcification, Rt 1st MTP joint\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion \n",
      "\n",
      "--- Example 236 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      "FINDINGS: Lt. 1st MTP joint, suspicious erosion and soft tissue swelling --> R/O gout \n",
      "\n",
      "--- Example 21 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 10 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both accessory navicular bone, type II_x000D_\n",
      "Lt. fiula and tibia, old fracture._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both accessory navicular bone, type II_x000D_\n",
      "Lt. fiula and tibia, old fracture._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both accessory navicular bone, type II Lt. fiula and tibia, old fracture.\n",
      "Generated Report : \n",
      "FINDINGS: both accessory navicular bone, type II with OA. \n",
      "\n",
      "--- Example 113 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "shortening, left 3rd distal phalanx._x000D_\n",
      "degenerative change._x000D_\n",
      "osteopenia._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "shortening, left 3rd distal phalanx._x000D_\n",
      "degenerative change._x000D_\n",
      "osteopenia._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "shortening, left 3rd distal phalanx. degenerative change. osteopenia.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 196 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 164 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality. No bony abnormality.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 116 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_joint space narrowing, erosions at both MTP joint \n",
      "erosions at Lt 1st IP joint \n",
      "-> probable inflammatory arthritis _x000D__x000D_[CONCLUSION    ]_x000D_joint space narrowing, erosions at both MTP joint \n",
      "erosions at Lt 1st IP joint \n",
      "-> probable inflammatory arthritis _x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "joint space narrowing, erosions at both MTP joint erosions at Lt 1st IP joint -> probable inflammatory arthritis\n",
      "Generated Report : \n",
      "FINDINGS: diffuse osteopenia degenerative change \n",
      "\n",
      "--- Example 193 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Calcification in soft tissue, bilateral 1st DP_x000D_\n",
      "Diffuse osteopenia_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Calcification in soft tissue, bilateral 1st DP_x000D_\n",
      "Diffuse osteopenia_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Calcification in soft tissue, bilateral 1st DP Diffuse osteopenia\n",
      "Generated Report : \n",
      "FINDINGS: both 1st MTP joint, OA with suspicious gout arthritis. \n",
      "\n",
      "--- Example 38 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_joint space narrowing with suspicious erosion at Rt 1st MTP joint \n",
      "-> r/o RA involvement_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- joint space narrowing with suspicious erosion at Rt 1st MTP joint -> r/o RA involvement\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change \n",
      "\n",
      "--- Example 179 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Rt. 1st PP intramedullary cystic lesion._x000D_\n",
      "  --> R/O gout._x000D_\n",
      "       bone tumor, less likely._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Rt. 1st PP intramedullary cystic lesion._x000D_\n",
      "  --> R/O gout._x000D_\n",
      "       bone tumor, less likely._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Rt. 1st PP intramedullary cystic lesion. --> R/O gout. bone tumor, less likely.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 161 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Osteoarthritis of both 1st MTP joints and both talonavicular joints._x000D_\n",
      "soft itssue swelling with multiple calcifications in lateral portion of both ankle._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Osteoarthritis of both 1st MTP joints and both talonavicular joints. soft itssue swelling with multiple calcifications in lateral portion of both ankle.\n",
      "Generated Report : \n",
      "FINDINGS: Rt. 1st PP, Lt., calcifications \n",
      "\n",
      "--- Example 122 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Hallux valgus, left foot._x000D_\n",
      "Possible large bone erosion with overhanging edge in medial aspect of left 1st metatarsal head._x000D_\n",
      " --- possible gouty arthritis._x000D_\n",
      " --- Rec) Clinical correlation._x000D_\n",
      "Suspicious fracture with partial callus formation of right lateral malleolus._x000D_\n",
      "--- with soft tissue swelling._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Hallux valgus, left foot. Possible large bone erosion with overhanging edge in medial aspect of left 1st metatarsal head. --- possible gouty arthritis. --- Rec) Clinical correlation. Suspicious fracture with partial callus formation of right lateral malleolus. --- with soft tissue swelling.\n",
      "Generated Report : \n",
      "FINDINGS: both ankle OA. \n",
      "\n",
      "--- Example 8 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "calcaneal spur, both._x000D_\n",
      "both ankle OA_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "calcaneal spur, both._x000D_\n",
      "both ankle OA_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "calcaneal spur, both. both ankle OA\n",
      "Generated Report : \n",
      "FINDINGS: mild degenerative change. \n",
      "\n",
      "--- Example 83 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_Rt. ankle soft tissue swelling._x000D__x000D_[CONCLUSION    ]_x000D_Rt. ankle soft tissue swelling._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "Rt. ankle soft tissue swelling.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 118 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "suspicious fracture, left 1st toe, distal phalanx with nonunion._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "suspicious fracture, left 1st toe, distal phalanx with nonunion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "suspicious fracture, left 1st toe, distal phalanx with nonunion. suspicious fracture, left 1st toe, distal phalanx with nonunion.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 124 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "minimal OA, both knee joints._x000D_\n",
      "_x000D_\n",
      "ulnar negative variance, both._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "minimal OA, both knee joints._x000D_\n",
      "_x000D_\n",
      "ulnar negative variance, both._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "minimal OA, both knee joints. ulnar negative variance, both.\n",
      "Generated Report : \n",
      "FINDINGS: both 1st MTP joint, OA with suspicious gout arthritis. \n",
      "\n",
      "--- Example 86 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality No bony abnormality\n",
      "Generated Report : \n",
      "FINDINGS: both feet, OA with suspicious gout arthritis. \n",
      "\n",
      "--- Example 146 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Rt. ankle soft tissue swelling._x000D_\n",
      "_x000D_\n",
      "both hallux valgus._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Rt. ankle soft tissue swelling. both hallux valgus.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 192 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "advanced RA, both hands and feet._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "advanced RA, both hands and feet._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "advanced RA, both hands and feet.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change \n"
     ]
    }
   ],
   "source": [
    "for idx in random.sample(range(len(test_ds)), min(30,len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    # visual context\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N,C,H,W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1), torch.cat([g,pf],1), torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    # <<<— CHANGED: generate after FINDINGS: prompt\n",
    "    prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4629d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 1, Epoch 1/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01058c8941641cc8c1eea4adc1de00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ec475a89764b31a8a77d312f443376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.7527\n",
      "  Validation Loss     : 1.2028\n",
      "  Semantic Similarity : 0.4955\n",
      "\n",
      "-- Phase 1, Epoch 2/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bfdd89c9d04ed3a065cae6c00e6a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f804ea5236514be6b8910ce761afb355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.3945\n",
      "  Validation Loss     : 1.1270\n",
      "  Semantic Similarity : 0.4768\n",
      "\n",
      "-- Phase 1, Epoch 3/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d635be66375b4782aaca8f00e0ca0e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf0d90bb82e40cd80bf5244e3f07426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.3699\n",
      "  Validation Loss     : 1.0924\n",
      "  Semantic Similarity : 0.4989\n",
      "\n",
      "-- Phase 1, Epoch 4/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f8ba5b117b44bfb7746c55a2ef5848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649820c1dd5f4bd288f0145909e7e10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.3138\n",
      "  Validation Loss     : 1.0620\n",
      "  Semantic Similarity : 0.5134\n",
      "\n",
      "-- Phase 1, Epoch 5/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5d1479c6d14141b227311e6788b13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9015418d2a244fbbea2d50c8dd0f04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2921\n",
      "  Validation Loss     : 1.0522\n",
      "  Semantic Similarity : 0.4837\n",
      "\n",
      "-- Phase 1, Epoch 6/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5181bdee17de476eac4da211c4f5e251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf752fe47ac42649af77d337ed2fbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2769\n",
      "  Validation Loss     : 1.0364\n",
      "  Semantic Similarity : 0.4958\n",
      "\n",
      "-- Phase 1, Epoch 7/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d824f30f34e45afbbc8322cb82eb916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64cd3afdb09546edb7fa7c056623ec1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2246\n",
      "  Validation Loss     : 1.0088\n",
      "  Semantic Similarity : 0.4933\n",
      "\n",
      "-- Phase 1, Epoch 8/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc09b0d91b2d4d3a81bd1a26b7298a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366a7ac3bc0748c8a7e5aa62ca042efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2136\n",
      "  Validation Loss     : 1.0011\n",
      "  Semantic Similarity : 0.4839\n",
      "\n",
      "-- Phase 1, Epoch 9/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60c5dee213349899cf9bfb38e73e6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5307a8fc56d14a8a98f6b904fbba7a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1884\n",
      "  Validation Loss     : 0.9858\n",
      "  Semantic Similarity : 0.5243\n",
      "\n",
      "-- Phase 1, Epoch 10/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b986588fba42ca96f76fe00653458a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824b066e5b8b4acbab6e0a9f772e1ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1949\n",
      "  Validation Loss     : 0.9880\n",
      "  Semantic Similarity : 0.5138\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 2, Epoch 1/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb51eb992f524b4bad8a791cbe6df996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44df2a02551d404faa14cab32ff5a5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1477\n",
      "  Validation Loss     : 0.9537\n",
      "  Semantic Similarity : 0.5210\n",
      "\n",
      "-- Phase 2, Epoch 2/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e14c1ed26f04c56bf743f70db50c9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6800d4100e074381aa630b940cc42829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1134\n",
      "  Validation Loss     : 0.9314\n",
      "  Semantic Similarity : 0.5011\n",
      "\n",
      "-- Phase 2, Epoch 3/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87956bf291d148b19986242386c18d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3326fa0f834002ab813519a50b43b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0890\n",
      "  Validation Loss     : 0.9142\n",
      "  Semantic Similarity : 0.5007\n",
      "\n",
      "-- Phase 2, Epoch 4/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97de6cf30dc547ef86f6e168bec6c0ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf51e7cd70045fbab0ee3c90ab72874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0664\n",
      "  Validation Loss     : 0.9048\n",
      "  Semantic Similarity : 0.5041\n",
      "\n",
      "-- Phase 2, Epoch 5/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a5ebbbb83d4fe19c04646a6eef5ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71957117369c4851b8d391de6fb4359b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0697\n",
      "  Validation Loss     : 0.9029\n",
      "  Semantic Similarity : 0.5106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b176996cbd6441fbbc0cf01d337ae132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91efc3cdf89a460ca30a47cdefbaffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss               : 1.0194\n",
      "Test Semantic Similarity: 0.5148\n",
      "\n",
      "--- Example 39 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality No bony abnormality\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 173 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_degenerative change\n",
      "\n",
      "both knee joint effusion.\n",
      "\n",
      "both wrist, joint space narrowing and suspicious erosion\n",
      "   --> R/O RA\n",
      "\n",
      "cervical spondylosis.\n",
      "disc space narrowing, C5/6 with both neural foraminal stenosis.\n",
      "cervical straightening._x000D__x000D_[CONCLUSION    ]_x000D_degenerative change\n",
      "\n",
      "both knee joint effusion.\n",
      "\n",
      "both wrist, joint space narrowing and suspicious erosion\n",
      "   --> R/O RA\n",
      "\n",
      "cervical spondylosis.\n",
      "disc space narrowing, C5/6 with both neural foraminal stenosis.\n",
      "cervical straightening._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "degenerative change both knee joint effusion. both wrist, joint space narrowing and suspicious erosion --> R/O RA cervical spondylosis. disc space narrowing, C5/6 with both neural foraminal stenosis. cervical straightening.\n",
      "Generated Report : \n",
      "FINDINGS: diffuse osteopenia degenerative change \n",
      "\n",
      "--- Example 45 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion. no bony lesion.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 75 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Both plantar calcaneal spur._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Both plantar calcaneal spur.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 144 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_osteophyte or ossification at lateral aspet of 1st MTP joint, both _x000D__x000D_[CONCLUSION    ]_x000D_osteophyte or ossification at lateral aspet of 1st MTP joint, both _x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "osteophyte or ossification at lateral aspet of 1st MTP joint, both\n",
      "Generated Report : \n",
      "FINDINGS: - diffuse osteopenia degenerative change \n",
      "\n",
      "--- Example 165 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change.\n",
      "Generated Report : \n",
      "FINDINGS: both feet, degenerative change. \n",
      "\n",
      "--- Example 103 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_Rt. hallux valgus and degenerative change.\n",
      "\n",
      "both talocalcaneal coalition, suspicious._x000D__x000D_[CONCLUSION    ]_x000D_Rt. hallux valgus and degenerative change.\n",
      "\n",
      "both talocalcaneal coalition, suspicious._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "Rt. hallux valgus and degenerative change. both talocalcaneal coalition, suspicious.\n",
      "Generated Report : \n",
      "FINDINGS: - diffuse osteopenia degenerative change \n",
      "\n",
      "--- Example 226 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Retrolisthesis, C4 on C5, C5 on C6_x000D_\n",
      "_x000D_\n",
      "Degenerative change_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Retrolisthesis, C4 on C5, C5 on C6_x000D_\n",
      "_x000D_\n",
      "Degenerative change_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Retrolisthesis, C4 on C5, C5 on C6 Degenerative change\n",
      "Generated Report : \n",
      "FINDINGS: No bony lesion on radiographs. \n",
      "\n",
      "--- Example 62 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No significant abnormality._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No significant abnormality.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 146 ---\n",
      "Raw Report       : \n",
      " 임시판독 결과 입니다 추후에 판독결과가 수정 될수 있으므로 확인 바랍니다._x000D_\n",
      "------------------------------------------------------------------------ _x000D_\n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Soft tissue swelling in both lateral malleous (Lt>Rt)._x000D_\n",
      "Enthesophyte in calcaneal tuberosity, both._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      ". ------------------------------------------------------------------------ Soft tissue swelling in both lateral malleous (Lt>Rt). Enthesophyte in calcaneal tuberosity, both.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions (unchanged)\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    abnormal = ['ra', 'oa', 'gout']\n",
    "    normal = ['normal']\n",
    "    class_counts, data_by_class = count_labels(data, abnormal + normal, cfg)\n",
    "    combined = {\n",
    "        'abnormal': sum((data_by_class[c] for c in abnormal), []),\n",
    "        'normal': data_by_class['normal']\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': sum(class_counts[c] for c in abnormal),\n",
    "        'normal': class_counts['normal']\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced = []\n",
    "    final_counts = {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if len(target_classes) == 2 and 'abnormal' in target_classes and 'normal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms (unchanged)\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (with FINDINGS: prefix in __getitem__)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2\n",
    "        self.abnormal_classify = self.is_binary and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {'ra': 'abnormal', 'oa': 'abnormal', 'gout': 'abnormal', 'normal': 'normal'}\n",
    "            if self.abnormal_classify else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        for i, (merged, fp, item) in enumerate(filtered):\n",
    "            cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                cls = self.abnormal_mapping.get(cls, cls)\n",
    "            self.data[i] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token  = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        # <<<— CHANGED: prepend FINDINGS: so model learns after it\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    # _gen_patches and _clean_report methods as before...\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function (unchanged)\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition (unchanged)\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim>2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p     = patches.view(B*N, C, H, W)\n",
    "        pf_feats = (self.patch_encoder.forward_features(p)\n",
    "                    if hasattr(self.patch_encoder, 'forward_features')\n",
    "                    else self.patch_encoder(p))\n",
    "        pf_pooled= self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops (unchanged decode with FINDINGS:)\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p      = pts.view(B*N, C, H, W)\n",
    "            pf_feats = model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1))\n",
    "            comb    = model.norm(cat)\n",
    "\n",
    "            # <<<— CHANGED: decode with FINDINGS: prefix\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_ids = model.decoder.generate(\n",
    "                input_ids=prompt_ids,\n",
    "                attention_mask=prompt_mask,\n",
    "                encoder_hidden_states=comb,\n",
    "                encoder_attention_mask=torch.ones(B, comb.size(1), device=device),\n",
    "                max_length=150,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                temperature=0.7,\n",
    "                repetition_penalty=1.3,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            gen_txt = [tokenizer.decode(g_, skip_special_tokens=True) for g_ in gen_ids]\n",
    "            gt_txt  = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss/len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: two‐phase training with freeze/unfreeze\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW        = True\n",
    "cfg.DATASET.USE_PATCH      = True\n",
    "cfg.DATASET.REPORT         = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['ra','oa','gout','normal','uncertain','ref.prev']\n",
    "cfg.DATASET.BALANCE        = False\n",
    "cfg.DATASET.AUGMENT        = False\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n       = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 1: freeze GPT-2 body, train only global_proj, patch_proj, cross-attn\n",
    "# =============================================================================\n",
    "for name, p in model.decoder.named_parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.global_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.patch_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "for name, p in model.decoder.named_parameters():\n",
    "    if \"crossattention\" in name.lower():\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda x: x.requires_grad, model.parameters()), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase1_epochs = 10\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\n-- Phase 1, Epoch {epoch+1}/{phase1_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2: unfreeze entire GPT-2, low‐LR fine‐tune\n",
    "# =============================================================================\n",
    "for p in model.decoder.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# rebuild optimizer for full fine-tune\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase2_epochs = 5\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\n-- Phase 2, Epoch {epoch+1}/{phase2_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# Final test\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(30, len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    # build visual context\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N, C, H, W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    # generate after FINDINGS: prompt\n",
    "    prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd68801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 1, Epoch 1/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f7e2cfce9a4cd1bc370404c503aa22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d98cc9d2ad4258b094a1f05e113c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.7461\n",
      "  Validation Loss     : 1.2250\n",
      "  Semantic Similarity : 0.4190\n",
      "\n",
      "-- Phase 1, Epoch 2/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f53e95146945b7b9c3d943b378f618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468b5903619643a08486435fb18a652f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.4226\n",
      "  Validation Loss     : 1.1668\n",
      "  Semantic Similarity : 0.4556\n",
      "\n",
      "-- Phase 1, Epoch 3/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d70d193b19415eaa73637c671b0af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2384568a9c944c159ce6d49b86fd15eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.3595\n",
      "  Validation Loss     : 1.1287\n",
      "  Semantic Similarity : 0.4982\n",
      "\n",
      "-- Phase 1, Epoch 4/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb76a064c2d54f2f992f3a9e052b6302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3e9a32b9ba402583843eae35878f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.3259\n",
      "  Validation Loss     : 1.1137\n",
      "  Semantic Similarity : 0.4877\n",
      "\n",
      "-- Phase 1, Epoch 5/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38cb689d6b344de920004ec5db78516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae7795d4fee4316a60de7fd167f42df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2957\n",
      "  Validation Loss     : 1.0972\n",
      "  Semantic Similarity : 0.4897\n",
      "\n",
      "-- Phase 1, Epoch 6/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae11aab526ab42c690bcd588aa22e8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330ab9f8e3e64a52858202aef38a359e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2688\n",
      "  Validation Loss     : 1.0910\n",
      "  Semantic Similarity : 0.4816\n",
      "\n",
      "-- Phase 1, Epoch 7/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8f9f02e2cf4559bc1df2091c1e3053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1430849f2aaa4879b3b54e8315fa5977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2414\n",
      "  Validation Loss     : 1.0791\n",
      "  Semantic Similarity : 0.5175\n",
      "\n",
      "-- Phase 1, Epoch 8/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0fd6718d074df8bd36f98da05a19ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a77ecf4d7a54c00892273989c7245f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2275\n",
      "  Validation Loss     : 1.0530\n",
      "  Semantic Similarity : 0.4974\n",
      "\n",
      "-- Phase 1, Epoch 9/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89289a661b94a56a13e9d2df19037d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35856a52973940ee8254496f4514c39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.2173\n",
      "  Validation Loss     : 1.0463\n",
      "  Semantic Similarity : 0.4946\n",
      "\n",
      "-- Phase 1, Epoch 10/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6483b91cd5b3403cb7ec4ce1e5f10c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674c664ab0c34d3d8264af06d740043b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1976\n",
      "  Validation Loss     : 1.0509\n",
      "  Semantic Similarity : 0.4931\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 2, Epoch 1/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b046d7af07468eaad6bd3ce11316d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b4c73963284ca6927f84b36a5e6f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1764\n",
      "  Validation Loss     : 1.0177\n",
      "  Semantic Similarity : 0.5187\n",
      "\n",
      "-- Phase 2, Epoch 2/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4600398a3eda437c8d1d886608816e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea2cc6ee9e243048c2752344b9e62b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1555\n",
      "  Validation Loss     : 0.9899\n",
      "  Semantic Similarity : 0.5128\n",
      "\n",
      "-- Phase 2, Epoch 3/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccffeebe41f142f0ad432d7c7373e8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7dfed42a9c04fe9803cbd47c0d8e964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1123\n",
      "  Validation Loss     : 0.9774\n",
      "  Semantic Similarity : 0.4998\n",
      "\n",
      "-- Phase 2, Epoch 4/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952df0333d5b4f158048b901195187e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd8108866c24a0b8aa8b33f411be869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0764\n",
      "  Validation Loss     : 0.9702\n",
      "  Semantic Similarity : 0.4785\n",
      "\n",
      "-- Phase 2, Epoch 5/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5728ed82d24d45befba280f63e8a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610457d7720c49469e41ea2e61b4a2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0716\n",
      "  Validation Loss     : 0.9673\n",
      "  Semantic Similarity : 0.5099\n",
      "\n",
      "-- Phase 2, Epoch 6/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a60fd56d0b74aca8d19e71ec882988b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb5ad0454cf45fe869f8b8ed3666460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0666\n",
      "  Validation Loss     : 0.9483\n",
      "  Semantic Similarity : 0.5267\n",
      "\n",
      "-- Phase 2, Epoch 7/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e2584cd1984490a1ecf7650cd295de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3902dce94aef479cba6dd65c3775801f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0359\n",
      "  Validation Loss     : 0.9281\n",
      "  Semantic Similarity : 0.4903\n",
      "\n",
      "-- Phase 2, Epoch 8/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de5185de9b3444e8355a2b417c150bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f793083889944838729872f040f7a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0172\n",
      "  Validation Loss     : 0.9158\n",
      "  Semantic Similarity : 0.5031\n",
      "\n",
      "-- Phase 2, Epoch 9/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0227c6048f154d8da584c2e839fa387b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31d3a4d8ed64f1db226fd6fb21fbb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.9963\n",
      "  Validation Loss     : 0.9078\n",
      "  Semantic Similarity : 0.4916\n",
      "\n",
      "-- Phase 2, Epoch 10/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0997293fc5a437a909cf839b3206e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8692e4239c44e48118afd79190425b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.9924\n",
      "  Validation Loss     : 0.9053\n",
      "  Semantic Similarity : 0.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abadceb96704519a89fcbad4bb7899a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17de9389d4143ecbc12ab44816fc915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss               : 0.9017\n",
      "Test Semantic Similarity: 0.5048\n",
      "\n",
      "--- Example 106 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "RA, both hands with erosions._x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "RA, both hands with erosions._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "RA, both hands with erosions. RA, both hands with erosions.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 110 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Rt. TMT joint space narrowing and erosion, suggestive of RA._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Rt. TMT joint space narrowing and erosion, suggestive of RA._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Rt. TMT joint space narrowing and erosion, suggestive of RA.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 210 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Within normal limit._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Within normal limit.\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 41 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_Lt. knee severe OA.\n",
      "Rt. knee moderate OA.\n",
      "both 5th MTP joint erosions.\n",
      "   --> RA involvement._x000D__x000D_[CONCLUSION    ]_x000D_Lt. knee severe OA.\n",
      "Rt. knee moderate OA.\n",
      "both 5th MTP joint erosions.\n",
      "   --> RA involvement._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "Lt. knee severe OA. Rt. knee moderate OA. both 5th MTP joint erosions. --> RA involvement.\n",
      "Generated Report : \n",
      "FINDINGS: - both hands and feet flat foot, diffuse osteopenia \n",
      "\n",
      "--- Example 57 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both ankle OA._x000D_\n",
      "both calcaneal spur change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both ankle OA._x000D_\n",
      "both calcaneal spur change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both ankle OA. both calcaneal spur change.\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 150 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "minimal OA, both knee joints._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "minimal OA, both knee joints._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "minimal OA, both knee joints. minimal OA, both knee joints.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 215 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 2 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_No significant interval change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- No significant interval change\n",
      "Generated Report : \n",
      "FINDINGS: mild degenerative change \n",
      "\n",
      "--- Example 43 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "suspicious erosive change, right big toe, sesamoid bone._x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "suspicious erosive change, right big toe, sesamoid bone._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "sesamoid view.\n",
      "Cleaned Report   : \n",
      "suspicious erosive change, right big toe, sesamoid bone. suspicious erosive change, right big toe, sesamoid bone.\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion on radiographs. \n",
      "\n",
      "--- Example 238 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_diffuse osteopenia.\n",
      "degenerative change\n",
      "calcaneo-naviculo-cuboidal coaltion, both.\n",
      "rec> CT\n",
      "\n",
      "both hands, degenerative change._x000D__x000D_[CONCLUSION    ]_x000D_diffuse osteopenia.\n",
      "degenerative change\n",
      "calcaneo-naviculo-cuboidal coaltion, both.\n",
      "rec> CT\n",
      "\n",
      "both hands, degenerative change._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "diffuse osteopenia. degenerative change calcaneo-naviculo-cuboidal coaltion, both. rec> CT both hands, degenerative change.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change \n",
      "\n",
      "--- Example 32 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 226 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both 1st MTP joint, gout arthritis._x000D_\n",
      "Calcification, Rt. 1st MTP medial side_x000D_\n",
      "Both hallux valgus_x000D_\n",
      "Lt. accessory navicula, type 1_x000D_\n",
      "Diffuse osteopenia_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both 1st MTP joint, gout arthritis._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both 1st MTP joint, gout arthritis. Calcification, Rt. 1st MTP medial side Both hallux valgus Lt. accessory navicula, type 1 Diffuse osteopenia both 1st MTP joint, gout arthritis.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 127 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_Diffuse osteopenia\n",
      "Degenerative change_x000D__x000D_[CONCLUSION    ]_x000D_Diffuse osteopenia\n",
      "Degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "Diffuse osteopenia Degenerative change\n",
      "Generated Report : \n",
      "FINDINGS: - No significant interval change \n",
      "\n",
      "--- Example 128 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Lt. talocalcaneal coalition._x000D_\n",
      "both 1st MTP joint, R/O gout._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Lt. talocalcaneal coalition._x000D_\n",
      "both 1st MTP joint, R/O gout._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Lt. talocalcaneal coalition. both 1st MTP joint, R/O gout.\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 144 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 202 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality \n",
      "\n",
      "--- Example 27 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "포함된 bone에 이상소견은 보이지 않음._x000D_\n",
      "보이는 한도내에 soft tissue에 이상소견 보이지 않음._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "bone . soft tissue . No bony abnormality\n",
      "Generated Report : \n",
      "FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 162 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both wrist RA_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both wrist RA_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both wrist RA\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 105 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "hallux valgus, both._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "hallux valgus, both._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "hallux valgus, both.\n",
      "Generated Report : \n",
      "FINDINGS: both feet, degenerative change. \n",
      "\n",
      "--- Example 182 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Interval progression of marginal erosion at LT. 2nd MT head_x000D_\n",
      "Both accessory navicula_x000D_\n",
      "Probable accessory ossicles, both 2nd and 5th MC haed_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Interval progression of marginal erosion at LT. 2nd MT head Both accessory navicula Probable accessory ossicles, both 2nd and 5th MC haed\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 165 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_degenerative change.\n",
      "diffuse osteopenia._x000D__x000D_[CONCLUSION    ]_x000D_degenerative change.\n",
      "diffuse osteopenia._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "degenerative change. diffuse osteopenia.\n",
      "Generated Report : \n",
      "FINDINGS: mild degenerative change \n",
      "\n",
      "--- Example 87 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "OA at both 1st MTP joint._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "OA at both 1st MTP joint.\n",
      "Generated Report : \n",
      "FINDINGS: no significant interval change since last study. \n",
      "\n",
      "--- Example 96 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both 1st MTP joint erosion_x000D_\n",
      "  --> gout arthritis._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both 1st MTP joint erosion_x000D_\n",
      "  --> gout arthritis._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both 1st MTP joint erosion --> gout arthritis.\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 120 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Os naviculare accessorium, type 3_x000D_\n",
      "Otherwise, no bony abnormalities_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Os naviculare accessorium, type 3 Otherwise, no bony abnormalities\n",
      "Generated Report : \n",
      "FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 100 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "r/o gout, right 1st MTP joint._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "r/o gout, right 1st MTP joint._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "r/o gout, right 1st MTP joint.\n",
      "Generated Report : \n",
      "FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 18 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_degenerative change_x000D__x000D_[CONCLUSION    ]_x000D_degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "degenerative change\n",
      "Generated Report : \n",
      "FINDINGS: - degenerative change \n",
      "\n",
      "--- Example 83 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "moderate OA, both knee joints._x000D_\n",
      "both foot, achilles tendon, enthesitis._x000D_\n",
      "LT. MTP joint, R/O bony erosion._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "moderate OA, both knee joints. both foot, achilles tendon, enthesitis. LT. MTP joint, R/O bony erosion.\n",
      "Generated Report : \n",
      "FINDINGS: No significant interval change since last study. \n",
      "\n",
      "--- Example 85 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_mild hallux valgus, both._x000D__x000D_[CONCLUSION    ]_x000D_mild hallux valgus, both._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "mild hallux valgus, both.\n",
      "Generated Report : \n",
      "FINDINGS: diffuse osteopenia degenerative change \n",
      "\n",
      "--- Example 132 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change of both feet._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change of both feet._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change of both feet.\n",
      "Generated Report : \n",
      "FINDINGS: No significant interval change since last study. \n",
      "\n",
      "--- Example 84 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      "FINDINGS: degenerative change. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions (unchanged)\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    abnormal = ['ra', 'oa', 'gout']\n",
    "    normal = ['normal']\n",
    "    class_counts, data_by_class = count_labels(data, abnormal + normal, cfg)\n",
    "    combined = {\n",
    "        'abnormal': sum((data_by_class[c] for c in abnormal), []),\n",
    "        'normal': data_by_class['normal']\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': sum(class_counts[c] for c in abnormal),\n",
    "        'normal': class_counts['normal']\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced = []\n",
    "    final_counts = {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if len(target_classes) == 2 and 'abnormal' in target_classes and 'normal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms (unchanged)\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (with FINDINGS: prefix in __getitem__)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2\n",
    "        self.abnormal_classify = self.is_binary and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {'ra': 'abnormal', 'oa': 'abnormal', 'gout': 'abnormal', 'normal': 'normal'}\n",
    "            if self.abnormal_classify else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        for i, (merged, fp, item) in enumerate(filtered):\n",
    "            cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                cls = self.abnormal_mapping.get(cls, cls)\n",
    "            self.data[i] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token  = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        # <<<— CHANGED: prepend FINDINGS: so model learns after it\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    # _gen_patches and _clean_report methods as before...\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function (unchanged)\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition (unchanged)\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim>2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p     = patches.view(B*N, C, H, W)\n",
    "        pf_feats = (self.patch_encoder.forward_features(p)\n",
    "                    if hasattr(self.patch_encoder, 'forward_features')\n",
    "                    else self.patch_encoder(p))\n",
    "        pf_pooled= self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops (unchanged decode with FINDINGS:)\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p      = pts.view(B*N, C, H, W)\n",
    "            pf_feats = model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1))\n",
    "            comb    = model.norm(cat)\n",
    "\n",
    "            # <<<— CHANGED: decode with FINDINGS: prefix\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_ids = model.decoder.generate(\n",
    "                input_ids=prompt_ids,\n",
    "                attention_mask=prompt_mask,\n",
    "                encoder_hidden_states=comb,\n",
    "                encoder_attention_mask=torch.ones(B, comb.size(1), device=device),\n",
    "                max_length=150,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                temperature=0.7,\n",
    "                repetition_penalty=1.3,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            gen_txt = [tokenizer.decode(g_, skip_special_tokens=True) for g_ in gen_ids]\n",
    "            gt_txt  = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss/len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: two‐phase training with freeze/unfreeze\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW        = True\n",
    "cfg.DATASET.USE_PATCH      = True\n",
    "cfg.DATASET.REPORT         = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['ra','oa','gout','normal','uncertain','ref.prev']\n",
    "cfg.DATASET.BALANCE        = False\n",
    "cfg.DATASET.AUGMENT        = False\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n       = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 1: freeze GPT-2 body, train only global_proj, patch_proj, cross-attn\n",
    "# =============================================================================\n",
    "for name, p in model.decoder.named_parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.global_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.patch_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "for name, p in model.decoder.named_parameters():\n",
    "    if \"crossattention\" in name.lower():\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda x: x.requires_grad, model.parameters()), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase1_epochs = 10\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\n-- Phase 1, Epoch {epoch+1}/{phase1_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2: unfreeze entire GPT-2, low‐LR fine‐tune\n",
    "# =============================================================================\n",
    "for p in model.decoder.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# rebuild optimizer for full fine-tune\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase2_epochs = 10\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\n-- Phase 2, Epoch {epoch+1}/{phase2_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# Final test\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(30, len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    # build visual context\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N, C, H, W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    # generate after FINDINGS: prompt\n",
    "    prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6b7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8383a871",
   "metadata": {},
   "source": [
    "## Abnormal vs Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830622e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting dataset: 100%|██████████| 1714/1714 [00:00<00:00, 708978.01it/s]\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 1, Epoch 1/2 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e9b081466e4967ae614baf5e345536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f362330d7d004655a7290711cf131096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.4965\n",
      "  Validation Loss     : 1.0576\n",
      "  Semantic Similarity : 0.5293\n",
      "\n",
      "-- Phase 1, Epoch 2/2 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 517\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(phase1_epochs):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Phase 1, Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mphase1_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 517\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m     val_loss, gen_txt, gt_txt \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[1;32m    519\u001b[0m     sem \u001b[38;5;241m=\u001b[39m compute_semantic_similarity(gen_txt, gt_txt)\n",
      "Cell \u001b[0;32mIn[5], line 373\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, scaler, device)\u001b[0m\n\u001b[1;32m    371\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    372\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m--> 373\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_imgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatches\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[5], line 188\u001b[0m, in \u001b[0;36mFinalSamplesDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    187\u001b[0m     e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m--> 188\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_transform(img)\n\u001b[1;32m    190\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Dataset] full_img shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/PIL/Image.py:984\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    # Only use the 'abnormal' vs 'normal' labels\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue  # drop uncertain, ref.prev, etc.\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        # balance & augment if binary\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p     = patches.view(B*N, C, H, W)\n",
    "        pf_feats = (self.patch_encoder.forward_features(p)\n",
    "                    if hasattr(self.patch_encoder, 'forward_features')\n",
    "                    else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf         = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p      = pts.view(B*N, C, H, W)\n",
    "            pf_feats = model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1))\n",
    "            comb    = model.norm(cat)\n",
    "\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_ids = model.decoder.generate(\n",
    "                input_ids=prompt_ids,\n",
    "                attention_mask=prompt_mask,\n",
    "                encoder_hidden_states=comb,\n",
    "                encoder_attention_mask=torch.ones(B, comb.size(1), device=device),\n",
    "                max_length=150,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                temperature=0.7,\n",
    "                repetition_penalty=1.3,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            gen_txt = [tokenizer.decode(g_, skip_special_tokens=True) for g_ in gen_ids]\n",
    "            gt_txt  = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: two‐phase training with early cross‐attention unfreeze\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW        = True\n",
    "cfg.DATASET.USE_PATCH      = True\n",
    "cfg.DATASET.REPORT         = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "cfg.DATASET.BALANCE        = True\n",
    "cfg.DATASET.AUGMENT        = True\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n       = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 1: freeze everything except cross-attn + projection heads\n",
    "# =============================================================================\n",
    "for name, p in model.decoder.named_parameters():\n",
    "    p.requires_grad = (\"crossattention\" in name.lower())\n",
    "for p in model.global_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.patch_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda x: x.requires_grad, model.parameters()), lr=5e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase1_epochs = 2\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\n-- Phase 1, Epoch {epoch+1}/{phase1_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2: unfreeze entire GPT-2, low‐LR fine‐tune\n",
    "# =============================================================================\n",
    "for p in model.decoder.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase2_epochs = 2\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\n-- Phase 2, Epoch {epoch+1}/{phase2_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# Final test\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(30, len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N, C, H, W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask= torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b2b3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting dataset: 100%|██████████| 1714/1714 [00:00<00:00, 670681.69it/s]\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 1, Epoch 1/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a5fe22736f4a5bbfa10ef6714a7628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a0414ed991442fbb47127b6ba31bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.4165\n",
      "  Validation Loss     : 1.0961\n",
      "  Semantic Similarity : 0.5341\n",
      "\n",
      "-- Phase 1, Epoch 2/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1991b0ee0a194698b6b3c50f21d5c744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe09d581543f41eca482c033b6b0dbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1184\n",
      "  Validation Loss     : 0.8544\n",
      "  Semantic Similarity : 0.4822\n",
      "\n",
      "-- Phase 1, Epoch 3/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b3f3cfc4d64c91a344e76055530f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60f6944a7884808b313110c49f44e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.8216\n",
      "  Validation Loss     : 0.7127\n",
      "  Semantic Similarity : 0.4871\n",
      "\n",
      "-- Phase 1, Epoch 4/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344065b116a74ef9a48840da817ca25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e455a95e6f49c583d4fbf6e8e13aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.7021\n",
      "  Validation Loss     : 0.6584\n",
      "  Semantic Similarity : 0.4968\n",
      "\n",
      "-- Phase 1, Epoch 5/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cebf1f79a7549fabbc445fa10061d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93398900f1a54e2490a63d34a58c9912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.6420\n",
      "  Validation Loss     : 0.6210\n",
      "  Semantic Similarity : 0.5100\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 2, Epoch 1/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db7620f04b04f399aa2693bc291c660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37eb5f2f55344df788acf06c05409024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.5842\n",
      "  Validation Loss     : 0.5801\n",
      "  Semantic Similarity : 0.5092\n",
      "\n",
      "-- Phase 2, Epoch 2/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d240c18a2440a8b05f90e1b27d54cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d844ce5024b759d6741e72481e824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.5643\n",
      "  Validation Loss     : 0.5726\n",
      "  Semantic Similarity : 0.5247\n",
      "\n",
      "-- Phase 2, Epoch 3/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf402b3ef494fc7b45e61af310fef67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d0d1cfc1834e1e9251ee711f407b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.5542\n",
      "  Validation Loss     : 0.5692\n",
      "  Semantic Similarity : 0.5233\n",
      "\n",
      "-- Phase 2, Epoch 4/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471daacd144247fe800df575bf9374ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f85ac7a6b7456986818446aceb95d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.5500\n",
      "  Validation Loss     : 0.5628\n",
      "  Semantic Similarity : 0.5289\n",
      "\n",
      "-- Phase 2, Epoch 5/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac49fc14fd04a24b656336bb2355bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0115a5d00444f3ac09946b15471ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.5466\n",
      "  Validation Loss     : 0.5655\n",
      "  Semantic Similarity : 0.5380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c132e0a3752443787118ea44dcc0024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533fdbc25f9e4ebf82a9a60def0c5ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss               : 0.6106\n",
      "Test Semantic Similarity: 0.5149\n",
      "\n",
      "--- Example 212 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Soft tissue swelling in medial aspect of left 1st MTP joint level._x000D_\n",
      "No evidence of bone erosion._x000D_\n",
      "Enthesophyte in plantar aspect of right calcaneus._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Soft tissue swelling in medial aspect of left 1st MTP joint level. No evidence of bone erosion. Enthesophyte in plantar aspect of right calcaneus.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 48 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      " FINDINGS: both feet, OA. \n",
      "\n",
      "--- Example 160 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "accessory navicular bones, both, type 1._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "accessory navicular bones, both, type 1.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 218 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "No bony abnormalities._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormalities.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 130 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "advanced RA, both hands and feet._x000D_\n",
      "s/p PVP, L2-5._x000D_\n",
      "multiple old compression fracture, T-L spines._x000D_\n",
      "degenerative change._x000D_\n",
      "osteopenia._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "advanced RA, both hands and feet._x000D_\n",
      "s/p PVP, L2-5._x000D_\n",
      "multiple old compression fracture, T-L spines._x000D_\n",
      "degenerative change._x000D_\n",
      "osteopenia._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "advanced RA, both hands and feet. s/p PVP, L2-5. multiple old compression fracture, T-L spines. degenerative change. osteopenia.\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony abnormality \n",
      "\n",
      "--- Example 191 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 78 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Os peroneum, both_x000D_\n",
      "Haglund deformity, both_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Os peroneum, both Haglund deformity, both\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 242 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "minimal OA, both knee joints._x000D_\n",
      "_x000D_\n",
      "otherwise no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "minimal OA, both knee joints._x000D_\n",
      "_x000D_\n",
      "otherwise no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "minimal OA, both knee joints. otherwise no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 34 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_No significant interval change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- No significant interval change\n",
      "Generated Report : \n",
      " FINDINGS: No significant interval change \n",
      "\n",
      "--- Example 46 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "os naviculare, both(right type 2, left 3)_x000D_\n",
      "degenerative change_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "os naviculare, both(right type 2, left 3)_x000D_\n",
      "degenerative change_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "os naviculare, both(right type 2, left 3) degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 43 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_no significant bony abnormality_x000D__x000D_[CONCLUSION    ]_x000D_no significant bony abnormality_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "no significant bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 47 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_no significant interval change since last study._x000D__x000D_[CONCLUSION    ]_x000D_no significant interval change since last study._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "no significant interval change since last study.\n",
      "Generated Report : \n",
      " FINDINGS: - no significant interval change since last study. \n",
      "\n",
      "--- Example 221 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 49 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_no significant bony abnormality_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- no significant bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 190 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_diffuse osteopenia\n",
      "degenerative change_x000D__x000D_[CONCLUSION    ]_x000D_diffuse osteopenia\n",
      "degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "diffuse osteopenia degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 66 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No significant abnormality._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No significant abnormality.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 284 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_no significant bony lesion on radiographs._x000D__x000D_[CONCLUSION    ]_x000D_no significant bony lesion on radiographs._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony abnormality \n",
      "\n",
      "--- Example 30 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 287 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Hallux valgus deformity, right._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Hallux valgus deformity, right.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 168 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "probable gout, right big toe._x000D_\n",
      "os naviculare type III._x000D_\n",
      "osteonecrosis, right medial sesamoid bone._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "probable gout, right big toe._x000D_\n",
      "os naviculare type III._x000D_\n",
      "osteonecrosis, right medial sesamoid bone._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "probable gout, right big toe. os naviculare type III. osteonecrosis, right medial sesamoid bone.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 62 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Lt. 5th MTP joint bony erosion._x000D_\n",
      "  --> R/O RA_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Lt. 5th MTP joint bony erosion._x000D_\n",
      "  --> R/O RA_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Lt. 5th MTP joint bony erosion. --> R/O RA\n",
      "Generated Report : \n",
      " FINDINGS: diffuse osteopenia degenerative change. \n",
      "\n",
      "--- Example 210 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change of both feet._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change of both feet._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change of both feet.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 181 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_diffuse osteopenia\n",
      "degenerative change_x000D__x000D_[CONCLUSION    ]_x000D_diffuse osteopenia\n",
      "degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "diffuse osteopenia degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: diffuse osteopenia degenerative change \n",
      "\n",
      "--- Example 216 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "possible gout, left big toe._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "possible gout, left big toe._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "possible gout, left big toe.\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. \n",
      "\n",
      "--- Example 26 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 147 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_soft tissue swelling around Rt 1st MTP joint \n",
      "suspicious erosion, Rt 1st MT head \n",
      "-> r/o gout_x000D__x000D_[CONCLUSION    ]_x000D_soft tissue swelling around Rt 1st MTP joint \n",
      "suspicious erosion, Rt 1st MT head \n",
      "-> r/o gout_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "soft tissue swelling around Rt 1st MTP joint suspicious erosion, Rt 1st MT head -> r/o gout\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 159 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_no significant bony abnormality_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- no significant bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 180 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "os naviculare type 1, both feet._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "os naviculare type 1, both feet._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "os naviculare type 1, both feet. os naviculare type 1, both feet.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 53 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both ankle OA._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both ankle OA._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both ankle OA.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 295 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_flat foot, both._x000D__x000D_[CONCLUSION    ]_x000D_flat foot, both._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "flat foot, both.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p         = patches.view(B*N, C, H, W)\n",
    "        pf_feats  = (self.patch_encoder.forward_features(p)\n",
    "                     if hasattr(self.patch_encoder, 'forward_features')\n",
    "                     else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p       = pts.view(B*N, C, H, W)\n",
    "            pf_feats= model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_   = model.attn(torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1))\n",
    "            comb     = model.norm(cat)\n",
    "\n",
    "            # per-sample generation to avoid size mismatch\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_txt = []\n",
    "            for i in range(B):\n",
    "                inp = prompt_ids[i:i+1]\n",
    "                m   = prompt_mask[i:i+1]\n",
    "                enc = comb[i:i+1]\n",
    "                enc_attn = torch.ones(1, enc.size(1), device=device)\n",
    "                out_ids = model.decoder.generate(\n",
    "                    input_ids=inp,\n",
    "                    attention_mask=m,\n",
    "                    encoder_hidden_states=enc,\n",
    "                    encoder_attention_mask=enc_attn,\n",
    "                    max_length=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.9,\n",
    "                    temperature=0.7,\n",
    "                    repetition_penalty=1.3,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                gen_txt.append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: two‐phase training with early cross‐attention unfreeze and frozen encoders\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW        = True\n",
    "cfg.DATASET.USE_PATCH      = True\n",
    "cfg.DATASET.REPORT         = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "cfg.DATASET.BALANCE        = True\n",
    "cfg.DATASET.AUGMENT        = True\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n       = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# Freeze vision backbones\n",
    "# =============================================================================\n",
    "for p in model.global_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 1: freeze everything except cross-attn + projection heads\n",
    "# =============================================================================\n",
    "for name, p in model.decoder.named_parameters():\n",
    "    p.requires_grad = (\"crossattention\" in name.lower())\n",
    "for p in model.global_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.patch_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda x: x.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase1_epochs = 5\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\n-- Phase 1, Epoch {epoch+1}/{phase1_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2: unfreeze entire GPT-2, low‐LR fine‐tune\n",
    "# =============================================================================\n",
    "for p in model.decoder.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase2_epochs = 5\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\n-- Phase 2, Epoch {epoch+1}/{phase2_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# Final test\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(30, len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N, C, H, W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    prompt_text = f\"{tokenizer.bos_token} FINDINGS:\"\n",
    "    prompt_ids  = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bcf5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2574ef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 12:09:58.824293: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-15 12:09:58.830974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747336198.838715  103426 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747336198.841015  103426 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747336198.847007  103426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747336198.847014  103426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747336198.847015  103426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747336198.847015  103426 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-15 12:09:58.849134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Counting dataset: 100%|██████████| 1714/1714 [00:00<00:00, 673256.89it/s]\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2-medium and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.12.crossattention.c_attn.bias', 'h.12.crossattention.c_attn.weight', 'h.12.crossattention.c_proj.bias', 'h.12.crossattention.c_proj.weight', 'h.12.crossattention.q_attn.bias', 'h.12.crossattention.q_attn.weight', 'h.12.ln_cross_attn.bias', 'h.12.ln_cross_attn.weight', 'h.13.crossattention.c_attn.bias', 'h.13.crossattention.c_attn.weight', 'h.13.crossattention.c_proj.bias', 'h.13.crossattention.c_proj.weight', 'h.13.crossattention.q_attn.bias', 'h.13.crossattention.q_attn.weight', 'h.13.ln_cross_attn.bias', 'h.13.ln_cross_attn.weight', 'h.14.crossattention.c_attn.bias', 'h.14.crossattention.c_attn.weight', 'h.14.crossattention.c_proj.bias', 'h.14.crossattention.c_proj.weight', 'h.14.crossattention.q_attn.bias', 'h.14.crossattention.q_attn.weight', 'h.14.ln_cross_attn.bias', 'h.14.ln_cross_attn.weight', 'h.15.crossattention.c_attn.bias', 'h.15.crossattention.c_attn.weight', 'h.15.crossattention.c_proj.bias', 'h.15.crossattention.c_proj.weight', 'h.15.crossattention.q_attn.bias', 'h.15.crossattention.q_attn.weight', 'h.15.ln_cross_attn.bias', 'h.15.ln_cross_attn.weight', 'h.16.crossattention.c_attn.bias', 'h.16.crossattention.c_attn.weight', 'h.16.crossattention.c_proj.bias', 'h.16.crossattention.c_proj.weight', 'h.16.crossattention.q_attn.bias', 'h.16.crossattention.q_attn.weight', 'h.16.ln_cross_attn.bias', 'h.16.ln_cross_attn.weight', 'h.17.crossattention.c_attn.bias', 'h.17.crossattention.c_attn.weight', 'h.17.crossattention.c_proj.bias', 'h.17.crossattention.c_proj.weight', 'h.17.crossattention.q_attn.bias', 'h.17.crossattention.q_attn.weight', 'h.17.ln_cross_attn.bias', 'h.17.ln_cross_attn.weight', 'h.18.crossattention.c_attn.bias', 'h.18.crossattention.c_attn.weight', 'h.18.crossattention.c_proj.bias', 'h.18.crossattention.c_proj.weight', 'h.18.crossattention.q_attn.bias', 'h.18.crossattention.q_attn.weight', 'h.18.ln_cross_attn.bias', 'h.18.ln_cross_attn.weight', 'h.19.crossattention.c_attn.bias', 'h.19.crossattention.c_attn.weight', 'h.19.crossattention.c_proj.bias', 'h.19.crossattention.c_proj.weight', 'h.19.crossattention.q_attn.bias', 'h.19.crossattention.q_attn.weight', 'h.19.ln_cross_attn.bias', 'h.19.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.20.crossattention.c_attn.bias', 'h.20.crossattention.c_attn.weight', 'h.20.crossattention.c_proj.bias', 'h.20.crossattention.c_proj.weight', 'h.20.crossattention.q_attn.bias', 'h.20.crossattention.q_attn.weight', 'h.20.ln_cross_attn.bias', 'h.20.ln_cross_attn.weight', 'h.21.crossattention.c_attn.bias', 'h.21.crossattention.c_attn.weight', 'h.21.crossattention.c_proj.bias', 'h.21.crossattention.c_proj.weight', 'h.21.crossattention.q_attn.bias', 'h.21.crossattention.q_attn.weight', 'h.21.ln_cross_attn.bias', 'h.21.ln_cross_attn.weight', 'h.22.crossattention.c_attn.bias', 'h.22.crossattention.c_attn.weight', 'h.22.crossattention.c_proj.bias', 'h.22.crossattention.c_proj.weight', 'h.22.crossattention.q_attn.bias', 'h.22.crossattention.q_attn.weight', 'h.22.ln_cross_attn.bias', 'h.22.ln_cross_attn.weight', 'h.23.crossattention.c_attn.bias', 'h.23.crossattention.c_attn.weight', 'h.23.crossattention.c_proj.bias', 'h.23.crossattention.c_proj.weight', 'h.23.crossattention.q_attn.bias', 'h.23.crossattention.q_attn.weight', 'h.23.ln_cross_attn.bias', 'h.23.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Epoch 1/1 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9c22a6360c4dc89519a9c1ef977c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f5b73bdc1742439ede5d7cbcb2c287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : nan\n",
      "  Validation Loss     : nan\n",
      "  Semantic Similarity : 0.0901\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 608\u001b[0m\n\u001b[1;32m    605\u001b[0m plot_metrics(train_losses, val_losses, sems)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;66;03m# Final test evaluation\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m test_loss, test_gen, test_gt \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m test_sem \u001b[38;5;241m=\u001b[39m compute_semantic_similarity(test_gen, test_gt)\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m========== TEST RESULTS ==========\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 465\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, loader, device)\u001b[0m\n\u001b[1;32m    462\u001b[0m     enc_attn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, enc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdecoder_dtype)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# Change to greedy decoding to avoid multinomial sampling issues\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m     out_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use greedy decoding instead of sampling\u001b[39;49;00m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     gen_txt\u001b[38;5;241m.\u001b[39mappend(tokenizer\u001b[38;5;241m.\u001b[39mdecode(out_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    477\u001b[0m gt_txt \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mdecode(i_, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i_ \u001b[38;5;129;01min\u001b[39;00m ids]\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/transformers/generation/utils.py:2255\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2247\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2248\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2249\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2250\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2251\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2252\u001b[0m     )\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2255\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2256\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2258\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2268\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2269\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2274\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2275\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/transformers/generation/utils.py:3257\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3259\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3260\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3261\u001b[0m     outputs,\n\u001b[1;32m   3262\u001b[0m     model_kwargs,\n\u001b[1;32m   3263\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3264\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1061\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1061\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:922\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    910\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    911\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    912\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m         output_attentions,\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:441\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    439\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    440\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 441\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[1;32m    443\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:370\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    368\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(hidden_states)\n\u001b[1;32m    369\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(hidden_states)\n\u001b[0;32m--> 370\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_proj\u001b[49m(hidden_states)\n\u001b[1;32m    371\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "\n",
    "# pip install transformers bitsandbytes accelerate sentence-transformers\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import bitsandbytes as bnb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Global tokenizer (for collate_fn and evaluation)\n",
    "# =============================================================================\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
    "tokenizer.bos_token    = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token    = tokenizer.eos_token\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition: GPT2-medium quantized with projection layer\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2-medium'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "        \n",
    "        # Cross projection layer to match GPT-2's hidden dimension\n",
    "        self.cross_proj     = nn.Linear(768, 1024)\n",
    "\n",
    "        # Load GPT-2 without float16 to avoid precision issues\n",
    "        self.decoder = GPT2LMHeadModel.from_pretrained(\n",
    "            gpt2_model_name,\n",
    "            add_cross_attention=True,\n",
    "            load_in_8bit=True,\n",
    "            device_map='auto',\n",
    "            _fast_init=False\n",
    "        )\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p         = patches.view(B*N, C, H, W)\n",
    "        pf_feats  = (self.patch_encoder.forward_features(p)\n",
    "                    if hasattr(self.patch_encoder, 'forward_features')\n",
    "                    else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "        \n",
    "        # Project to match GPT-2's hidden dimension\n",
    "        comb_proj = self.cross_proj(comb)\n",
    "        \n",
    "        # Convert encoder outputs to match decoder's dtype\n",
    "        decoder_dtype = next(p for p in self.decoder.parameters() if p.dtype.is_floating_point).dtype\n",
    "        comb_proj = comb_proj.to(decoder_dtype)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb_proj,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops (simplified to avoid precision issues)\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass - regular precision\n",
    "        out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "        loss = out.loss\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p        = pts.view(B*N, C, H, W)\n",
    "            pf_feats = (model.patch_encoder.forward_features(p)\n",
    "                        if hasattr(model.patch_encoder, 'forward_features')\n",
    "                        else model.patch_encoder(p))\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_   = model.attn(torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1))\n",
    "            comb    = model.norm(cat)\n",
    "            comb_proj = model.cross_proj(comb)\n",
    "            \n",
    "            # Add these two lines here, before the generation loop\n",
    "            decoder_dtype = next(p for p in model.decoder.parameters() if p.dtype.is_floating_point).dtype\n",
    "            comb_proj = comb_proj.to(decoder_dtype)\n",
    "\n",
    "            # per-sample generation\n",
    "            prompt_ids  = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids  = prompt_ids.expand(B, -1)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_txt = []\n",
    "            for i in range(B):\n",
    "                inp = prompt_ids[i:i+1]\n",
    "                m = prompt_mask[i:i+1]\n",
    "                enc = comb_proj[i:i+1]  # Use projected features\n",
    "                \n",
    "                # Convert attention mask to the same dtype as the model parameters\n",
    "                decoder_dtype = next(p for p in model.decoder.parameters() if p.dtype.is_floating_point).dtype\n",
    "                enc = enc.to(decoder_dtype)\n",
    "                enc_attn = torch.ones(1, enc.size(1), device=device, dtype=decoder_dtype)\n",
    "                \n",
    "                # Change to greedy decoding to avoid multinomial sampling issues\n",
    "                out_ids = model.decoder.generate(\n",
    "                    input_ids=inp,\n",
    "                    attention_mask=m,\n",
    "                    encoder_hidden_states=enc,\n",
    "                    encoder_attention_mask=enc_attn,\n",
    "                    max_length=150,\n",
    "                    do_sample=False,  # Use greedy decoding instead of sampling\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                gen_txt.append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN SCRIPT (simplified to a single training phase)\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Set CUDA_LAUNCH_BLOCKING for better error messages\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "    \n",
    "    # Configuration\n",
    "    class Cfg: pass\n",
    "    cfg = Cfg()\n",
    "    cfg.DATASET = Cfg()\n",
    "    cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "    cfg.DATASET.USE_RAW        = True\n",
    "    cfg.DATASET.USE_PATCH      = True\n",
    "    cfg.DATASET.REPORT         = True\n",
    "    cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "    cfg.DATASET.BALANCE        = True\n",
    "    cfg.DATASET.AUGMENT        = False\n",
    "\n",
    "    # Device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logging.info(f\"Using device: {device}\")\n",
    "\n",
    "    # Dataset & tokenizer hookup\n",
    "    dataset = FinalSamplesDataset(cfg)\n",
    "    dataset.tokenizer = tokenizer\n",
    "    dataset.eos_token = tokenizer.eos_token\n",
    "\n",
    "    dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "    for cls, cnt in dist.items():\n",
    "        logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "    # Train/val/test split\n",
    "    n       = len(dataset)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val   = int(0.1 * n)\n",
    "    n_test  = n - n_train - n_val\n",
    "    train_ds, val_ds, test_ds = random_split(dataset, [n_train, n_val, n_test])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # Model\n",
    "    model = MultiModalModel(gpt2_model_name='gpt2-medium')\n",
    "    \n",
    "    # Move vision modules & attention to GPU\n",
    "    model.global_encoder = model.global_encoder.to(device)\n",
    "    model.global_proj    = model.global_proj.to(device)\n",
    "    model.patch_encoder  = model.patch_encoder.to(device)\n",
    "    model.patch_proj     = model.patch_proj.to(device)\n",
    "    model.attn           = model.attn.to(device)\n",
    "    model.norm           = model.norm.to(device)\n",
    "    model.cross_proj     = model.cross_proj.to(device)\n",
    "    \n",
    "    # Set trainable parameters - only train projection layers and cross-attention\n",
    "    # Keep vision encoders frozen\n",
    "    for p in model.global_encoder.parameters():\n",
    "        p.requires_grad = False\n",
    "    for p in model.patch_encoder.parameters():\n",
    "        p.requires_grad = False\n",
    "        \n",
    "    # Make sure projection layers are trainable\n",
    "    for p in model.global_proj.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.patch_proj.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.cross_proj.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.attn.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in model.norm.parameters():\n",
    "        p.requires_grad = True\n",
    "        \n",
    "    # For decoder, make only cross-attention trainable\n",
    "    for name, p in model.decoder.named_parameters():\n",
    "        if \"crossattention\" in name.lower() and (p.dtype.is_floating_point or p.dtype.is_complex):\n",
    "            p.requires_grad = True\n",
    "        else:\n",
    "            p.requires_grad = False\n",
    "\n",
    "    # Optimizer and scheduler\n",
    "    optimizer = optim.AdamW(filter(lambda x: x.requires_grad, model.parameters()), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "    # Training loop - single phase, no mixed precision\n",
    "    num_epochs = 1\n",
    "    train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n-- Epoch {epoch+1}/{num_epochs} --\")\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "        val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "        sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        sems.append(sem)\n",
    "\n",
    "        print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "        print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "        print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "        scheduler.step()\n",
    "\n",
    "    plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "    test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "    print(\"\\n========== TEST RESULTS ==========\")\n",
    "    print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "    print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "    # Generate sample reports\n",
    "    for idx in random.sample(range(len(test_ds)), min(3, len(test_ds))):\n",
    "        ex    = test_ds[idx]\n",
    "        raw   = ex['raw_report']\n",
    "        clean = ex['cleaned_report']\n",
    "        fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "        pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "        # rebuild context\n",
    "        g_feats = model.global_encoder(fi)\n",
    "        g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "        B,N,C,H,W = pa.shape\n",
    "        p        = pa.view(B*N, C, H, W)\n",
    "        pf_feats = (model.patch_encoder.forward_features(p)\n",
    "                    if hasattr(model.patch_encoder, 'forward_features')\n",
    "                    else model.patch_encoder(p))\n",
    "        pf_pooled= model._pool(pf_feats)\n",
    "        pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "        cat,_   = model.attn(torch.cat([g,pf],1),\n",
    "                             torch.cat([g,pf],1),\n",
    "                             torch.cat([g,pf],1))\n",
    "        comb    = model.norm(cat)\n",
    "        comb_proj = model.cross_proj(comb)\n",
    "        \n",
    "        # Convert to appropriate dtype for the decoder\n",
    "        decoder_dtype = next(p for p in model.decoder.parameters() if p.dtype.is_floating_point).dtype\n",
    "        comb_proj = comb_proj.to(decoder_dtype)\n",
    "        \n",
    "        prompt_text = f\"{tokenizer.bos_token} FINDINGS:\"\n",
    "        prompt_ids  = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "        prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "        \n",
    "        # Create encoder attention mask with proper dtype\n",
    "        enc_attn = torch.ones(1, comb_proj.size(1), device=device, dtype=decoder_dtype)\n",
    "        \n",
    "        # Use greedy decoding to avoid sampling issues\n",
    "        gen_ids = model.decoder.generate(\n",
    "            input_ids=prompt_ids,\n",
    "            attention_mask=prompt_mask,\n",
    "            encoder_hidden_states=comb_proj,\n",
    "            encoder_attention_mask=enc_attn,\n",
    "            max_length=150,\n",
    "            do_sample=False,  # Switch to greedy decoding\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        print(f\"\\n--- Example {idx} ---\")\n",
    "        print(f\"Raw Report       : \\n{raw}\")\n",
    "        print(f\"Cleaned Report   : \\n{clean}\")\n",
    "        print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81cc233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p         = patches.view(B*N, C, H, W)\n",
    "        pf_feats  = (self.patch_encoder.forward_features(p)\n",
    "                     if hasattr(self.patch_encoder, 'forward_features')\n",
    "                     else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p       = pts.view(B*N, C, H, W)\n",
    "            pf_feats= model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_   = model.attn(torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1))\n",
    "            comb     = model.norm(cat)\n",
    "\n",
    "            # per-sample generation to avoid size mismatch\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_txt = []\n",
    "            for i in range(B):\n",
    "                inp = prompt_ids[i:i+1]\n",
    "                m   = prompt_mask[i:i+1]\n",
    "                enc = comb[i:i+1]\n",
    "                enc_attn = torch.ones(1, enc.size(1), device=device)\n",
    "                out_ids = model.decoder.generate(\n",
    "                    input_ids=inp,\n",
    "                    attention_mask=m,\n",
    "                    encoder_hidden_states=enc,\n",
    "                    encoder_attention_mask=enc_attn,\n",
    "                    max_length=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.9,\n",
    "                    temperature=0.7,\n",
    "                    repetition_penalty=1.3,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                gen_txt.append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: two‐phase training with early cross‐attention unfreeze and frozen encoders\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW        = True\n",
    "cfg.DATASET.USE_PATCH      = True\n",
    "cfg.DATASET.REPORT         = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "cfg.DATASET.BALANCE        = True\n",
    "cfg.DATASET.AUGMENT        = True\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n       = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# Freeze vision backbones\n",
    "# =============================================================================\n",
    "for p in model.global_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 1: freeze everything except cross-attn + projection heads\n",
    "# =============================================================================\n",
    "for name, p in model.decoder.named_parameters():\n",
    "    p.requires_grad = (\"crossattention\" in name.lower())\n",
    "for p in model.global_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.patch_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda x: x.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase1_epochs = 5\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\n-- Phase 1, Epoch {epoch+1}/{phase1_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2: unfreeze entire GPT-2, low‐LR fine‐tune\n",
    "# =============================================================================\n",
    "for p in model.decoder.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase2_epochs = 5\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\n-- Phase 2, Epoch {epoch+1}/{phase2_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# Final test\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(30, len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N, C, H, W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    prompt_text = f\"{tokenizer.bos_token} FINDINGS:\"\n",
    "    prompt_ids  = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948a8001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-15 12:57:37.629540: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-15 12:57:37.636141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747339057.643708  103756 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747339057.646005  103756 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747339057.651980  103756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747339057.651987  103756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747339057.651988  103756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747339057.651989  103756 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-15 12:57:37.654387: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Counting dataset: 100%|██████████| 1714/1714 [00:00<00:00, 700685.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reports successfully saved to all_dataset_reports.txt\n",
      "Word frequency analysis saved to word_frequencies.txt\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 1, Epoch 1/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 607\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(phase1_epochs):\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Phase 1, Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mphase1_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 607\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     val_loss, gen_txt, gt_txt \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[1;32m    609\u001b[0m     sem \u001b[38;5;241m=\u001b[39m compute_semantic_similarity(gen_txt, gt_txt)\n",
      "Cell \u001b[0;32mIn[1], line 437\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, scaler, device)\u001b[0m\n\u001b[1;32m    435\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    436\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m--> 437\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_imgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatches\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[1], line 256\u001b[0m, in \u001b[0;36mFinalSamplesDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    253\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_transform(img)\n\u001b[1;32m    254\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Dataset] full_img shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 256\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft_right_file_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkeypoints\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m pt \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_transform(Image\u001b[38;5;241m.\u001b[39mfromarray(p)) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m patches]\n\u001b[1;32m    258\u001b[0m patches_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(pt, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m pt \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m34\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m112\u001b[39m, \u001b[38;5;241m112\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 316\u001b[0m, in \u001b[0;36mFinalSamplesDataset._gen_patches\u001b[0;34m(self, paths, kps_dict, crop_size, patch_size)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m side, pth \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m], paths):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pth \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pth):\n\u001b[0;32m--> 316\u001b[0m         img_arr \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m img_arr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m             arr \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_arr, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "def save_reports_to_txt(dataset, output_file=\"all_reports.txt\", include_generated=False, generated_reports=None):\n",
    "    \"\"\"\n",
    "    Save all reports from the dataset to a text file\n",
    "    \n",
    "    Args:\n",
    "        dataset: Dataset containing the reports\n",
    "        output_file: Path to the output text file\n",
    "        include_generated: Whether to include generated reports\n",
    "        generated_reports: Optional list of generated reports\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=== MEDICAL DIAGNOSIS REPORTS ===\\n\\n\")\n",
    "        \n",
    "        for i, idx in enumerate(range(len(dataset))):\n",
    "            sample = dataset[idx]\n",
    "            f.write(f\"=== REPORT {i+1} ===\\n\")\n",
    "            #f.write(f\"RAW REPORT:\\n{sample['raw_report']}\\n\\n\")\n",
    "            f.write(f\"CLEANED REPORT:\\n{sample['cleaned_report']}\\n\\n\")\n",
    "            \n",
    "            f.write(\"-\" * 50 + \"\\n\\n\")\n",
    "    \n",
    "    print(f\"Reports successfully saved to {output_file}\")\n",
    "\n",
    "def analyze_word_frequencies(dataset, output_file=\"word_frequencies.txt\"):\n",
    "    \"\"\"Analyze and save word frequencies from all reports\"\"\"\n",
    "    from collections import Counter\n",
    "    import re\n",
    "    \n",
    "    all_words = []\n",
    "    for idx in range(len(dataset)):\n",
    "        sample = dataset[idx]\n",
    "        text = sample['cleaned_report']\n",
    "        # Convert to lowercase and split into words\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
    "        all_words.extend(words)\n",
    "    \n",
    "    # Count word frequencies\n",
    "    word_counts = Counter(all_words)\n",
    "    \n",
    "    # Save to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(\"WORD FREQUENCY ANALYSIS\\n\")\n",
    "        f.write(\"======================\\n\\n\")\n",
    "        for word, count in word_counts.most_common():\n",
    "            f.write(f\"{word}: {count}\\n\")\n",
    "    \n",
    "    print(f\"Word frequency analysis saved to {output_file}\")\n",
    "    \n",
    "    # Plot word frequencies\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Get the top 30 words for visualization\n",
    "    top_words = dict(word_counts.most_common(30))\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.bar(top_words.keys(), top_words.values(), color='turquoise')\n",
    "    plt.title('Frequency of Words in Diagnosis Reports')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('word_frequencies.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return word_counts\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p         = patches.view(B*N, C, H, W)\n",
    "        pf_feats  = (self.patch_encoder.forward_features(p)\n",
    "                     if hasattr(self.patch_encoder, 'forward_features')\n",
    "                     else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p       = pts.view(B*N, C, H, W)\n",
    "            pf_feats= model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_   = model.attn(torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1))\n",
    "            comb     = model.norm(cat)\n",
    "\n",
    "            # per-sample generation to avoid size mismatch\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_txt = []\n",
    "            for i in range(B):\n",
    "                inp = prompt_ids[i:i+1]\n",
    "                m   = prompt_mask[i:i+1]\n",
    "                enc = comb[i:i+1]\n",
    "                enc_attn = torch.ones(1, enc.size(1), device=device)\n",
    "                out_ids = model.decoder.generate(\n",
    "                    input_ids=inp,\n",
    "                    attention_mask=m,\n",
    "                    encoder_hidden_states=enc,\n",
    "                    encoder_attention_mask=enc_attn,\n",
    "                    max_length=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.9,\n",
    "                    temperature=0.7,\n",
    "                    repetition_penalty=1.3,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                gen_txt.append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: two‐phase training with early cross‐attention unfreeze and frozen encoders\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW        = True\n",
    "cfg.DATASET.USE_PATCH      = True\n",
    "cfg.DATASET.REPORT         = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "cfg.DATASET.BALANCE        = True\n",
    "cfg.DATASET.AUGMENT        = True\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n       = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# After creating the dataset\n",
    "save_reports_to_txt(dataset, \"all_dataset_reports.txt\")\n",
    "# Analyze word frequencies\n",
    "word_counts = analyze_word_frequencies(dataset)\n",
    "\n",
    "\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# Freeze vision backbones\n",
    "# =============================================================================\n",
    "for p in model.global_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 1: freeze everything except cross-attn + projection heads\n",
    "# =============================================================================\n",
    "for name, p in model.decoder.named_parameters():\n",
    "    p.requires_grad = (\"crossattention\" in name.lower())\n",
    "for p in model.global_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.patch_proj.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda x: x.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase1_epochs = 5\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\n-- Phase 1, Epoch {epoch+1}/{phase1_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2: unfreeze entire GPT-2, low‐LR fine‐tune\n",
    "# =============================================================================\n",
    "for p in model.decoder.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase2_epochs = 5\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\n-- Phase 2, Epoch {epoch+1}/{phase2_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# Final test\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(30, len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N, C, H, W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    prompt_text = f\"{tokenizer.bos_token} FINDINGS:\"\n",
    "    prompt_ids  = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a8dc668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting dataset: 100%|██████████| 1714/1714 [00:00<00:00, 746447.62it/s]\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/avaghasiya/.conda/envs/rsna/lib/python3.12/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 1, Epoch 1/1 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1545c7f4846c4d9083adaba2f5a7931e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003121d6c6cc412f9473e160936480c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 2.3445\n",
      "  Validation Loss     : 1.3597\n",
      "  Semantic Similarity : 0.4949\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 2, Epoch 1/1 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548dbbbf476e4bc28acb91aade4223fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b5a1f0bd9d345b0805129d2527453e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.3826\n",
      "  Validation Loss     : 1.3478\n",
      "  Semantic Similarity : 0.5124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3b1a3f8b7a4b33890045d1fd8b5c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e20256c0ff4804a6e03eca29f198f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss               : 1.2910\n",
      "Test Semantic Similarity: 0.5512\n",
      "\n",
      "--- Example 106 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Soft tissue swelling of both lateral malleolar area and right 1st MTP joint._x000D_\n",
      "Osteoarthritis of both 1st MTP joint._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Soft tissue swelling of both lateral malleolar area and right 1st MTP joint. Osteoarthritis of both 1st MTP joint.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 24 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion. no bony lesion.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change ------------- Osteosarcoma. ------------------- Bilateral oedema, no bony abnormality but radiocordination with both knees bent out and left arm open on right thigh at elbow 3rd level of 1st joint ------------------------------------------------ Tendon protrusion (tibia). . ----------------------------------------------------------------------- Rb2 bone mineral density > 0 rudite fracture - low tibial calcaneus x-ray to 5th ankle cartilage below knee joints >= 4 thalamic medallion * osteogeic osseous tissue swelling in all joints as above high levels are not normal for any otitisosis or arthritis ? 10/10 gmd max 2nd foot <1\n",
      "\n",
      "--- Example 80 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "os naviculare typeII, both_x000D_\n",
      "otherwise, no significant bony lesion_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "os naviculare typeII, both_x000D_\n",
      "otherwise, no significant bony lesion_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "os naviculare typeII, both otherwise, no significant bony lesion\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 109 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change, both feet_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change, both feet_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change, both feet\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 148 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both 1st MTP joint, OA with suspicious gout arthritis._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both 1st MTP joint, OA with suspicious gout arthritis._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both 1st MTP joint, OA with suspicious gout arthritis.\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 65 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_no significant interval change since last study._x000D__x000D_[CONCLUSION    ]_x000D_no significant interval change since last study._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "no significant interval change since last study.\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 95 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_mild degenerative change_x000D__x000D_[CONCLUSION    ]_x000D_mild degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "mild degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality \n",
      "\n",
      "--- Example 39 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant interval change since last study._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant interval change since last study._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant interval change since last study.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion \n",
      "\n",
      "--- Example 121 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality No bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 17 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change, both feet._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change, both feet._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change, both feet.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 23 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change.\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 21 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_diffuse osteopenia\n",
      "degenerative change_x000D__x000D_[CONCLUSION    ]_x000D_diffuse osteopenia\n",
      "degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "diffuse osteopenia degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality. \n",
      "\n",
      "--- Example 140 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Calcaneal spur, both._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Calcaneal spur, both.\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 110 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_mild degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- mild degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony abnormality \n",
      "\n",
      "--- Example 149 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both ankle gout arthritis._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both ankle gout arthritis._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both ankle gout arthritis.\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 144 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_degenerative change_x000D__x000D_[CONCLUSION    ]_x000D_degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. \n",
      "\n",
      "--- Example 33 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony abnormality \n",
      "\n",
      "--- Example 15 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 84 ---\n",
      "Raw Report       : \n",
      " 임시판독 결과 입니다 추후에 판독결과가 수정 될수 있으므로 확인 바랍니다._x000D_\n",
      "------------------------------------------------------------------------ _x000D_\n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      ". ------------------------------------------------------------------------ No bony abnormality No bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 31 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_No significant interval change_x000D__x000D_[CONCLUSION    ]_x000D_No significant interval change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "No significant interval change\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 105 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs \n",
      "\n",
      "--- Example 90 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_joint space narrowing, multiple TMT joints, both \n",
      "- RA involvement, more likely \n",
      "hallux valgus with degenerative change, both _x000D__x000D_[CONCLUSION    ]_x000D_joint space narrowing, multiple TMT joints, both \n",
      "- RA involvement, more likely \n",
      "hallux valgus with degenerative change, both _x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "joint space narrowing, multiple TMT joints, both - RA involvement, more likely hallux valgus with degenerative change, both\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 108 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality. \n",
      "\n",
      "--- Example 13 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Lt. accessory navicular bone, type II with OA._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Lt. accessory navicular bone, type II with OA._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Lt. accessory navicular bone, type II with OA.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 123 ---\n",
      "Raw Report       : \n",
      " 임시판독 결과 입니다 추후에 판독결과가 수정 될수 있으므로 확인 바랍니다._x000D_\n",
      "------------------------------------------------------------------------ _x000D_\n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      ". ------------------------------------------------------------------------ No bony abnormality No bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 36 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "osteopenia._x000D_\n",
      "degenerative change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "osteopenia._x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "osteopenia. degenerative change.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion \n",
      "\n",
      "--- Example 76 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "moderate OA, both knee joints._x000D_\n",
      "_x000D_\n",
      "both ankle OA._x000D_\n",
      "_x000D_\n",
      "lumbar spondylosis._x000D_\n",
      "spondylolishtesis, L4 on L5_x000D_\n",
      "facet arthritis, L-spines._x000D_\n",
      "disc space narrowing, L5/S1_x000D_\n",
      "_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "moderate OA, both knee joints. both ankle OA. lumbar spondylosis. spondylolishtesis, L4 on L5 facet arthritis, L-spines. disc space narrowing, L5/S1\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 143 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 45 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "포함된 bone에 이상소견은 보이지 않음._x000D_\n",
      "보이는 한도내에 soft tissue에 이상소견 보이지 않음._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "bone . soft tissue . No bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: no bony abnormality \n",
      "\n",
      "--- Example 127 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add PEFT imports for LoRA\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition with LoRA\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        # load GPT-2 with cross-attention\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p         = patches.view(B*N, C, H, W)\n",
    "        pf_feats  = (self.patch_encoder.forward_features(p)\n",
    "                     if hasattr(self.patch_encoder, 'forward_features')\n",
    "                     else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops (unchanged)\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p       = pts.view(B*N, C, H, W)\n",
    "            pf_feats= model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_   = model.attn(torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1))\n",
    "            comb     = model.norm(cat)\n",
    "\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_txt = []\n",
    "            for i in range(B):\n",
    "                inp = prompt_ids[i:i+1]\n",
    "                m   = prompt_mask[i:i+1]\n",
    "                enc = comb[i:i+1]\n",
    "                enc_attn = torch.ones(1, enc.size(1), device=device)\n",
    "                out_ids = model.decoder.generate(\n",
    "                    input_ids=inp,\n",
    "                    attention_mask=m,\n",
    "                    encoder_hidden_states=enc,\n",
    "                    encoder_attention_mask=enc_attn,\n",
    "                    max_length=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.9,\n",
    "                    temperature=0.7,\n",
    "                    repetition_penalty=1.3,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                gen_txt.append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: two‐phase training with LoRA on GPT-2 cross-attention\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW        = True\n",
    "cfg.DATASET.USE_PATCH      = True\n",
    "cfg.DATASET.REPORT         = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "cfg.DATASET.BALANCE        = True\n",
    "cfg.DATASET.AUGMENT        = False\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate dataset\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n       = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Build model and apply LoRA\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# Freeze visual encoders and non-LoRA decoder parameters\n",
    "for p in model.global_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.global_proj.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_proj.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Define LoRA config targeting GPT-2's cross-attention q and v projections\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,             # LoRA rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"c_attn\"]  # GPT-2 uses a combined c_attn; PEFT will split internally\n",
    ")\n",
    "model.decoder = get_peft_model(model.decoder, lora_config)\n",
    "\n",
    "# Phase 1: only LoRA adapters are trainable\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase1_epochs = 1\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\n-- Phase 1, Epoch {epoch+1}/{phase1_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2: unfreeze also the projection heads + LayerNorm; keep visual encoders frozen\n",
    "# =============================================================================\n",
    "for name, p in model.named_parameters():\n",
    "    # Unfreeze global/patch projection and LayerNorm and LoRA; keep visual backbones frozen\n",
    "    if any(nd in name for nd in [\"global_proj\", \"patch_proj\", \"norm\", \"lora\"]):\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase2_epochs = 1\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\n-- Phase 2, Epoch {epoch+1}/{phase2_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# =============================================================================\n",
    "# Final test\n",
    "# =============================================================================\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(30, len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N, C, H, W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    prompt_text = f\"{tokenizer.bos_token} FINDINGS:\"\n",
    "    prompt_ids  = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d8c5109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting dataset: 100%|██████████| 1714/1714 [00:00<00:00, 764547.17it/s]\n",
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 1, Epoch 1/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93c35999f7d4e8995648034e1b608aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed391ef673b4cad819aa363adff29f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.9182\n",
      "  Validation Loss     : 1.0553\n",
      "  Semantic Similarity : 0.5387\n",
      "\n",
      "-- Phase 1, Epoch 2/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e7d377acbd43dcaa50257c58146406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e3f723def94a4ebd544e1a5783233d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1372\n",
      "  Validation Loss     : 0.9148\n",
      "  Semantic Similarity : 0.4734\n",
      "\n",
      "-- Phase 1, Epoch 3/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28bfe435cdf4407684b47d371068e76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0b460558e243f695730a9007c76740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.9893\n",
      "  Validation Loss     : 0.8276\n",
      "  Semantic Similarity : 0.5037\n",
      "\n",
      "-- Phase 1, Epoch 4/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146d402926da4657b9a2389fc28774b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da24f01dcc3410ab54933188dc88472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.8902\n",
      "  Validation Loss     : 0.7859\n",
      "  Semantic Similarity : 0.3994\n",
      "\n",
      "-- Phase 1, Epoch 5/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16abe8ddfa9149ce9d984798b103141f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b8f711198246a3ae1412f08fdda2ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.8305\n",
      "  Validation Loss     : 0.7477\n",
      "  Semantic Similarity : 0.4765\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Phase 2, Epoch 1/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a818e4f65734f89876b79a61fd34881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d47780547b9648e6aebc7418b819bc5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.7907\n",
      "  Validation Loss     : 0.7408\n",
      "  Semantic Similarity : 0.4943\n",
      "\n",
      "-- Phase 2, Epoch 2/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d63003a2ec4272b0af2304df7cde3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b63f631192b41a6876f6fca17f9f2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.8067\n",
      "  Validation Loss     : 0.7384\n",
      "  Semantic Similarity : 0.4853\n",
      "\n",
      "-- Phase 2, Epoch 3/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd60aec0bc00499e99d79c787b6966b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302dbd59417a418d927150293b4bec43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.7921\n",
      "  Validation Loss     : 0.7370\n",
      "  Semantic Similarity : 0.4641\n",
      "\n",
      "-- Phase 2, Epoch 4/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3273238220f4ad4b01ba19353edcbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecc9762e45842a0bcc781381d634137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.7849\n",
      "  Validation Loss     : 0.7374\n",
      "  Semantic Similarity : 0.4997\n",
      "\n",
      "-- Phase 2, Epoch 5/5 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6937c74f29f34bd4a704d061fdaf633b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae84b762792b4a06b1d2ddc08b53d1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.7931\n",
      "  Validation Loss     : 0.7373\n",
      "  Semantic Similarity : 0.4967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e153deb72b4090a574d3d81b41c5e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22dd1ad66c541f1b9a43d1f7478c5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TEST RESULTS ==========\n",
      "Test Loss               : 0.7336\n",
      "Test Semantic Similarity: 0.5162\n",
      "\n",
      "--- Example 106 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change. degenerative change.\n",
      "Generated Report : \n",
      " FINDINGS: No bony lesion. -------------------------- no abnormality, both feet and wrists ------------------------------------------ mild gout arthritis (diastolic bone swelling) at left ankle joint Lt 1st MTP joints Rt/O RA involvement with degenerative change of right wrist base soft tissue erosion in lateral portion of calcaneal proximal phalanx ------------------------------------------------------------------------ type 2 accessory navicular bones rp OA site osteopenia --- hallux valgus medial aspect --> possible dearthritic changes on radiographs from T1 fracture along warts < 5th MT area moderate to low thickness erosions periartisial effusion near incisionation asphyxia - probable diffuse os trigonum > 3rd\n",
      "\n",
      "--- Example 24 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_Both hallux valgus\n",
      "- with OA, 1st MTP joint \n",
      "Rt. os trigonum_x000D__x000D_[CONCLUSION    ]_x000D_Both hallux valgus\n",
      "- with OA, 1st MTP joint \n",
      "Rt. os trigonum_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "Both hallux valgus - with OA, 1st MTP joint Rt. os trigonum\n",
      "Generated Report : \n",
      " FINDINGS: both accessory navicular bone, type II. ------------- Rt 1st MTP joint OA with degenerative change at left 5th proximal portion of right ankle and other joints (gout arthritis) --> RA involvement in medial part of elbow/lanklinoid calcaneal group III TMT lateral tibia -> rheumatoidal fracture associated with mild to moderate dearthrous changes - small erosion on 2nd molar vertebral body site along patellar ridge around 3rd foot LB1 gaito osteopenia -- Lt MR tractors suggestive possible nodular swelling --------------------------------------- Bilateral pelvic floor hallux valve > bony abnormality reconditioned form as seen here --- Suggestion\n",
      "\n",
      "--- Example 80 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Osteopenia_x000D_\n",
      "Degenerative changes_x000D_\n",
      "Lt. os peroneum_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Osteopenia Degenerative changes Lt. os peroneum\n",
      "Generated Report : \n",
      " FINDINGS: No significant bony lesion on radiographs. \n",
      "comparative change to Rt 1st MTP joint, both knee joints and OA erosion with gout arthritis in left 2nd TMT ankle bone type II Lt radicular degeneration of right 3rd MT foot osteophyteoid tissue at CPT site --> GIPO involvement Both accessory naviculare (diastolic calcaneal canal) diffuse nodular swelling from medial tibia - probable r/o RA locally small soft tissues suggestive os valgus fracture that suggest possible bilateral BOO ball formation as usual -- no abnormality pes planar root or lateral talonavancosis either ---------------------------------------- mild loose body area along proximal\n",
      "\n",
      "--- Example 109 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "acrolysis, both feet, 1st-3rd distal phalanges._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "acrolysis, both feet, 1st-3rd distal phalanges._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "acrolysis, both feet, 1st-3rd distal phalanges.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 148 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_bone erosions at both 1st MTP joint with probable tophi at Lt 1st MTP joint \n",
      "-> gouty arthritis, probably\n",
      "mild degenerative change _x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- bone erosions at both 1st MTP joint with probable tophi at Lt 1st MTP joint -> gouty arthritis, probably mild degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. \n",
      " The right 1st MTP joint, both knee joints and gout arthritis in 2nd MTG medial navicular bone type II Rt 3rd TMT ankle OA with BIP involvement Lt RA soft tissue swelling at left lateral portion of first talonavus proximal phalanx -> KF2R1 degenerative change from pes planum to calcaneal spur --> incongruous development diffuse osteopenia (phi) small fracture/diaphragm formation recurrence as indicated by nodular activity ------------------------------------------------------------------------ No abnormality either foot or feet ------------------------------------------ Both rf accessory muscle GLS union hallux valgarey edema\n",
      "\n",
      "--- Example 65 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "gout, both feet._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "gout, both feet._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "gout, both feet.\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. ------------- No notable crescent change to left lateral portion of both 1st MTP joint, R/O gout involvement in Lt 2nd 5th MT joints and GV soft tissue erosion around medial bone area with degenerative changes evident at first molar site ---------------------------------------- Bilateral osteopenia (diagnosis) - OA PPT calcaneal fracture -> right knee swelling --> RA risk associated variance from previous seasontime interval analysis --- Both ankle dorsifugal deformity hallux valgus formation --------------------------------------------------------------------------- ---------- neither foot os naviculare inguinal canal or pes planar tuberosity type II > rt., incisioned perfor\n",
      "\n",
      "--- Example 95 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. ------------- No substantial abnormality either, both feet and knee joints in right 1st MTP joint with OA at left 2nd/3rd toe angle of RA involvement -> Rt gouty arthritis mild degenerative change - MR headspace narrowing -- Lt calcaneal erosion along PPR proximal medial portion thereof to connective tissue type II fracture --> GOUTY osteopenia (Pterygium) diffuse swelling near 3x1 cm lateral bone-tooth site-- probable low density erosions or soft tissues rather than incongruous osseum.-- Both accessory navicular ridge as suspected possible possibility rheumatoid tract --- ---------------------------------------\n",
      "\n",
      "--- Example 39 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_No significant interval change_x000D__x000D_[CONCLUSION    ]_x000D_No significant interval change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "No significant interval change\n",
      "Generated Report : \n",
      " FINDINGS: No significant interval change since last study.  ------------------------------------------------------------------------ Lt 1st MTP joint RA involvement, both knee joints and other OA arthritis with R/O gouty dyscalciform movement ------------------------------------------ - rt 2nd 3rd 5th TMT ankle soft tissue erosion --> os navicular bone weakening ---------------------- degenerative changes on radiographs no appreciable difference from previous findings to suggest possible bony abnormality of lateral calcaneal osteopenia type II --- probable BPO presence in MR area at middle level (ie mild fracture angle) hallux valgus medial psoa diffuse swelling -> QD root canal narrowing likely C-section accessory tendons apparent periartic elevation recurrence or\n",
      "\n",
      "--- Example 121 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "both feet, RA_x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "both feet, RA_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "both feet, RA\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 17 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality No bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. \n",
      "— Lt. 1st MTP joint, type II R/O gouty arthritis in left 5th molar tract and right middle toe with degenerative change of both feet (low-density bone formation).   No substantial brucellosis at site to radia suggest probable bilateral osteopenic abnormality . hallux valgus incongruous ligamentation , diffuse ossification --> OA involvement soleron erosion - erosions suggestive postcentral segment os trigemare lateral pelvic spuriform swelling --- Pronchetial fracture or other apparent odd morphology ------------------------------------------ rngs -- soft tissue calcifications from either side-- mild nod\n",
      "\n",
      "--- Example 23 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_no significant bony lesion on radiographs._x000D__x000D_[CONCLUSION    ]_x000D_no significant bony lesion on radiographs._x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 21 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change.\n",
      "Generated Report : \n",
      " FINDINGS: both ankle OA, Lt. 1st MTP joint \n",
      "\n",
      "--- Example 140 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. \n",
      " - bone suggestive of both ankle, left 1st MTP joint and right 2nd mt-1 finger fracture at MR joints gouty arthritis --> R/O RA involvement Ltdi obliquity with suspected rheumatoid osteopenia (R+5th MT knee) -> OA soft tissue swelling from either talons or other structures ---------------------------------------- erogenous area in proximal portion of medial section ---------------------- pesoidal protrusions on radiculare lateral aspect to distal side -------------------------------------------------------------------------------- No Bary Lactation evidence suggesting possible bilateral accessory navicular arrangement between 5rd foot ulnar facet.-- diffusive erosion along TMT elbow site as well ---\n",
      "\n",
      "--- Example 110 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Rt. TMT joint, R/O RA._x000D_\n",
      "_x000D_\n",
      "pes cavus both._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Rt. TMT joint, R/O RA._x000D_\n",
      "_x000D_\n",
      "pes cavus both._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Rt. TMT joint, R/O RA. pes cavus both.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 149 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: diffuse osteopenia. degenerative change, both feet and ankle joints with Rt 1st MTP joint \n",
      "\n",
      "--- Example 144 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_both 1st MTP joint space narrowing.\n",
      "diffuse osteopenia\n",
      "degenerative change_x000D__x000D_[CONCLUSION    ]_x000D_both 1st MTP joint space narrowing.\n",
      "diffuse osteopenia\n",
      "degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "both 1st MTP joint space narrowing. diffuse osteopenia degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: no significant interval change ---------- No bony abnormality. soft tissue swelling, both feet and ankle joints with moderate to heavy OA progression at Rt 1st MTP joint Lt 5th knee fibula type 2 degenerative changes --- hallux valgus in left side of right 3rd MT gouty arthritis on radiographs ------------------------------------------------------------------------ - probable RA involvement --------------------------------------- mottled calcaneal bone erosion from medial PX lesions --> GV1-3 accessory navicular bones -> MI2 activity -- erosions likely r/o Kwik's foot deformity diffuse osteopenia locally (ie mild nodar tendinitis) small os trigonum lateral phalanx dorsomedial pes plan\n",
      "\n",
      "--- Example 33 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Lt. foot, accessory navicular bone._x000D_\n",
      "Rt. calcaneocuboid joint, OA_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Lt. foot, accessory navicular bone._x000D_\n",
      "Rt. calcaneocuboid joint, OA_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Lt. foot, accessory navicular bone. Rt. calcaneocuboid joint, OA\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 15 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "degenerative change_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "degenerative change_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 84 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. ------------- No Bery lumbar fracture, both feet and ankle soft tissue swelling in medial portion of lateral 1st MTP joint with Lt 2nd OA atrium to indicate probable erosion on radiographs - os trigonum type II left knee degenerative change Rt 5th phalanx right foot osteopenia gouty arthritis --- Both talons protrusion from calcaneal joints -> PGI involvement (weakness) -- GIP dysfunction --> RA > r/o mTOR return movement since last study --------------------------------------- ------------------------------------------------------------------------ ---------- Coccinelliform bone abnormality mild loose growth moderate postural changes hallux valgus diffuse ossification otitis suggestive\n",
      "\n",
      "--- Example 31 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality No bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. ------------- No major abnormality in radiology at MR tract, both hands and feet of fracture site with nodal osseum (R/O) joint erosion rather than erosions Rt 1st MTP joints --> RA involvement Lt 5th finger calcaneus -> rngs head OA ---------------------------------------- Bilateral gouty arthritis as indicated by KDF survey ----------------------------------------------------------------------- Both ankle soft tissue swelling from left talonoid bone type II post medial phalanx formation that suggest degenerative change to right 3rd foot tendon progression hallux valgare lateral QD1 unit osteopenia now evident periarticular changes indicating possible accessory navicul\n",
      "\n",
      "--- Example 105 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. \n",
      "- gout arthritis, both feet and knee joints in Rt 1st MTP joint swelling around right ankle with nodal involvement at base of left wrist/diaphragm type II rheumatoid bone development.>> Lt 2nd molar site (R2). -- No substantial brucellosis or other abnormal morphology along side of BCL TMT unit radia suggest RA presence to medial part --> --------------------------------------------------------------------------------------------------------------------------------------- ---------------------- ---------------------------------------- hallux valgus erosions -> postural change --- PPT tendon erosion evident as accessory navicular bones large lateral portion... soft tissue abnormality up front fracture possible Osteoarthritis calcaneous os\n",
      "\n",
      "--- Example 90 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony lesions_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "No bony lesions_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony lesions\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change. \n",
      "\n",
      "--- Example 108 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no bony lesion._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no bony lesion.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 13 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "Lt. 1st MTP joint, OA with hallux valgus, mild._x000D_\n",
      "both calcaneous, R/O Haglund deformity._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Lt. 1st MTP joint, OA with hallux valgus, mild. both calcaneous, R/O Haglund deformity.\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 123 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "no significant bony lesion on radiographs._x000D_\n",
      "_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "no significant bony lesion on radiographs.\n",
      "Generated Report : \n",
      " FINDINGS: no bony lesion. ------------- No abnormality, both hands and feet soft tissue swelling in left lateral portion of right 1st MTP joint (sclerotic change) Ltgus gouty arthritis , r/o RA involvement --------------------------------------- mild osteopenia moderate OA Rt 2nd MT joints diffuse erosion at all sites with possible degenerative changes -> postcentral ridge to suggest fracture --> likely type II periarticular bone loss Both talonavondial spur syndrome Bilateral pelvic floor deformity --- probable GIP dysfunction - possibly accessory calcaneal tangle on radiographs ------------------------------------------------------------------------ hallux valineauitis ingrachiform narrowing nodule os trigicula pes planum small tend\n",
      "\n",
      "--- Example 36 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "Lt. talocalcaneal joint OA._x000D_\n",
      "both 1st MCP joint OA_x000D_\n",
      "both 3rd PIP joint OA._x000D_\n",
      "_x000D_\n",
      "both 5th MTP joint erosion._x000D_\n",
      "   --> RA involvement._x000D_\n",
      "_x000D_\n",
      "moderate OA, both knee joints._x000D_\n",
      "_x000D_\n",
      "[ Conclusion ]_x000D_\n",
      "Lt. talocalcaneal joint OA._x000D_\n",
      "both 1st MCP joint OA_x000D_\n",
      "both 3rd PIP joint OA._x000D_\n",
      "_x000D_\n",
      "both 5th MTP joint erosion._x000D_\n",
      "   --> RA involvement._x000D_\n",
      "_x000D_\n",
      "moderate OA, both knee joints._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "Lt. talocalcaneal joint OA. both 1st MCP joint OA both 3rd PIP joint OA. both 5th MTP joint erosion. --> RA involvement. moderate OA, both knee joints. Lt. talocalcaneal joint OA. both 1st MCP joint OA both 3rd PIP joint OA. both 5th MTP joint erosion. --> RA involvement. moderate OA, both knee joints.\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 76 ---\n",
      "Raw Report       : \n",
      "[FINDING       ]_x000D_-_x000D__x000D_[CONCLUSION    ]_x000D_degenerative change_x000D__x000D_[RECOMMENDATION]_x000D_-\n",
      "Cleaned Report   : \n",
      "- degenerative change\n",
      "Generated Report : \n",
      " FINDINGS: degenerative change \n",
      "\n",
      "--- Example 143 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "No bony abnormality_x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "No bony abnormality No bony abnormality\n",
      "Generated Report : \n",
      " FINDINGS: No bony abnormality. \n",
      "\n",
      "--- Example 45 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "probable tophi, right 2nd MTP joint._x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "probable tophi, right 2nd MTP joint._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "probable tophi, right 2nd MTP joint. probable tophi, right 2nd MTP joint.\n",
      "Generated Report : \n",
      " FINDINGS: No bony lesion. ------------- Lt. 1st MTP joint, OA and both ankle soft tissue swelling with degenerative change ------------------------------------------ Rt 5th finger accessory navicular bone type II post traumatic arthritis --> gouty dysplasia of medial portion of left thumb in fracture site -> RA involvement at proximal part of right wrist head (R/O) Both feet strongly suggestive of possible calcification on radiographs or proton ectoplasmosis ------------------------------------------------------------------------ hallux valgus osteopenia as indicated by erosion along base 3rd molar toe joints to form fractures laterally up the lateral aspect TST-G2 hands outgrowth evident locally no significant intervalal abnormality either large crescent\n",
      "\n",
      "--- Example 127 ---\n",
      "Raw Report       : \n",
      "[ Finding ]_x000D_\n",
      "_x000D_\n",
      "[ Diagnosis ]_x000D_\n",
      "c/w gout : bony erosion with soft tissue swelling at Rt. 2nd and 3rd TMT joint._x000D_\n",
      "[ Recommend ]_x000D_\n",
      "\n",
      "Cleaned Report   : \n",
      "c/w gout : bony erosion with soft tissue swelling at Rt. 2nd and 3rd TMT joint.\n",
      "Generated Report : \n",
      " FINDINGS: no significant bony lesion on radiographs. ------------- Rt 1st MTP joint, Lt 3rd knee joints - possible soft tissue erosion in lateral portion of right ankle and left wrist area at both 2nd PT head accessory muscle groups with gouty arthritis --> RA involvement (unilateral bone swelling). --- No substantial bruise or nodal abnormality either ------------------------------------------ Both feet OA1 ------------------------------------------------------------------------ probable degenerative change to pes planus fracture -> erosions into medial part of foot upper body ---------------------- TRS calcification along bilateral fractures/oesophageous structures are sparsely evident here hallux valgare formation near the center of talonoid gland-shaped space below middle toe temple\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add PEFT imports for LoRA\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration: write INFO+ logs only to training.log (no console output)\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition with LoRA\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj    = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder  = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj     = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn           = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm           = nn.LayerNorm(768)\n",
    "\n",
    "        # load GPT-2 with cross-attention\n",
    "        self.decoder        = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g       = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p         = patches.view(B*N, C, H, W)\n",
    "        pf_feats  = (self.patch_encoder.forward_features(p)\n",
    "                     if hasattr(self.patch_encoder, 'forward_features')\n",
    "                     else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf        = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1),\n",
    "                           torch.cat([g,pf],1))\n",
    "        comb    = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops (unchanged)\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts  = b['patches'].to(device)\n",
    "        ids  = b['input_ids'].to(device)\n",
    "        msk  = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p       = pts.view(B*N, C, H, W)\n",
    "            pf_feats= model.patch_encoder(p)\n",
    "            pf_pooled= model._pool(pf_feats)\n",
    "            pf        = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat,_   = model.attn(torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1),\n",
    "                                 torch.cat([g,pf],1))\n",
    "            comb     = model.norm(cat)\n",
    "\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_txt = []\n",
    "            for i in range(B):\n",
    "                inp = prompt_ids[i:i+1]\n",
    "                m   = prompt_mask[i:i+1]\n",
    "                enc = comb[i:i+1]\n",
    "                enc_attn = torch.ones(1, enc.size(1), device=device)\n",
    "                out_ids = model.decoder.generate(\n",
    "                    input_ids=inp,\n",
    "                    attention_mask=m,\n",
    "                    encoder_hidden_states=enc,\n",
    "                    encoder_attention_mask=enc_attn,\n",
    "                    max_length=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.9,\n",
    "                    temperature=0.7,\n",
    "                    repetition_penalty=1.3,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                gen_txt.append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt .extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1  = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2  = stm.encode(gt,  convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses,   label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: two‐phase training with LoRA on GPT-2 cross-attention\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON           = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW        = True\n",
    "cfg.DATASET.USE_PATCH      = True\n",
    "cfg.DATASET.REPORT         = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "cfg.DATASET.BALANCE        = True\n",
    "cfg.DATASET.AUGMENT        = False\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token     = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate dataset\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token  = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n       = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = int(0.1 * n)\n",
    "n_test  = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,  collate_fn=collate_fn)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# Build model and apply LoRA\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# Freeze visual encoders and non-LoRA decoder parameters\n",
    "for p in model.global_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.global_proj.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_proj.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Define LoRA config targeting GPT-2's cross-attention q and v projections\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,             # LoRA rank\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"]  # GPT-2 uses a combined c_attn; PEFT will split internally\n",
    ")\n",
    "model.decoder = get_peft_model(model.decoder, lora_config)\n",
    "\n",
    "# Phase 1: only LoRA adapters are trainable\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase1_epochs = 5\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(phase1_epochs):\n",
    "    print(f\"\\n-- Phase 1, Epoch {epoch+1}/{phase1_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# =============================================================================\n",
    "# Phase 2: unfreeze also the projection heads + LayerNorm; keep visual encoders frozen\n",
    "# =============================================================================\n",
    "for name, p in model.named_parameters():\n",
    "    # Unfreeze global/patch projection and LayerNorm and LoRA; keep visual backbones frozen\n",
    "    if any(nd in name for nd in [\"global_proj\", \"patch_proj\", \"norm\", \"lora\"]):\n",
    "        p.requires_grad = True\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "scaler    = torch.amp.GradScaler()\n",
    "\n",
    "phase2_epochs = 5\n",
    "for epoch in range(phase2_epochs):\n",
    "    print(f\"\\n-- Phase 2, Epoch {epoch+1}/{phase2_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "# =============================================================================\n",
    "# Final test\n",
    "# =============================================================================\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Random examples\n",
    "for idx in random.sample(range(len(test_ds)), min(30, len(test_ds))):\n",
    "    ex    = test_ds[idx]\n",
    "    raw   = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi    = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa    = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g       = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p      = pa.view(B*N, C, H, W)\n",
    "    pf_feats= model.patch_encoder(p)\n",
    "    pf_pooled= model._pool(pf_feats)\n",
    "    pf        = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_  = model.attn(torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1),\n",
    "                        torch.cat([g,pf],1))\n",
    "    comb    = model.norm(cat)\n",
    "\n",
    "    prompt_text = f\"{tokenizer.bos_token} FINDINGS:\"\n",
    "    prompt_ids  = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40192d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting dataset: 100%|██████████| 1714/1714 [00:00<00:00, 651771.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  abnormal: 966\n",
      "  normal: 748\n",
      "\n",
      "Number of training samples:   1371\n",
      "Number of validation samples: 171\n",
      "Number of test samples:       172\n",
      "Total samples:                1714\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/avaghasiya/.conda/envs/rsna/lib/python3.12/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Epoch 1/10 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 569\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 569\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    570\u001b[0m     val_loss, gen_txt, gt_txt \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[1;32m    571\u001b[0m     sem \u001b[38;5;241m=\u001b[39m compute_semantic_similarity(gen_txt, gt_txt)\n",
      "Cell \u001b[0;32mIn[10], line 410\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, scaler, device)\u001b[0m\n\u001b[1;32m    408\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    409\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m--> 410\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_imgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatches\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[10], line 191\u001b[0m, in \u001b[0;36mFinalSamplesDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    190\u001b[0m     e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[0;32m--> 191\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_transform(img)\n\u001b[1;32m    193\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Dataset] full_img shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/PIL/Image.py:984\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import PEFT for LoRA implementation\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    print(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    print(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition with LoRA\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        # Vision encoders\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(768)\n",
    "        \n",
    "        # Initialize base GPT-2 model with cross-attention\n",
    "        base_decoder = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "        \n",
    "        # Configure LoRA\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=TaskType.CAUSAL_LM,\n",
    "            r=16,                  # Low rank dimension\n",
    "            lora_alpha=32,         # Scaling factor\n",
    "            lora_dropout=0.05,     # Dropout probability\n",
    "            target_modules=[\"c_attn\", \"c_proj\"],  # Apply to attention modules\n",
    "            bias=\"none\"\n",
    "        )\n",
    "        \n",
    "        # Apply LoRA to the model\n",
    "        self.decoder = get_peft_model(base_decoder, lora_config)\n",
    "        \n",
    "        # Print trainable parameters info\n",
    "        self.print_trainable_parameters()\n",
    "    \n",
    "    def print_trainable_parameters(self):\n",
    "        \"\"\"\n",
    "        Prints the number of trainable parameters in the model.\n",
    "        \"\"\"\n",
    "        trainable_params = 0\n",
    "        all_param = 0\n",
    "        for _, param in self.decoder.named_parameters():\n",
    "            all_param += param.numel()\n",
    "            if param.requires_grad:\n",
    "                trainable_params += param.numel()\n",
    "        \n",
    "        logging.info(\n",
    "            f\"GPT-2 with LoRA trainable params: {trainable_params} || all params: {all_param} || \"\n",
    "            f\"trainable%: {100 * trainable_params / all_param:.2f}%\"\n",
    "        )\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p = patches.view(B*N, C, H, W)\n",
    "        pf_feats = (self.patch_encoder.forward_features(p)\n",
    "                   if hasattr(self.patch_encoder, 'forward_features')\n",
    "                   else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                          torch.cat([g,pf],1),\n",
    "                          torch.cat([g,pf],1))\n",
    "        comb = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts = b['patches'].to(device)\n",
    "        ids = b['input_ids'].to(device)\n",
    "        msk = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts = b['patches'].to(device)\n",
    "        ids = b['input_ids'].to(device)\n",
    "        msk = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p = pts.view(B*N, C, H, W)\n",
    "            pf_feats = model.patch_encoder(p)\n",
    "            pf_pooled = model._pool(pf_feats)\n",
    "            pf = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat, _ = model.attn(torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1))\n",
    "            comb = model.norm(cat)\n",
    "\n",
    "            # per-sample generation to avoid size mismatch\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_txt = []\n",
    "            for i in range(B):\n",
    "                inp = prompt_ids[i:i+1]\n",
    "                m = prompt_mask[i:i+1]\n",
    "                enc = comb[i:i+1]\n",
    "                enc_attn = torch.ones(1, enc.size(1), device=device)\n",
    "                out_ids = model.decoder.generate(\n",
    "                    input_ids=inp,\n",
    "                    attention_mask=m,\n",
    "                    encoder_hidden_states=enc,\n",
    "                    encoder_attention_mask=enc_attn,\n",
    "                    max_length=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.9,\n",
    "                    temperature=0.7,\n",
    "                    repetition_penalty=1.3,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                gen_txt.append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt.extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1 = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2 = stm.encode(gt, convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: LoRA fine-tuning with frozen vision encoders\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW = True\n",
    "cfg.DATASET.USE_PATCH = True\n",
    "cfg.DATASET.REPORT = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "cfg.DATASET.BALANCE = False\n",
    "cfg.DATASET.AUGMENT = False\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "    print(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = int(0.1 * n)\n",
    "n_test = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "# print sample counts\n",
    "print(f\"\\nNumber of training samples:   {len(train_ds)}\")\n",
    "print(f\"Number of validation samples: {len(val_ds)}\")\n",
    "print(f\"Number of test samples:       {len(test_ds)}\")\n",
    "print(f\"Total samples:                {len(train_ds) + len(val_ds) + len(test_ds)}\\n\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# Freeze vision backbones\n",
    "for p in model.global_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Setup optimizer for trainable parameters only (LoRA parameters + projection heads)\n",
    "optimizer = optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "# Training loop with LoRA\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n-- Epoch {epoch+1}/{num_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# Save LoRA weights\n",
    "#model.decoder.save_pretrained(\"lora_gpt2_medical_model\")\n",
    "\n",
    "# Final test evaluation\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Generate examples from test set\n",
    "for idx in random.sample(range(len(test_ds)), min(5, len(test_ds))):\n",
    "    ex = test_ds[idx]\n",
    "    raw = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p = pa.view(B*N, C, H, W)\n",
    "    pf_feats = model.patch_encoder(p)\n",
    "    pf_pooled = model._pool(pf_feats)\n",
    "    pf = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_ = model.attn(torch.cat([g,pf],1),\n",
    "                      torch.cat([g,pf],1),\n",
    "                      torch.cat([g,pf],1))\n",
    "    comb = model.norm(cat)\n",
    "\n",
    "    prompt_text = f\"{tokenizer.bos_token} FINDINGS:\"\n",
    "    prompt_ids = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n",
    "\n",
    "# Load and use the saved LoRA weights\n",
    "def load_lora_model():\n",
    "    base_model = GPT2LMHeadModel.from_pretrained('gpt2', add_cross_attention=True)\n",
    "    lora_model = PeftModel.from_pretrained(base_model, \"lora_gpt2_medical_model\")\n",
    "    return lora_model\n",
    "\n",
    "# If you want to merge the LoRA weights with the base model for faster inference\n",
    "def merge_and_save():\n",
    "    model = load_lora_model()\n",
    "    model = model.merge_and_unload()  # This merges the LoRA weights into the base model\n",
    "    model.save_pretrained(\"merged_gpt2_medical_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1340c8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting dataset: 100%|██████████| 2394/2394 [00:00<00:00, 705435.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  abnormal: 1646\n",
      "  normal: 748\n",
      "\n",
      "Number of training samples:   1915\n",
      "Number of validation samples: 239\n",
      "Number of test samples:       240\n",
      "Total samples:                2394\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.crossattention.c_attn.bias', 'h.0.crossattention.c_attn.weight', 'h.0.crossattention.c_proj.bias', 'h.0.crossattention.c_proj.weight', 'h.0.crossattention.q_attn.bias', 'h.0.crossattention.q_attn.weight', 'h.0.ln_cross_attn.bias', 'h.0.ln_cross_attn.weight', 'h.1.crossattention.c_attn.bias', 'h.1.crossattention.c_attn.weight', 'h.1.crossattention.c_proj.bias', 'h.1.crossattention.c_proj.weight', 'h.1.crossattention.q_attn.bias', 'h.1.crossattention.q_attn.weight', 'h.1.ln_cross_attn.bias', 'h.1.ln_cross_attn.weight', 'h.10.crossattention.c_attn.bias', 'h.10.crossattention.c_attn.weight', 'h.10.crossattention.c_proj.bias', 'h.10.crossattention.c_proj.weight', 'h.10.crossattention.q_attn.bias', 'h.10.crossattention.q_attn.weight', 'h.10.ln_cross_attn.bias', 'h.10.ln_cross_attn.weight', 'h.11.crossattention.c_attn.bias', 'h.11.crossattention.c_attn.weight', 'h.11.crossattention.c_proj.bias', 'h.11.crossattention.c_proj.weight', 'h.11.crossattention.q_attn.bias', 'h.11.crossattention.q_attn.weight', 'h.11.ln_cross_attn.bias', 'h.11.ln_cross_attn.weight', 'h.2.crossattention.c_attn.bias', 'h.2.crossattention.c_attn.weight', 'h.2.crossattention.c_proj.bias', 'h.2.crossattention.c_proj.weight', 'h.2.crossattention.q_attn.bias', 'h.2.crossattention.q_attn.weight', 'h.2.ln_cross_attn.bias', 'h.2.ln_cross_attn.weight', 'h.3.crossattention.c_attn.bias', 'h.3.crossattention.c_attn.weight', 'h.3.crossattention.c_proj.bias', 'h.3.crossattention.c_proj.weight', 'h.3.crossattention.q_attn.bias', 'h.3.crossattention.q_attn.weight', 'h.3.ln_cross_attn.bias', 'h.3.ln_cross_attn.weight', 'h.4.crossattention.c_attn.bias', 'h.4.crossattention.c_attn.weight', 'h.4.crossattention.c_proj.bias', 'h.4.crossattention.c_proj.weight', 'h.4.crossattention.q_attn.bias', 'h.4.crossattention.q_attn.weight', 'h.4.ln_cross_attn.bias', 'h.4.ln_cross_attn.weight', 'h.5.crossattention.c_attn.bias', 'h.5.crossattention.c_attn.weight', 'h.5.crossattention.c_proj.bias', 'h.5.crossattention.c_proj.weight', 'h.5.crossattention.q_attn.bias', 'h.5.crossattention.q_attn.weight', 'h.5.ln_cross_attn.bias', 'h.5.ln_cross_attn.weight', 'h.6.crossattention.c_attn.bias', 'h.6.crossattention.c_attn.weight', 'h.6.crossattention.c_proj.bias', 'h.6.crossattention.c_proj.weight', 'h.6.crossattention.q_attn.bias', 'h.6.crossattention.q_attn.weight', 'h.6.ln_cross_attn.bias', 'h.6.ln_cross_attn.weight', 'h.7.crossattention.c_attn.bias', 'h.7.crossattention.c_attn.weight', 'h.7.crossattention.c_proj.bias', 'h.7.crossattention.c_proj.weight', 'h.7.crossattention.q_attn.bias', 'h.7.crossattention.q_attn.weight', 'h.7.ln_cross_attn.bias', 'h.7.ln_cross_attn.weight', 'h.8.crossattention.c_attn.bias', 'h.8.crossattention.c_attn.weight', 'h.8.crossattention.c_proj.bias', 'h.8.crossattention.c_proj.weight', 'h.8.crossattention.q_attn.bias', 'h.8.crossattention.q_attn.weight', 'h.8.ln_cross_attn.bias', 'h.8.ln_cross_attn.weight', 'h.9.crossattention.c_attn.bias', 'h.9.crossattention.c_attn.weight', 'h.9.crossattention.c_proj.bias', 'h.9.crossattention.c_proj.weight', 'h.9.crossattention.q_attn.bias', 'h.9.crossattention.q_attn.weight', 'h.9.ln_cross_attn.bias', 'h.9.ln_cross_attn.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Epoch 1/20 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d9c730505d4b849f503690e9c991dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efb3945c0ce4657aaa0aea7beeb333d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.7469\n",
      "  Validation Loss     : 1.1070\n",
      "  Semantic Similarity : 0.4667\n",
      "\n",
      "-- Epoch 2/20 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e16732e35d48299c46fa7e45ec137a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48325d190414340a479ecf3187d52ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.1399\n",
      "  Validation Loss     : 0.9318\n",
      "  Semantic Similarity : 0.4377\n",
      "\n",
      "-- Epoch 3/20 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26105aebafa14f299be577fa58bd6107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5ad2da655145f396d524c43096435a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 1.0239\n",
      "  Validation Loss     : 0.8605\n",
      "  Semantic Similarity : 0.4430\n",
      "\n",
      "-- Epoch 4/20 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89967596f81543c59daee0cf5a132641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d713c5049174b61bf072293f689a5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.9437\n",
      "  Validation Loss     : 0.8230\n",
      "  Semantic Similarity : 0.4672\n",
      "\n",
      "-- Epoch 5/20 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfd40b90bfd406396ef00ff1012d133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eafcd3617944abaa35674750938b152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.8817\n",
      "  Validation Loss     : 0.7911\n",
      "  Semantic Similarity : 0.4794\n",
      "\n",
      "-- Epoch 6/20 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16763c5e947b4ff68de3b7184f7243f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b95c68b6ce34ae584e394bca21295c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.8536\n",
      "  Validation Loss     : 0.7682\n",
      "  Semantic Similarity : 0.4810\n",
      "\n",
      "-- Epoch 7/20 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b53f6d2d22944e2b3802f640528b0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8775375f9f9a40ed930521243f4b4fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train Loss          : 0.8317\n",
      "  Validation Loss     : 0.7522\n",
      "  Semantic Similarity : 0.4652\n",
      "\n",
      "-- Epoch 8/20 --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 571\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m --\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 571\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m     val_loss, gen_txt, gt_txt \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n\u001b[1;32m    573\u001b[0m     sem \u001b[38;5;241m=\u001b[39m compute_semantic_similarity(gen_txt, gt_txt)\n",
      "Cell \u001b[0;32mIn[12], line 412\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, scaler, device)\u001b[0m\n\u001b[1;32m    410\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    411\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m--> 412\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfull_imgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatches\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[12], line 194\u001b[0m, in \u001b[0;36mFinalSamplesDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    192\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[idx]\n\u001b[1;32m    193\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 194\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Dataset] full_img shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    197\u001b[0m patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_patches(e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft_right_file_path\u001b[39m\u001b[38;5;124m'\u001b[39m], e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torchvision/transforms/transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torchvision/transforms/functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/rsna/lib/python3.12/site-packages/PIL/Image.py:2356\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2346\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2347\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2348\u001b[0m         )\n\u001b[1;32m   2349\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2350\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2351\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2352\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2353\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2354\u001b[0m         )\n\u001b[0;32m-> 2356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "import random\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import PEFT for LoRA implementation\n",
    "from peft import LoraConfig, get_peft_model, TaskType, PeftModel\n",
    "\n",
    "# =============================================================================\n",
    "# Logging configuration\n",
    "# =============================================================================\n",
    "for h in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(h)\n",
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    filemode='w',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Utility functions\n",
    "# =============================================================================\n",
    "def count_labels(data, target_classes, cfg):\n",
    "    class_counts = defaultdict(int)\n",
    "    data_by_class = defaultdict(list)\n",
    "    for entry in tqdm(data.values(), desc=\"Counting dataset\"):\n",
    "        lbl = entry.get('class_label', '').lower()\n",
    "        if lbl in target_classes and os.path.exists(entry['file_path']):\n",
    "            class_counts[lbl] += 1\n",
    "            data_by_class[lbl].append(entry)\n",
    "    return class_counts, data_by_class\n",
    "\n",
    "def prepare_abnormal_normal_data(data, cfg):\n",
    "    random.seed(42)\n",
    "    class_counts, data_by_class = count_labels(data, ['abnormal', 'normal'], cfg)\n",
    "    combined = {\n",
    "        'abnormal': data_by_class.get('abnormal', []),\n",
    "        'normal':   data_by_class.get('normal',   [])\n",
    "    }\n",
    "    combined_counts = {\n",
    "        'abnormal': class_counts.get('abnormal', 0),\n",
    "        'normal':   class_counts.get('normal',   0)\n",
    "    }\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(combined.values(), []), combined_counts, combined_counts\n",
    "    min_count = min(combined_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl, items in combined.items():\n",
    "        sampled = random.sample(items, min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, combined_counts, final_counts\n",
    "\n",
    "def prepare_data(data, target_classes, cfg, is_binary=False):\n",
    "    random.seed(42)\n",
    "    if is_binary and len(target_classes) == 2 and 'abnormal' in target_classes:\n",
    "        logging.info(\"Using abnormal-vs-normal logic\")\n",
    "        return prepare_abnormal_normal_data(data, cfg)\n",
    "    class_counts, data_by_class = count_labels(data, target_classes, cfg)\n",
    "    logging.info(f\"Original class distribution: {class_counts}\")\n",
    "    print(f\"Original class distribution: {class_counts}\")\n",
    "    if not cfg.DATASET.BALANCE and not cfg.DATASET.AUGMENT:\n",
    "        return sum(data_by_class.values(), []), class_counts, class_counts\n",
    "    min_count = min(class_counts.values())\n",
    "    balanced, final_counts = [], {}\n",
    "    for lbl in target_classes:\n",
    "        sampled = random.sample(data_by_class[lbl], min_count)\n",
    "        balanced.extend(sampled)\n",
    "        final_counts[lbl] = min_count\n",
    "    logging.info(f\"Balanced class distribution: {final_counts}\")\n",
    "    print(f\"Balanced class distribution: {final_counts}\")\n",
    "    if cfg.DATASET.AUGMENT:\n",
    "        balanced = balanced * 2\n",
    "        for lbl in final_counts:\n",
    "            final_counts[lbl] *= 2\n",
    "    return balanced, class_counts, final_counts\n",
    "\n",
    "# =============================================================================\n",
    "# Transforms\n",
    "# =============================================================================\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "patch_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "# =============================================================================\n",
    "# Dataset (binary abnormal vs normal)\n",
    "# =============================================================================\n",
    "class FinalSamplesDataset(Dataset):\n",
    "    def __init__(self, cfg, image_transform=train_transform, patch_transform=patch_transform):\n",
    "        self.cfg = cfg\n",
    "        self.image_transform = image_transform\n",
    "        self.patch_transform = patch_transform\n",
    "\n",
    "        self.target_classes = cfg.DATASET.TARGET_CLASSES\n",
    "        if isinstance(self.target_classes, str):\n",
    "            self.target_classes = self.target_classes.split(\",\")\n",
    "\n",
    "        self.is_binary = len(self.target_classes) == 2 and 'abnormal' in self.target_classes\n",
    "        self.abnormal_mapping = (\n",
    "            {\n",
    "                'ra':   'abnormal',\n",
    "                'oa':   'abnormal',\n",
    "                'gout': 'abnormal',\n",
    "                'oa, ra':               'abnormal',\n",
    "                'combination of oa, ra':'abnormal',\n",
    "                'uncertain': 'abnormal',\n",
    "                'ref.prev' : 'abnormal',\n",
    "                'normal':'normal'\n",
    "            }\n",
    "            if self.is_binary else None\n",
    "        )\n",
    "\n",
    "        with open(cfg.DATASET.JSON, 'r') as f:\n",
    "            raw_list = json.load(f)\n",
    "\n",
    "        filtered = []\n",
    "        for item in raw_list:\n",
    "            merged = item.get('merged_image_path', '')\n",
    "            fp = item.get('file_paths', [])\n",
    "            if isinstance(fp, str):\n",
    "                fp = [fp]\n",
    "            paths = [merged] + fp\n",
    "            if any(os.path.exists(p) for p in paths):\n",
    "                filtered.append((merged, fp, item))\n",
    "\n",
    "        self.data = {}\n",
    "        idx = 0\n",
    "        for merged, fp, item in filtered:\n",
    "            raw_cls = item.get('class', 'unknown').lower()\n",
    "            if self.abnormal_mapping:\n",
    "                if raw_cls not in self.abnormal_mapping:\n",
    "                    continue\n",
    "                cls = self.abnormal_mapping[raw_cls]\n",
    "            else:\n",
    "                if raw_cls not in self.target_classes:\n",
    "                    continue\n",
    "                cls = raw_cls\n",
    "\n",
    "            self.data[idx] = {\n",
    "                'file_path': merged,\n",
    "                'left_right_file_path': fp,\n",
    "                'class_label': cls,\n",
    "                'diagnosis': item.get('diagnosis', ''),\n",
    "                'keypoints': item.get('keypoints', {})\n",
    "            }\n",
    "            idx += 1\n",
    "\n",
    "        if self.is_binary:\n",
    "            balanced, _, _ = prepare_data(self.data, self.target_classes, cfg, True)\n",
    "            self.data = {i: e for i, e in enumerate(balanced)}\n",
    "\n",
    "        self.tokenizer = None\n",
    "        self.eos_token = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        e = self.data[idx]\n",
    "        img = Image.open(e['file_path']).convert('RGB')\n",
    "        img = self.image_transform(img)\n",
    "        logging.info(f\"[Dataset] full_img shape: {img.shape}\")\n",
    "\n",
    "        patches = self._gen_patches(e['left_right_file_path'], e['keypoints'])\n",
    "        pt = [self.patch_transform(Image.fromarray(p)) for p in patches]\n",
    "        patches_tensor = torch.stack(pt, 0) if pt else torch.zeros(34, 3, 112, 112)\n",
    "        logging.info(f\"[Dataset] patches_tensor shape: {patches_tensor.shape}\")\n",
    "\n",
    "        raw = e.get('diagnosis', '')\n",
    "        clean = self._clean_report(raw)\n",
    "\n",
    "        input_text = f\"{self.tokenizer.bos_token} FINDINGS: {clean} {self.tokenizer.eos_token}\"\n",
    "        tok = self.tokenizer(input_text, truncation=True, max_length=512, return_tensors='pt')\n",
    "\n",
    "        input_ids      = tok['input_ids'].squeeze(0)\n",
    "        attention_mask = tok['attention_mask'].squeeze(0)\n",
    "        logging.info(f\"[Dataset] input_ids shape: {input_ids.shape}, attention_mask shape: {attention_mask.shape}\")\n",
    "\n",
    "        return {\n",
    "            'full_img':       img,\n",
    "            'patches':        patches_tensor,\n",
    "            'raw_report':     raw,\n",
    "            'cleaned_report': clean,\n",
    "            'input_ids':      input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "    def _gen_patches(self, paths, kps_dict, crop_size=(200, 300), patch_size=(112, 112)):\n",
    "        def extract(arr, side_kps):\n",
    "            lst = []\n",
    "            pts = side_kps[0]['keypoints']\n",
    "            for i in range(17):\n",
    "                x, y, s = int(pts[3*i]), int(pts[3*i+1]), pts[3*i+2]\n",
    "                if s > 0:\n",
    "                    x0 = max(x - crop_size[0]//2, 0)\n",
    "                    y0 = max(y - crop_size[1]//2, 0)\n",
    "                    x1 = min(x + crop_size[0]//2, arr.shape[1])\n",
    "                    y1 = min(y + crop_size[1]//2, arr.shape[0])\n",
    "                    c = arr[y0:y1, x0:x1]\n",
    "                    if c.size:\n",
    "                        lst.append(cv2.resize(c, patch_size))\n",
    "            return lst\n",
    "\n",
    "        def pad17(lst):\n",
    "            black = np.zeros((patch_size[1], patch_size[0], 3), np.uint8)\n",
    "            while len(lst) < 17:\n",
    "                lst.append(black)\n",
    "            return lst[:17]\n",
    "\n",
    "        left, right = [], []\n",
    "        if len(paths) == 1:\n",
    "            pth = paths[0]\n",
    "            if not pth or not os.path.exists(pth):\n",
    "                return pad17([]) + pad17([])\n",
    "            img_arr = cv2.imread(pth)\n",
    "            if img_arr is None:\n",
    "                return pad17([]) + pad17([])\n",
    "            arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "            if kps_dict.get('left'):  left  = extract(arr, kps_dict['left'])\n",
    "            if kps_dict.get('right'): right = extract(arr, kps_dict['right'])\n",
    "        else:\n",
    "            for side, pth in zip(['left','right'], paths):\n",
    "                if pth and os.path.exists(pth):\n",
    "                    img_arr = cv2.imread(pth)\n",
    "                    if img_arr is not None:\n",
    "                        arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n",
    "                        if kps_dict.get(side):\n",
    "                            lst = extract(arr, kps_dict[side])\n",
    "                            if side=='left':  left  = lst\n",
    "                            else:             right = lst\n",
    "\n",
    "        if left and not right:\n",
    "            right = [cv2.flip(p,1) for p in left]\n",
    "        if right and not left:\n",
    "            left  = [cv2.flip(p,1) for p in right]\n",
    "        if not left and not right:\n",
    "            return pad17([]) + pad17([])\n",
    "\n",
    "        return pad17(left) + pad17(right)\n",
    "\n",
    "    def _clean_report(self, text):\n",
    "        text = unicodedata.normalize('NFKC', text or '')\n",
    "        text = re.sub(r'(?m)^-+\\s*$', '', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "        text = re.sub(r'([.!?]){2,}', r'\\1', text)\n",
    "        text = re.sub(r'\\[\\s*finding\\s*\\]', '[FINDING]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*conclusion\\s*\\]', '[CONCLUSION]', text, flags=re.IGNORECASE)\n",
    "        text = re.sub(r'\\[\\s*diagnosis\\s*\\]', '[DIAGNOSIS]', text, flags=re.IGNORECASE)\n",
    "        parts = re.split(r'\\[\\s*recommend(?:ation)?\\s*\\]', text, flags=re.IGNORECASE)\n",
    "        text = parts[0]\n",
    "        fm = re.search(r'\\[FINDING\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        cm = re.search(r'\\[CONCLUSION\\](.*?)(?=\\[|$)', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        if fm and cm and fm.group(1).strip().lower() == cm.group(1).strip().lower():\n",
    "            text = re.sub(r'\\[CONCLUSION\\].*?(?=\\[|$)', '', text, flags=re.IGNORECASE|re.DOTALL)\n",
    "        text = re.sub(r'\\[\\s*(FINDING|CONCLUSION|DIAGNOSIS)\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "        text = text.replace('_x000D_', ' ')\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "# =============================================================================\n",
    "# Collate function\n",
    "# =============================================================================\n",
    "def collate_fn(batch):\n",
    "    imgs = torch.stack([b['full_img'] for b in batch])\n",
    "    logging.info(f\"[Collate] imgs: {imgs.shape}\")\n",
    "\n",
    "    pts = [b['patches'] for b in batch]\n",
    "    max_p = max(p.shape[0] for p in pts)\n",
    "    pads = []\n",
    "    for p in pts:\n",
    "        if p.shape[0] < max_p:\n",
    "            pad = torch.zeros((max_p - p.shape[0], *p.shape[1:]))\n",
    "            p = torch.cat([p, pad], dim=0)\n",
    "        pads.append(p)\n",
    "    patches = torch.stack(pads, 0)\n",
    "    logging.info(f\"[Collate] patches: {patches.shape}\")\n",
    "\n",
    "    ids   = [b['input_ids'] for b in batch]\n",
    "    masks = [b['attention_mask'] for b in batch]\n",
    "    ids   = nn.utils.rnn.pad_sequence(ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    masks = nn.utils.rnn.pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "    logging.info(f\"[Collate] ids: {ids.shape}, masks: {masks.shape}\")\n",
    "\n",
    "    return {\n",
    "        'full_imgs':       imgs,\n",
    "        'patches':         patches,\n",
    "        'input_ids':       ids,\n",
    "        'attention_mask':  masks,\n",
    "        'raw_reports':     [b['raw_report']     for b in batch],\n",
    "        'cleaned_reports': [b['cleaned_report'] for b in batch]\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# Model definition with LoRA\n",
    "# =============================================================================\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, gpt2_model_name='gpt2'):\n",
    "        super().__init__()\n",
    "        # Vision encoders\n",
    "        self.global_encoder = timm.create_model('swin_base_patch4_window7_224', pretrained=True)\n",
    "        self.global_encoder.reset_classifier(0)\n",
    "        self.global_proj = nn.Linear(self.global_encoder.num_features, 768)\n",
    "\n",
    "        self.patch_encoder = timm.create_model('resnet50', pretrained=True)\n",
    "        self.patch_encoder.fc = nn.Identity()\n",
    "        self.patch_proj = nn.Linear(self.patch_encoder.num_features, 768)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=768, num_heads=8, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(768)\n",
    "        \n",
    "        # Initialize base GPT-2 model with cross-attention\n",
    "        base_decoder = GPT2LMHeadModel.from_pretrained(gpt2_model_name, add_cross_attention=True)\n",
    "        \n",
    "        # Configure LoRA\n",
    "        lora_config = LoraConfig(\n",
    "            task_type=TaskType.CAUSAL_LM,\n",
    "            r=16,                  # Low rank dimension\n",
    "            lora_alpha=32,         # Scaling factor\n",
    "            lora_dropout=0.05,     # Dropout probability\n",
    "            target_modules=[\"c_attn\", \"c_proj\"],  # Apply to attention modules\n",
    "            bias=\"none\"\n",
    "        )\n",
    "        \n",
    "        # Apply LoRA to the model\n",
    "        self.decoder = get_peft_model(base_decoder, lora_config)\n",
    "        \n",
    "        # Print trainable parameters info\n",
    "        self.print_trainable_parameters()\n",
    "    \n",
    "    def print_trainable_parameters(self):\n",
    "        \"\"\"\n",
    "        Prints the number of trainable parameters in the model.\n",
    "        \"\"\"\n",
    "        trainable_params = 0\n",
    "        all_param = 0\n",
    "        for _, param in self.decoder.named_parameters():\n",
    "            all_param += param.numel()\n",
    "            if param.requires_grad:\n",
    "                trainable_params += param.numel()\n",
    "        \n",
    "        logging.info(\n",
    "            f\"GPT-2 with LoRA trainable params: {trainable_params} || all params: {all_param} || \"\n",
    "            f\"trainable%: {100 * trainable_params / all_param:.2f}%\"\n",
    "        )\n",
    "\n",
    "    def _pool(self, feats):\n",
    "        return feats.mean(dim=[2,3]) if feats.ndim > 2 else feats\n",
    "\n",
    "    def forward(self, imgs, patches, input_ids, attention_mask, decoder_labels=None):\n",
    "        g_feats = self.global_encoder(imgs)\n",
    "        g = self.global_proj(g_feats).unsqueeze(1)\n",
    "\n",
    "        B,N,C,H,W = patches.shape\n",
    "        p = patches.view(B*N, C, H, W)\n",
    "        pf_feats = (self.patch_encoder.forward_features(p)\n",
    "                   if hasattr(self.patch_encoder, 'forward_features')\n",
    "                   else self.patch_encoder(p))\n",
    "        pf_pooled = self._pool(pf_feats)\n",
    "        pf = self.patch_proj(pf_pooled).view(B, N, 768)\n",
    "\n",
    "        cat, _ = self.attn(torch.cat([g,pf],1),\n",
    "                          torch.cat([g,pf],1),\n",
    "                          torch.cat([g,pf],1))\n",
    "        comb = self.norm(cat)\n",
    "\n",
    "        out = self.decoder(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            encoder_hidden_states=comb,\n",
    "            labels=decoder_labels\n",
    "        )\n",
    "        return out\n",
    "\n",
    "# =============================================================================\n",
    "# Training & evaluation loops\n",
    "# =============================================================================\n",
    "def train_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for b in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts = b['patches'].to(device)\n",
    "        ids = b['input_ids'].to(device)\n",
    "        msk = b['attention_mask'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.amp.autocast(device_type='cuda'):\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            loss = out.loss\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    all_gen, all_gt = [], []\n",
    "    for b in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
    "        imgs = b['full_imgs'].to(device)\n",
    "        pts = b['patches'].to(device)\n",
    "        ids = b['input_ids'].to(device)\n",
    "        msk = b['attention_mask'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(imgs, pts, ids, msk, decoder_labels=ids)\n",
    "            total_loss += out.loss.item()\n",
    "\n",
    "            # rebuild visual context\n",
    "            g_feats = model.global_encoder(imgs)\n",
    "            g = model.global_proj(g_feats).unsqueeze(1)\n",
    "            B,N,C,H,W = pts.shape\n",
    "            p = pts.view(B*N, C, H, W)\n",
    "            pf_feats = model.patch_encoder(p)\n",
    "            pf_pooled = model._pool(pf_feats)\n",
    "            pf = model.patch_proj(pf_pooled).view(B, N, 768)\n",
    "            cat, _ = model.attn(torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1),\n",
    "                                torch.cat([g,pf],1))\n",
    "            comb = model.norm(cat)\n",
    "\n",
    "            # per-sample generation to avoid size mismatch\n",
    "            prompt_ids = tokenizer(\"FINDINGS:\", return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "            prompt_ids = prompt_ids.expand(B, -1)\n",
    "            prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "\n",
    "            gen_txt = []\n",
    "            for i in range(B):\n",
    "                inp = prompt_ids[i:i+1]\n",
    "                m = prompt_mask[i:i+1]\n",
    "                enc = comb[i:i+1]\n",
    "                enc_attn = torch.ones(1, enc.size(1), device=device)\n",
    "                out_ids = model.decoder.generate(\n",
    "                    input_ids=inp,\n",
    "                    attention_mask=m,\n",
    "                    encoder_hidden_states=enc,\n",
    "                    encoder_attention_mask=enc_attn,\n",
    "                    max_length=150,\n",
    "                    do_sample=True,\n",
    "                    top_p=0.9,\n",
    "                    temperature=0.7,\n",
    "                    repetition_penalty=1.3,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                    pad_token_id=tokenizer.eos_token_id\n",
    "                )\n",
    "                gen_txt.append(tokenizer.decode(out_ids[0], skip_special_tokens=True))\n",
    "\n",
    "            gt_txt = [tokenizer.decode(i_, skip_special_tokens=True) for i_ in ids]\n",
    "            all_gen.extend(gen_txt)\n",
    "            all_gt.extend(gt_txt)\n",
    "\n",
    "    return total_loss / len(loader), all_gen, all_gt\n",
    "\n",
    "def compute_semantic_similarity(gen, gt):\n",
    "    stm = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    e1 = stm.encode(gen, convert_to_tensor=True)\n",
    "    e2 = stm.encode(gt, convert_to_tensor=True)\n",
    "    return nn.functional.cosine_similarity(e1, e2).mean().item()\n",
    "\n",
    "def plot_metrics(train_losses, val_losses, sems):\n",
    "    epochs = range(1, len(train_losses)+1)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, sems, label=\"Semantic Sim\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Sim\"); plt.legend()\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN: LoRA fine-tuning with frozen vision encoders\n",
    "# =============================================================================\n",
    "class Cfg: pass\n",
    "cfg = Cfg()\n",
    "cfg.DATASET = Cfg()\n",
    "cfg.DATASET.JSON = 'final_samples_both_only_v2.json'\n",
    "cfg.DATASET.USE_RAW = True\n",
    "cfg.DATASET.USE_PATCH = True\n",
    "cfg.DATASET.REPORT = True\n",
    "cfg.DATASET.TARGET_CLASSES = ['abnormal','normal']\n",
    "cfg.DATASET.BALANCE = False\n",
    "cfg.DATASET.AUGMENT = False\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.bos_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "dataset = FinalSamplesDataset(cfg)\n",
    "dataset.tokenizer = tokenizer\n",
    "dataset.eos_token = tokenizer.eos_token\n",
    "\n",
    "dist = Counter(e['class_label'] for e in dataset.data.values())\n",
    "for cls,cnt in dist.items():\n",
    "    logging.info(f\"  {cls}: {cnt}\")\n",
    "    print(f\"  {cls}: {cnt}\")\n",
    "\n",
    "n = len(dataset)\n",
    "n_train = int(0.8 * n)\n",
    "n_val = int(0.1 * n)\n",
    "n_test = n - n_train - n_val\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [n_train,n_val,n_test])\n",
    "\n",
    "# print sample counts\n",
    "print(f\"\\nNumber of training samples:   {len(train_ds)}\")\n",
    "print(f\"Number of validation samples: {len(val_ds)}\")\n",
    "print(f\"Number of test samples:       {len(test_ds)}\")\n",
    "print(f\"Total samples:                {len(train_ds) + len(val_ds) + len(test_ds)}\\n\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "model = MultiModalModel().to(device)\n",
    "\n",
    "# Freeze vision backbones\n",
    "for p in model.global_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.patch_encoder.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Setup optimizer for trainable parameters only (LoRA parameters + projection heads)\n",
    "optimizer = optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "scaler = torch.amp.GradScaler()\n",
    "\n",
    "# Training loop with LoRA\n",
    "num_epochs = 20\n",
    "train_losses, val_losses, sems = [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n-- Epoch {epoch+1}/{num_epochs} --\")\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, gen_txt, gt_txt = evaluate(model, val_loader, device)\n",
    "    sem = compute_semantic_similarity(gen_txt, gt_txt)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    sems.append(sem)\n",
    "\n",
    "    print(f\"  Train Loss          : {train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss     : {val_loss:.4f}\")\n",
    "    print(f\"  Semantic Similarity : {sem:.4f}\")\n",
    "    scheduler.step()\n",
    "\n",
    "plot_metrics(train_losses, val_losses, sems)\n",
    "\n",
    "# Save LoRA weights\n",
    "#model.decoder.save_pretrained(\"lora_gpt2_medical_model\")\n",
    "\n",
    "# Final test evaluation\n",
    "test_loss, test_gen, test_gt = evaluate(model, test_loader, device)\n",
    "test_sem = compute_semantic_similarity(test_gen, test_gt)\n",
    "\n",
    "print(\"\\n========== TEST RESULTS ==========\")\n",
    "print(f\"Test Loss               : {test_loss:.4f}\")\n",
    "print(f\"Test Semantic Similarity: {test_sem:.4f}\")\n",
    "\n",
    "# Generate examples from test set\n",
    "for idx in random.sample(range(len(test_ds)), min(5, len(test_ds))):\n",
    "    ex = test_ds[idx]\n",
    "    raw = ex['raw_report']\n",
    "    clean = ex['cleaned_report']\n",
    "    fi = ex['full_img'].unsqueeze(0).to(device)\n",
    "    pa = ex['patches'].unsqueeze(0).to(device)\n",
    "\n",
    "    g_feats = model.global_encoder(fi)\n",
    "    g = model.global_proj(g_feats).unsqueeze(1)\n",
    "    B,N,C,H,W = pa.shape\n",
    "    p = pa.view(B*N, C, H, W)\n",
    "    pf_feats = model.patch_encoder(p)\n",
    "    pf_pooled = model._pool(pf_feats)\n",
    "    pf = model.patch_proj(pf_pooled).view(B,N,768)\n",
    "    cat,_ = model.attn(torch.cat([g,pf],1),\n",
    "                      torch.cat([g,pf],1),\n",
    "                      torch.cat([g,pf],1))\n",
    "    comb = model.norm(cat)\n",
    "\n",
    "    prompt_text = f\"{tokenizer.bos_token} FINDINGS:\"\n",
    "    prompt_ids = tokenizer(prompt_text, return_tensors=\"pt\", add_special_tokens=False).input_ids.to(device)\n",
    "    prompt_mask = torch.ones_like(prompt_ids, device=device)\n",
    "    gen_ids = model.decoder.generate(\n",
    "        input_ids=prompt_ids,\n",
    "        attention_mask=prompt_mask,\n",
    "        encoder_hidden_states=comb,\n",
    "        encoder_attention_mask=torch.ones(1, comb.size(1), device=device),\n",
    "        max_length=150,\n",
    "        do_sample=True,\n",
    "        top_p=0.9,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.3,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    gen = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    print(f\"\\n--- Example {idx} ---\")\n",
    "    print(f\"Raw Report       : \\n{raw}\")\n",
    "    print(f\"Cleaned Report   : \\n{clean}\")\n",
    "    print(f\"Generated Report : \\n{gen}\")\n",
    "\n",
    "# Load and use the saved LoRA weights\n",
    "def load_lora_model():\n",
    "    base_model = GPT2LMHeadModel.from_pretrained('gpt2', add_cross_attention=True)\n",
    "    lora_model = PeftModel.from_pretrained(base_model, \"lora_gpt2_medical_model\")\n",
    "    return lora_model\n",
    "\n",
    "# If you want to merge the LoRA weights with the base model for faster inference\n",
    "def merge_and_save():\n",
    "    model = load_lora_model()\n",
    "    model = model.merge_and_unload()  # This merges the LoRA weights into the base model\n",
    "    model.save_pretrained(\"merged_gpt2_medical_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d297295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
